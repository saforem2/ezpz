{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udf4b <code>ezpz</code>","text":"<ol> <li> <p>\ud83c\udfd6\ufe0f Setup environment<sup>1</sup> (see Shell Environment):</p> <pre><code>source &lt;(curl https://raw.githubusercontent.com/saforem2/ezpz/refs/heads/main/src/ezpz/bin/utils.sh) &amp;&amp; ezpz_setup_env\n</code></pre> </li> <li> <p>\ud83d\udc0d Install <code>ezpz</code> (see Python Library):</p> <pre><code>python3 -m pip install \"git+https://github.com/saforem2/ezpz\"\n</code></pre> </li> <li> <p>\ud83d\ude80 Launch any <code>*.py</code><sup>2</sup> from python (see Launch):</p> <pre><code>python3 -m ezpz.launch -m ezpz.test_dist\n</code></pre> </li> </ol> <p>\ud83d\ude0e 2 ez.</p> <ol> <li> <p>This will \ud83e\ude84 automagically source      <code>ezpz/bin/utils.sh</code>      and (<code>&amp;&amp;</code>) call <code>ezpz_setup_env</code> to setup your      python environment.\u00a0\u21a9</p> </li> <li> <p>Technically, we're launching (<code>-m ezpz.launch</code>) the      <code>ezpz/test_dist.py</code> as a module (<code>-m</code>),      in this example.\u00a0\u21a9</p> </li> </ol>"},{"location":"example/","title":"\ud83d\udcd1 Simple Example","text":"<ol> <li>Clone repo:</li> </ol> <pre><code>git clone https://github.com/saforem2/ezpz\ncd ezpz\n</code></pre> <ol> <li>Setup environment:</li> </ol> <pre><code>export PBS_O_WORKDIR=$(pwd) &amp;&amp; source src/ezpz/bin/utils.sh &amp;&amp; ezpz_setup_env\n</code></pre> Output <pre><code>$ export PBS_O_WORKDIR=$(pwd) &amp;&amp; source src/ezpz/bin/utils.sh &amp;&amp; ezpz_setup_env\nUsing WORKING_DIR: /gila/Aurora_deployment/foremans/projects/saforem2/ezpz\nNo conda_prefix OR virtual_env found in environment...\nSetting up conda...\n\nDue to MODULEPATH changes, the following have been reloaded:\n1) mpich/icc-all-pmix-gpu/20240717\n\nThe following have been reloaded with a version change:\n1) oneapi/eng-compiler/2024.07.30.002 =&gt; oneapi/release/2024.2.1\n\nFound conda at: /opt/aurora/24.180.1/frameworks/aurora_nre_models_frameworks-2024.2.1_u1\nNo VIRTUAL_ENV found in environment!\n- Trying to setup from /opt/aurora/24.180.1/frameworks/aurora_nre_models_frameworks-2024.2.1_u1\n- Using VENV_DIR=/gila/Aurora_deployment/foremans/projects/saforem2/ezpz/venvs/aurora_nre_models_frameworks-2024.2.1_u1\n\n- Creating a new virtual env on top of aurora_nre_models_frameworks-2024.2.1_u1 in /gila/Aurora_deployment/foremans/projects/saforem2/ezpz/venvs/aurora_nre_models_frameworks-2024.2.1_u1\n[python] Using /gila/Aurora_deployment/foremans/projects/saforem2/ezpz/venvs/aurora_nre_models_frameworks-2024.2.1_u1/bin/python3\n\n[\ud83c\udf4b ezpz/bin/utils.sh]\n\u2022 USER=foremans\n\u2022 MACHINE=sunspot\n\u2022 HOST=x1922c5s0b0n0\n\u2022 TSTAMP=2024-11-28-133756\n\n[ezpz_setup_host_pbs]\n\u2022 Using hostfile: /var/spool/pbs/aux/10283088.amn-0001\n\u2022 Found in environment:\n\u2022 HOSTFILE: /var/spool/pbs/aux/10283088.amn-0001\n\u2022 Writing PBS vars to: /home/foremans/.pbsenv\n\n[ezpz_save_pbs_env]\n\u2022 Setting:\n\u2022 HOSTFILE: /var/spool/pbs/aux/10283088.amn-0001\n\u2022 JOBENV_FILE: /home/foremans/.pbsenv\n\n[HOSTS]\n\u2022 [host:0] - x1922c5s0b0n0.hostmgmt2001.cm.americas.sgi.com\n\u2022 [host:1] - x1922c5s2b0n0.hostmgmt2001.cm.americas.sgi.com\n\u2022 [host:2] - x1922c5s4b0n0.hostmgmt2001.cm.americas.sgi.com\n\u2022 [host:3] - x1922c6s1b0n0.hostmgmt2001.cm.americas.sgi.com\n\n[DIST INFO]\n\u2022 NGPUS=48\n\u2022 NHOSTS=4\n\u2022 NGPU_PER_HOST=12\n\u2022 HOSTFILE=/var/spool/pbs/aux/10283088.amn-0001\n\u2022 DIST_LAUNCH=mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/10283088.amn-0001 --cpu-bind depth -d 8\n\n[LAUNCH]:\n\u2022 To launch across all available GPUs, use: launch\n\nlaunch = mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/10283088.amn-0001 --cpu-bind depth -d 8\n\ntook: 0h:00m:12s\n</code></pre> <ol> <li>Install <code>ezpz</code>:</li> </ol> <pre><code>python3 -m pip install -e \".\" --require-virtualenv\n</code></pre> <ol> <li>Check <code>launch</code>:</li> </ol> <pre><code>$ which launch\nlaunch: aliased to mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/10283088.amn-0001 --cpu-bind depth -d 8\n</code></pre> <ol> <li>Run <code>ezpz.test_dist</code>:</li> </ol> <pre><code>launch python3 src/ezpz/test_dist.py\n</code></pre> Output <pre><code>#[\ud83d\udc0d aurora_nre_models_frameworks-2023.2.1_u1](\ud83d\udc7b aurora_nre_models_frameworks-2024.2.1_u1)\n#[\ud83c\udf3b][01:42:37 PM][foremans@x1922c5s0b0n0][\u2026/ezpz][\ud83c\udf31 saforem2-patch-1]via \u2a01 v1.4.552\n$ launch python3 -m ezpz.test_dist\nDisabling local launch: multi-node application\nConnected to tcp://x1922c5s0b0n0.hostmgmt2001.cm.americas.sgi.com:7919\nFound executable /gila/Aurora_deployment/foremans/projects/saforem2/ezpz/venvs/aurora_nre_models_frameworks-2024.2.1_u1/bin/python3\nLaunching application ecd9868b-2b3b-4a0e-b2e6-79769ecc7eff\n[2024-11-28 13:43:41.385960][INFO][dist.py:348] - [device='xpu'][rank=3/47][local_rank=3/11][node=3/3]\n[2024-11-28 13:43:41.386603][INFO][dist.py:348] - [device='xpu'][rank=1/47][local_rank=1/11][node=1/3]\n[2024-11-28 13:43:41.386605][INFO][dist.py:348] - [device='xpu'][rank=2/47][local_rank=2/11][node=2/3]\n[2024-11-28 13:43:41.386834][INFO][dist.py:348] - [device='xpu'][rank=6/47][local_rank=6/11][node=2/3]\n[2024-11-28 13:43:41.387707][INFO][dist.py:348] - [device='xpu'][rank=8/47][local_rank=8/11][node=0/3]\n[2024-11-28 13:43:41.387290][INFO][dist.py:348] - [device='xpu'][rank=4/47][local_rank=4/11][node=0/3]\n[2024-11-28 13:43:41.387235][INFO][dist.py:348] - [device='xpu'][rank=10/47][local_rank=10/11][node=2/3]\n[2024-11-28 13:43:41.387362][INFO][dist.py:348] - [device='xpu'][rank=11/47][local_rank=11/11][node=3/3]\n[2024-11-28 13:43:41.387761][INFO][dist.py:348] - [device='xpu'][rank=5/47][local_rank=5/11][node=1/3]\n[2024-11-28 13:43:41.387958][INFO][dist.py:348] - [device='xpu'][rank=9/47][local_rank=9/11][node=1/3]\n[2024-11-28 13:43:46.384505][INFO][dist.py:348] - [device='xpu'][rank=7/47][local_rank=7/11][node=3/3]\n[2024-11-28 13:44:32.816252][INFO][dist.py:348] - [device='xpu'][rank=15/47][local_rank=3/11][node=3/3]\n[2024-11-28 13:44:32.821175][INFO][dist.py:348] - [device='xpu'][rank=17/47][local_rank=5/11][node=1/3]\n[2024-11-28 13:44:32.824021][INFO][dist.py:348] - [device='xpu'][rank=22/47][local_rank=10/11][node=2/3]\n[2024-11-28 13:44:32.825905][INFO][dist.py:348] - [device='xpu'][rank=41/47][local_rank=5/11][node=1/3]\n[2024-11-28 13:44:32.826590][INFO][dist.py:348] - [device='xpu'][rank=38/47][local_rank=2/11][node=2/3]\n[2024-11-28 13:44:32.838048][INFO][dist.py:348] - [device='xpu'][rank=23/47][local_rank=11/11][node=3/3]\n[2024-11-28 13:44:32.838526][INFO][dist.py:348] - [device='xpu'][rank=21/47][local_rank=9/11][node=1/3]\n[2024-11-28 13:44:32.838825][INFO][dist.py:348] - [device='xpu'][rank=19/47][local_rank=7/11][node=3/3]\n[2024-11-28 13:44:32.838817][INFO][dist.py:348] - [device='xpu'][rank=36/47][local_rank=0/11][node=0/3]\n[2024-11-28 13:44:32.838665][INFO][dist.py:348] - [device='xpu'][rank=35/47][local_rank=11/11][node=3/3]\n[2024-11-28 13:44:32.839033][INFO][dist.py:348] - [device='xpu'][rank=25/47][local_rank=1/11][node=1/3]\n[2024-11-28 13:44:32.838855][INFO][dist.py:348] - [device='xpu'][rank=26/47][local_rank=2/11][node=2/3]\n[2024-11-28 13:44:32.839144][INFO][dist.py:348] - [device='xpu'][rank=33/47][local_rank=9/11][node=1/3]\n[2024-11-28 13:44:32.840785][INFO][dist.py:348] - [device='xpu'][rank=37/47][local_rank=1/11][node=1/3]\n[2024-11-28 13:44:32.840740][INFO][dist.py:348] - [device='xpu'][rank=47/47][local_rank=11/11][node=3/3]\n[2024-11-28 13:44:32.844721][INFO][dist.py:348] - [device='xpu'][rank=46/47][local_rank=10/11][node=2/3]\n[2024-11-28 13:44:32.845202][INFO][dist.py:348] - [device='xpu'][rank=30/47][local_rank=6/11][node=2/3]\n[2024-11-28 13:44:32.845888][INFO][dist.py:348] - [device='xpu'][rank=18/47][local_rank=6/11][node=2/3]\n[2024-11-28 13:44:32.849905][INFO][dist.py:348] - [device='xpu'][rank=20/47][local_rank=8/11][node=0/3]\n[2024-11-28 13:44:32.849947][INFO][dist.py:348] - [device='xpu'][rank=32/47][local_rank=8/11][node=0/3]\n[2024-11-28 13:44:32.850232][INFO][dist.py:348] - [device='xpu'][rank=39/47][local_rank=3/11][node=3/3]\n[2024-11-28 13:44:32.850301][INFO][dist.py:348] - [device='xpu'][rank=44/47][local_rank=8/11][node=0/3]\n[2024-11-28 13:44:32.850795][INFO][dist.py:348] - [device='xpu'][rank=14/47][local_rank=2/11][node=2/3]\n[2024-11-28 13:44:32.851872][INFO][dist.py:348] - [device='xpu'][rank=28/47][local_rank=4/11][node=0/3]\n[2024-11-28 13:44:32.852078][INFO][dist.py:348] - [device='xpu'][rank=12/47][local_rank=0/11][node=0/3]\n[2024-11-28 13:44:32.853836][INFO][dist.py:348] - [device='xpu'][rank=16/47][local_rank=4/11][node=0/3]\n[2024-11-28 13:44:32.853997][INFO][dist.py:348] - [device='xpu'][rank=24/47][local_rank=0/11][node=0/3]\n[2024-11-28 13:44:32.855526][INFO][dist.py:348] - [device='xpu'][rank=13/47][local_rank=1/11][node=1/3]\n[2024-11-28 13:44:32.856609][INFO][dist.py:348] - [device='xpu'][rank=40/47][local_rank=4/11][node=0/3]\n[2024-11-28 13:44:32.857991][INFO][dist.py:348] - [device='xpu'][rank=42/47][local_rank=6/11][node=2/3]\n[2024-11-28 13:44:32.863239][INFO][dist.py:348] - [device='xpu'][rank=29/47][local_rank=5/11][node=1/3]\n[2024-11-28 13:44:32.864956][INFO][dist.py:348] - [device='xpu'][rank=45/47][local_rank=9/11][node=1/3]\n[2024-11-28 13:44:32.867388][INFO][dist.py:348] - [device='xpu'][rank=27/47][local_rank=3/11][node=3/3]\n[2024-11-28 13:44:32.867764][INFO][dist.py:348] - [device='xpu'][rank=43/47][local_rank=7/11][node=3/3]\n[2024-11-28 13:44:32.873106][INFO][dist.py:348] - [device='xpu'][rank=34/47][local_rank=10/11][node=2/3]\n[2024-11-28 13:44:32.877043][INFO][dist.py:348] - [device='xpu'][rank=31/47][local_rank=7/11][node=3/3]\n[2024-11-28 13:44:32.887609][INFO][dist.py:92] -\n\n[dist_info]:\n\u2022 DEVICE=xpu\n\u2022 DEVICE_ID=xpu:0\n\u2022 DISTRIBUTED_BACKEND=ccl\n\u2022 GPUS_PER_NODE=12\n\u2022 HOSTS=['x1922c5s0b0n0.hostmgmt2001.cm.americas.sgi.com', 'x1922c5s2b0n0.hostmgmt2001.cm.americas.sgi.com', 'x1922c5s4b0n0.hostmgmt2001.cm.americas.sgi.com', 'x1922c6s1b0n0.hostmgmt2001.cm.americas.sgi.com']\n\u2022 HOSTFILE=/var/spool/pbs/aux/10283088.amn-0001\n\u2022 HOSTNAME=x1922c5s0b0n0.hostmgmt2001.cm.americas.sgi.com\n\u2022 LOCAL_RANK=0\n\u2022 MACHINE=SunSpot\n\u2022 NUM_NODES=4\n\u2022 NGPUS=48\n\u2022 NGPUS_AVAILABLE=48\n\u2022 NODE_ID=0\n\u2022 RANK=0\n\u2022 SCHEDULER=PBS\n\u2022 WORLD_SIZE_TOTAL=48\n\u2022 WORLD_SIZE_IN_USE=48\n\u2022 LAUNCH_CMD=mpiexec --verbose --envall -n 48 -ppn 12 --hostfile /var/spool/pbs/aux/10283088.amn-0001 --cpu-bind depth -d 16\n\n\n[2024-11-28 13:44:32.933415][INFO][dist.py:725] - Using oneccl_bindings from: /opt/aurora/24.180.1/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/oneccl_bindings_for_pytorch/__init__.py\n[2024-11-28 13:44:32.933861][INFO][dist.py:727] - Using ipex from: /opt/aurora/24.180.1/frameworks/aurora_nre_models_frameworks-2024.2.1_u1/lib/python3.10/site-packages/intel_extension_for_pytorch/__init__.py\n[2024-11-28 13:44:32.934238][INFO][dist.py:728] - [0/48] Using device='xpu' with backend='DDP' + 'ccl' for distributed training.\n[2024-11-28 13:44:32.940188][INFO][dist.py:348] - [device='xpu'][rank=0/47][local_rank=0/11][node=0/3]\n[2024-11-28 13:44:32.940746][WARNING][_logger.py:68] - Using [48 / 48] available \"xpu\" devices !!\n[2024-11-28 13:44:34.193788][INFO][dist.py:882] - Setting up wandb from rank: 0\n[2024-11-28 13:44:34.194312][INFO][dist.py:883] - Using: WB PROJECT: ezpz.test_dist\nwandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\nwandb: Currently logged in as: foremans (aurora_gpt). Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.18.7\nwandb: Run data is saved locally in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/wandb/run-20241128_134434-4mwyy84l\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run driven-wind-683\nwandb: \u2b50\ufe0f View project at https://wandb.ai/aurora_gpt/ezpz.test_dist\nwandb: \ud83d\ude80 View run at https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/4mwyy84l\n[2024-11-28 13:44:35.481364][INFO][dist.py:908] - W&amp;B RUN: [driven-wind-683](https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/4mwyy84l)\n[2024-11-28 13:44:35.495959][INFO][dist.py:304] - Updating wandb.run: driven-wind-683 config with \"DIST_INFO\"\n[2024-11-28 13:44:35.500222][INFO][dist.py:936] - Running on machine='SunSpot'\n[2024-11-28 13:44:35.501304][INFO][dist.py:92] -\n\n[CONFIG]:\n\u2022 warmup=0\n\u2022 log_freq=1\n\u2022 batch_size=64\n\u2022 input_size=128\n\u2022 output_size=128\n\u2022 dtype=torch.float32\n\u2022 device=xpu\n\u2022 world_size=48\n\u2022 train_iters=100\n\n\n[2024-11-28 13:44:35.575161][INFO][test_dist.py:147] - model=Network(\n(layers): Sequential(\n(0): Linear(in_features=128, out_features=1024, bias=True)\n(1): Linear(in_features=1024, out_features=512, bias=True)\n(2): Linear(in_features=512, out_features=256, bias=True)\n(3): Linear(in_features=256, out_features=128, bias=True)\n(4): Linear(in_features=128, out_features=128, bias=True)\n)\n)\n[2024-11-28 13:44:48.340596][INFO][test_dist.py:228] - iter=1 dt=0.019713 dtf=0.002959 dtb=0.016754 loss=1821.131958 sps=3246.551823\n[2024-11-28 13:44:48.346527][INFO][test_dist.py:228] - iter=2 dt=0.004083 dtf=0.000822 dtb=0.003261 loss=1348.032227 sps=15673.877930\n[2024-11-28 13:44:48.351387][INFO][test_dist.py:228] - iter=3 dt=0.003260 dtf=0.000735 dtb=0.002525 loss=1072.068359 sps=19634.479814\n[2024-11-28 13:44:48.356043][INFO][test_dist.py:228] - iter=4 dt=0.003117 dtf=0.000716 dtb=0.002401 loss=928.493774 sps=20534.414826\n[2024-11-28 13:44:48.360830][INFO][test_dist.py:228] - iter=5 dt=0.003181 dtf=0.000798 dtb=0.002384 loss=867.221558 sps=20116.568892\n[2024-11-28 13:44:48.365608][INFO][test_dist.py:228] - iter=6 dt=0.003146 dtf=0.000738 dtb=0.002408 loss=794.671204 sps=20341.929281\n[2024-11-28 13:44:48.370473][INFO][test_dist.py:228] - iter=7 dt=0.003149 dtf=0.000751 dtb=0.002398 loss=748.687500 sps=20324.551047\n[2024-11-28 13:44:48.375126][INFO][test_dist.py:228] - iter=8 dt=0.003105 dtf=0.000719 dtb=0.002385 loss=720.116943 sps=20614.492256\n[2024-11-28 13:44:48.379744][INFO][test_dist.py:228] - iter=9 dt=0.003057 dtf=0.000698 dtb=0.002359 loss=714.217957 sps=20937.174740\n[2024-11-28 13:44:48.384429][INFO][test_dist.py:228] - iter=10 dt=0.003083 dtf=0.000703 dtb=0.002380 loss=718.780884 sps=20760.967373\n[2024-11-28 13:44:48.390098][INFO][test_dist.py:228] - iter=11 dt=0.003931 dtf=0.000802 dtb=0.003129 loss=699.931152 sps=16281.262548\n[2024-11-28 13:44:48.395638][INFO][test_dist.py:228] - iter=12 dt=0.003698 dtf=0.000865 dtb=0.002832 loss=687.315857 sps=17308.773026\n[2024-11-28 13:44:48.400852][INFO][test_dist.py:228] - iter=13 dt=0.003502 dtf=0.000792 dtb=0.002709 loss=685.231995 sps=18276.152786\n[2024-11-28 13:44:48.406145][INFO][test_dist.py:228] - iter=14 dt=0.003501 dtf=0.000788 dtb=0.002714 loss=678.643860 sps=18278.977230\n[2024-11-28 13:44:48.411186][INFO][test_dist.py:228] - iter=15 dt=0.003366 dtf=0.000760 dtb=0.002606 loss=675.734375 sps=19012.740109\n[2024-11-28 13:44:48.416092][INFO][test_dist.py:228] - iter=16 dt=0.003308 dtf=0.000764 dtb=0.002545 loss=656.803894 sps=19345.774997\n[2024-11-28 13:44:48.421088][INFO][test_dist.py:228] - iter=17 dt=0.003326 dtf=0.000800 dtb=0.002526 loss=663.846558 sps=19240.551489\n[2024-11-28 13:44:48.426305][INFO][test_dist.py:228] - iter=18 dt=0.003439 dtf=0.000805 dtb=0.002634 loss=646.870605 sps=18607.582468\n[2024-11-28 13:44:48.431107][INFO][test_dist.py:228] - iter=19 dt=0.003217 dtf=0.000730 dtb=0.002488 loss=631.541504 sps=19893.098888\n[2024-11-28 13:44:48.436171][INFO][test_dist.py:228] - iter=20 dt=0.003447 dtf=0.000707 dtb=0.002741 loss=645.819580 sps=18564.526433\n[2024-11-28 13:44:48.441333][INFO][test_dist.py:228] - iter=21 dt=0.003465 dtf=0.000921 dtb=0.002543 loss=642.620361 sps=18470.919500\n[2024-11-28 13:44:48.446923][INFO][test_dist.py:228] - iter=22 dt=0.003732 dtf=0.000822 dtb=0.002910 loss=639.229980 sps=17149.966074\n[2024-11-28 13:44:48.451965][INFO][test_dist.py:228] - iter=23 dt=0.003386 dtf=0.000778 dtb=0.002608 loss=627.894897 sps=18902.966756\n[2024-11-28 13:44:48.457006][INFO][test_dist.py:228] - iter=24 dt=0.003367 dtf=0.000807 dtb=0.002560 loss=604.797424 sps=19007.381386\n[2024-11-28 13:44:48.461850][INFO][test_dist.py:228] - iter=25 dt=0.003164 dtf=0.000721 dtb=0.002443 loss=614.561523 sps=20229.778931\n[2024-11-28 13:44:48.466983][INFO][test_dist.py:228] - iter=26 dt=0.003473 dtf=0.000759 dtb=0.002714 loss=617.550781 sps=18428.700435\n[2024-11-28 13:44:48.471925][INFO][test_dist.py:228] - iter=27 dt=0.003289 dtf=0.000758 dtb=0.002531 loss=618.434082 sps=19457.441792\n[2024-11-28 13:44:48.477516][INFO][test_dist.py:228] - iter=28 dt=0.003872 dtf=0.000930 dtb=0.002942 loss=607.261475 sps=16528.336617\n[2024-11-28 13:44:48.482581][INFO][test_dist.py:228] - iter=29 dt=0.003365 dtf=0.000773 dtb=0.002591 loss=601.454590 sps=19021.673645\n[2024-11-28 13:44:48.487622][INFO][test_dist.py:228] - iter=30 dt=0.003288 dtf=0.000825 dtb=0.002463 loss=594.649170 sps=19463.454229\n[2024-11-28 13:44:48.492493][INFO][test_dist.py:228] - iter=31 dt=0.003211 dtf=0.000734 dtb=0.002477 loss=582.087036 sps=19933.062380\n[2024-11-28 13:44:48.497510][INFO][test_dist.py:228] - iter=32 dt=0.003360 dtf=0.000851 dtb=0.002509 loss=582.850586 sps=19050.324061\n[2024-11-28 13:44:48.502534][INFO][test_dist.py:228] - iter=33 dt=0.003299 dtf=0.000751 dtb=0.002547 loss=574.619019 sps=19402.524122\n[2024-11-28 13:44:48.507516][INFO][test_dist.py:228] - iter=34 dt=0.003318 dtf=0.000843 dtb=0.002475 loss=571.530273 sps=19291.396984\n[2024-11-28 13:44:48.512324][INFO][test_dist.py:228] - iter=35 dt=0.003162 dtf=0.000718 dtb=0.002444 loss=569.056335 sps=20239.766403\n[2024-11-28 13:44:48.517314][INFO][test_dist.py:228] - iter=36 dt=0.003338 dtf=0.000803 dtb=0.002535 loss=570.773315 sps=19171.898987\n[2024-11-28 13:44:48.522111][INFO][test_dist.py:228] - iter=37 dt=0.003111 dtf=0.000712 dtb=0.002399 loss=564.691101 sps=20571.738756\n[2024-11-28 13:44:48.527333][INFO][test_dist.py:228] - iter=38 dt=0.003581 dtf=0.000698 dtb=0.002883 loss=555.157349 sps=17870.995302\n[2024-11-28 13:44:48.532827][INFO][test_dist.py:228] - iter=39 dt=0.003596 dtf=0.000841 dtb=0.002755 loss=542.374756 sps=17796.934508\n[2024-11-28 13:44:48.538391][INFO][test_dist.py:228] - iter=40 dt=0.003673 dtf=0.000872 dtb=0.002801 loss=538.616821 sps=17424.614226\n[2024-11-28 13:44:48.543835][INFO][test_dist.py:228] - iter=41 dt=0.003606 dtf=0.000837 dtb=0.002769 loss=546.055054 sps=17746.977167\n[2024-11-28 13:44:48.548728][INFO][test_dist.py:228] - iter=42 dt=0.003171 dtf=0.000786 dtb=0.002385 loss=541.741455 sps=20183.008810\n[2024-11-28 13:44:48.553392][INFO][test_dist.py:228] - iter=43 dt=0.003091 dtf=0.000675 dtb=0.002415 loss=541.895630 sps=20707.731509\n[2024-11-28 13:44:48.558674][INFO][test_dist.py:228] - iter=44 dt=0.003598 dtf=0.000797 dtb=0.002801 loss=532.636841 sps=17789.399613\n[2024-11-28 13:44:48.563691][INFO][test_dist.py:228] - iter=45 dt=0.003305 dtf=0.000726 dtb=0.002579 loss=527.679077 sps=19363.041186\n[2024-11-28 13:44:48.568927][INFO][test_dist.py:228] - iter=46 dt=0.003472 dtf=0.000776 dtb=0.002696 loss=519.220581 sps=18435.547756\n[2024-11-28 13:44:48.573801][INFO][test_dist.py:228] - iter=47 dt=0.003203 dtf=0.000723 dtb=0.002480 loss=527.749268 sps=19982.521481\n[2024-11-28 13:44:48.578761][INFO][test_dist.py:228] - iter=48 dt=0.003253 dtf=0.000782 dtb=0.002471 loss=524.344238 sps=19672.846752\n[2024-11-28 13:44:48.583369][INFO][test_dist.py:228] - iter=49 dt=0.003042 dtf=0.000652 dtb=0.002390 loss=514.100464 sps=21038.853899\n[2024-11-28 13:44:48.588292][INFO][test_dist.py:228] - iter=50 dt=0.003210 dtf=0.000763 dtb=0.002447 loss=513.998962 sps=19936.401969\n[2024-11-28 13:44:48.593155][INFO][test_dist.py:228] - iter=51 dt=0.003210 dtf=0.000763 dtb=0.002447 loss=506.444519 sps=19937.409848\n[2024-11-28 13:44:48.598482][INFO][test_dist.py:228] - iter=52 dt=0.003648 dtf=0.000781 dtb=0.002868 loss=505.063721 sps=17542.989327\n[2024-11-28 13:44:48.603395][INFO][test_dist.py:228] - iter=53 dt=0.003258 dtf=0.000742 dtb=0.002516 loss=500.011047 sps=19642.561466\n[2024-11-28 13:44:48.608385][INFO][test_dist.py:228] - iter=54 dt=0.003292 dtf=0.000797 dtb=0.002495 loss=508.445740 sps=19439.362133\n[2024-11-28 13:44:48.613115][INFO][test_dist.py:228] - iter=55 dt=0.003151 dtf=0.000699 dtb=0.002452 loss=492.626648 sps=20310.433009\n[2024-11-28 13:44:48.618036][INFO][test_dist.py:228] - iter=56 dt=0.003251 dtf=0.000727 dtb=0.002524 loss=487.402435 sps=19684.735824\n[2024-11-28 13:44:48.623122][INFO][test_dist.py:228] - iter=57 dt=0.003449 dtf=0.000979 dtb=0.002469 loss=474.962097 sps=18556.851343\n[2024-11-28 13:44:48.628167][INFO][test_dist.py:228] - iter=58 dt=0.003343 dtf=0.000811 dtb=0.002532 loss=479.064941 sps=19143.536594\n[2024-11-28 13:44:48.633070][INFO][test_dist.py:228] - iter=59 dt=0.003256 dtf=0.000787 dtb=0.002468 loss=471.197083 sps=19658.706785\n[2024-11-28 13:44:48.638373][INFO][test_dist.py:228] - iter=60 dt=0.003548 dtf=0.000853 dtb=0.002696 loss=469.964081 sps=18037.965649\n[2024-11-28 13:44:48.643270][INFO][test_dist.py:228] - iter=61 dt=0.003225 dtf=0.000736 dtb=0.002489 loss=476.972076 sps=19844.166872\n[2024-11-28 13:44:48.648256][INFO][test_dist.py:228] - iter=62 dt=0.003214 dtf=0.000745 dtb=0.002469 loss=463.572174 sps=19912.478524\n[2024-11-28 13:44:48.652939][INFO][test_dist.py:228] - iter=63 dt=0.003095 dtf=0.000683 dtb=0.002411 loss=462.910156 sps=20679.849741\n[2024-11-28 13:44:48.657892][INFO][test_dist.py:228] - iter=64 dt=0.003239 dtf=0.000746 dtb=0.002492 loss=457.325439 sps=19762.175344\n[2024-11-28 13:44:48.662903][INFO][test_dist.py:228] - iter=65 dt=0.003293 dtf=0.000729 dtb=0.002563 loss=453.347168 sps=19438.021843\n[2024-11-28 13:44:48.667970][INFO][test_dist.py:228] - iter=66 dt=0.003276 dtf=0.000788 dtb=0.002488 loss=450.351135 sps=19534.356115\n[2024-11-28 13:44:48.672824][INFO][test_dist.py:228] - iter=67 dt=0.003192 dtf=0.000735 dtb=0.002457 loss=450.714233 sps=20047.789409\n[2024-11-28 13:44:48.677882][INFO][test_dist.py:228] - iter=68 dt=0.003330 dtf=0.000799 dtb=0.002530 loss=440.284546 sps=19220.840096\n[2024-11-28 13:44:48.682532][INFO][test_dist.py:228] - iter=69 dt=0.003081 dtf=0.000663 dtb=0.002418 loss=444.536011 sps=20770.230742\n[2024-11-28 13:44:48.687492][INFO][test_dist.py:228] - iter=70 dt=0.003307 dtf=0.000766 dtb=0.002541 loss=446.201233 sps=19354.965715\n[2024-11-28 13:44:48.692350][INFO][test_dist.py:228] - iter=71 dt=0.003225 dtf=0.000737 dtb=0.002488 loss=427.167328 sps=19845.047963\n[2024-11-28 13:44:48.697422][INFO][test_dist.py:228] - iter=72 dt=0.003415 dtf=0.000881 dtb=0.002534 loss=434.620087 sps=18740.536560\n[2024-11-28 13:44:48.702393][INFO][test_dist.py:228] - iter=73 dt=0.003299 dtf=0.000740 dtb=0.002559 loss=425.558777 sps=19402.652860\n[2024-11-28 13:44:48.707240][INFO][test_dist.py:228] - iter=74 dt=0.003180 dtf=0.000789 dtb=0.002391 loss=428.168945 sps=20126.919392\n[2024-11-28 13:44:48.712103][INFO][test_dist.py:228] - iter=75 dt=0.003322 dtf=0.000680 dtb=0.002642 loss=417.153503 sps=19263.558998\n[2024-11-28 13:44:48.717120][INFO][test_dist.py:228] - iter=76 dt=0.003405 dtf=0.000787 dtb=0.002618 loss=412.435059 sps=18794.204421\n[2024-11-28 13:44:48.722012][INFO][test_dist.py:228] - iter=77 dt=0.003208 dtf=0.000722 dtb=0.002487 loss=426.690186 sps=19947.873515\n[2024-11-28 13:44:48.727040][INFO][test_dist.py:228] - iter=78 dt=0.003330 dtf=0.000775 dtb=0.002554 loss=404.138733 sps=19220.615648\n[2024-11-28 13:44:48.731946][INFO][test_dist.py:228] - iter=79 dt=0.003218 dtf=0.000757 dtb=0.002461 loss=396.998413 sps=19886.330391\n[2024-11-28 13:44:48.736956][INFO][test_dist.py:228] - iter=80 dt=0.003362 dtf=0.000818 dtb=0.002544 loss=405.073059 sps=19036.951133\n[2024-11-28 13:44:48.742154][INFO][test_dist.py:228] - iter=81 dt=0.003309 dtf=0.000840 dtb=0.002468 loss=408.205780 sps=19341.447610\n[2024-11-28 13:44:48.747100][INFO][test_dist.py:228] - iter=82 dt=0.003301 dtf=0.000801 dtb=0.002500 loss=391.203918 sps=19389.697222\n[2024-11-28 13:44:48.752235][INFO][test_dist.py:228] - iter=83 dt=0.003488 dtf=0.000732 dtb=0.002756 loss=401.911407 sps=18347.650097\n[2024-11-28 13:44:48.757468][INFO][test_dist.py:228] - iter=84 dt=0.003567 dtf=0.000886 dtb=0.002681 loss=390.872192 sps=17942.862497\n[2024-11-28 13:44:48.762431][INFO][test_dist.py:228] - iter=85 dt=0.003272 dtf=0.000769 dtb=0.002502 loss=390.741089 sps=19562.065370\n[2024-11-28 13:44:48.767527][INFO][test_dist.py:228] - iter=86 dt=0.003390 dtf=0.000795 dtb=0.002596 loss=393.982513 sps=18877.408330\n[2024-11-28 13:44:48.772363][INFO][test_dist.py:228] - iter=87 dt=0.003198 dtf=0.000727 dtb=0.002471 loss=378.682495 sps=20014.348794\n[2024-11-28 13:44:48.777779][INFO][test_dist.py:228] - iter=88 dt=0.003666 dtf=0.000914 dtb=0.002752 loss=378.739502 sps=17459.234394\n[2024-11-28 13:44:48.783160][INFO][test_dist.py:228] - iter=89 dt=0.003529 dtf=0.000832 dtb=0.002697 loss=382.028931 sps=18136.158201\n[2024-11-28 13:44:48.788498][INFO][test_dist.py:228] - iter=90 dt=0.003442 dtf=0.000809 dtb=0.002633 loss=371.271118 sps=18594.284077\n[2024-11-28 13:44:48.793524][INFO][test_dist.py:228] - iter=91 dt=0.003358 dtf=0.000754 dtb=0.002603 loss=371.135925 sps=19060.348912\n[2024-11-28 13:44:48.798593][INFO][test_dist.py:228] - iter=92 dt=0.003336 dtf=0.000791 dtb=0.002545 loss=368.860168 sps=19183.369504\n[2024-11-28 13:44:48.803491][INFO][test_dist.py:228] - iter=93 dt=0.003227 dtf=0.000725 dtb=0.002502 loss=371.283356 sps=19831.370522\n[2024-11-28 13:44:48.808397][INFO][test_dist.py:228] - iter=94 dt=0.003250 dtf=0.000769 dtb=0.002481 loss=362.983154 sps=19693.397864\n[2024-11-28 13:44:48.813075][INFO][test_dist.py:228] - iter=95 dt=0.003098 dtf=0.000703 dtb=0.002396 loss=365.535828 sps=20656.015873\n[2024-11-28 13:44:48.818465][INFO][test_dist.py:228] - iter=96 dt=0.003581 dtf=0.000872 dtb=0.002709 loss=344.663239 sps=17873.310048\n[2024-11-28 13:44:48.823831][INFO][test_dist.py:228] - iter=97 dt=0.003509 dtf=0.000834 dtb=0.002675 loss=361.620361 sps=18238.825661\n[2024-11-28 13:44:48.828930][INFO][test_dist.py:228] - iter=98 dt=0.003326 dtf=0.000804 dtb=0.002522 loss=347.258301 sps=19245.190902\n[2024-11-28 13:44:48.834103][INFO][test_dist.py:228] - iter=99 dt=0.003474 dtf=0.000740 dtb=0.002733 loss=346.517212 sps=18424.412945\nFailed to download font: IBM Plex Sans, skipping!\nFailed to download font: IBM Plex Sans Condensed, skipping!\nFailed to download font: IBM Plex Serif, skipping!\n[2024-11-28 13:44:50.885911][INFO][history.py:696] - Saving train_iter plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n[2024-11-28 13:44:51.498182][INFO][history.py:696] - Saving train_dt plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n[2024-11-28 13:44:51.758706][INFO][history.py:696] - Saving train_dtf plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n[2024-11-28 13:44:52.022463][INFO][history.py:696] - Saving train_dtb plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n[2024-11-28 13:44:52.309521][INFO][history.py:696] - Saving train_loss plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\n[2024-11-28 13:44:52.562425][INFO][history.py:696] - Saving train_sps plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/mplot\ntrain_iter [2024-11-28-134452]\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n99.0\u2524                                                                 \u2597\u2584\u2584\u2580\u2502\n\u2502                                                              \u2584\u259e\u2580\u2598   \u2502\n\u2502                                                          \u2584\u2584\u2580\u2580       \u2502\n82.7\u2524                                                      \u2584\u2584\u2580\u2580           \u2502\n\u2502                                                  \u2597\u2584\u259e\u2580               \u2502\n\u2502                                              \u2584\u2584\u2580\u2580\u2598                  \u2502\n66.3\u2524                                          \u2597\u2584\u2580\u2580                       \u2502\n\u2502                                      \u2597\u2584\u259e\u2580\u2598                          \u2502\n50.0\u2524                                  \u2597\u2584\u259e\u2580\u2598                              \u2502\n\u2502                               \u2584\u2584\u2580\u2598                                  \u2502\n\u2502                          \u2597\u2584\u259e\u2580\u2580                                      \u2502\n33.7\u2524                       \u2584\u259e\u2580\u2598                                          \u2502\n\u2502                   \u2584\u2584\u2580\u2580                                              \u2502\n\u2502              \u2597\u2584\u2584\u2580\u2580                                                  \u2502\n17.3\u2524           \u2584\u2584\u259e\u2598                                                      \u2502\n\u2502       \u2584\u2584\u2580\u2580                                                          \u2502\n\u2502   \u2597\u2584\u2580\u2580                                                              \u2502\n1.0\u2524\u2584\u259e\u2580\u2598                                                                 \u2502\n\u2514\u2500\u252c\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2518\n2 5  11 16 20   27 31 36   43  48 53 57 61  68 71  78 81 86 91   98\ntrain_iter                        train/iter\n[2024-11-28 13:44:52.868990][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_iter.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_iter.txt\ntrain_dt [2024-11-28-134452]\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n0.0197\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n0.0169\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n0.0142\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n0.0114\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n0.0086\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n0.0058\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u259a      \u2596          \u2597                                                \u2502\n0.0030\u2524 \u259a\u2584\u2584\u2584\u2584\u259e\u259d\u2580\u2580\u2580\u2580\u2584\u2580\u2580\u2580\u2584\u2580\u2598\u2580\u2584\u2580\u2580\u2584\u259a\u2580\u2580\u259a\u2584\u2580\u2580\u2584\u2584\u2584\u259e\u2584\u259a\u2584\u2580\u2584\u259a\u2584\u2584\u259e\u2584\u259e\u2584\u259a\u2580\u259a\u2580\u259a\u259e\u259e\u2580\u2580\u2580\u259e\u2584\u2580\u2580\u2580\u259a\u2584\u259e\u2580\u2580\u2502\n\u2514\u2500\u252c\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2518\n2 5  11 16 20   27 32 36  43  48 53   61   68  74   81 86  91  98\ntrain_dt                           train/iter\n[2024-11-28 13:44:52.888254][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dt.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dt.txt\ntrain_dtf [2024-11-28-134452]\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n0.00296\u2524\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n0.00257\u2524\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n0.00219\u2524\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n0.00181\u2524\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n0.00142\u2524\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n0.00104\u2524\u258c                                                                 \u2502\n\u2502\u258c            \u2597    \u2596                  \u259f                 \u2597  \u2596       \u2502\n\u2502\u259d\u2596\u2597   \u2597\u259e\u2584\u2584\u2584\u2584\u2597\u2598\u259a\u2584\u2597\u259f\u259a\u259f\u259e\u2584\u258c\u2597 \u259e\u2580\u2584\u2597 \u2596\u2597 \u2584\u2596\u2597 \u259b\u2584\u259f   \u2597 \u2596\u2596\u259f \u2596\u2596\u2597\u2584\u2580\u2596\u259b\u2584\u259f\u259d\u259a\u2584\u2596\u2596\u259e\u259a\u2596\u2502\n0.00065\u2524 \u259d\u2598\u2580\u2580\u2580\u2598     \u2580   \u2598   \u2598 \u259d\u2598\u2580  \u259d\u258c\u2580\u259d\u2580\u259e \u259d\u2598\u2580\u2598  \u2580\u259a\u2580\u2598\u2580\u259c\u259d\u2598\u2580\u259c\u259d\u2598  \u259d\u2598 \u259d   \u259d\u259d\u2598 \u259d\u2502\n\u2514\u2500\u252c\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2518\n2 5  11 16 20  27 31 36   43 48 53 57 61  68  74   81 86  91  98\ntrain_dtf                           train/iter\n[2024-11-28 13:44:52.904574][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dtf.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dtf.txt\ntrain_dtb [2024-11-28-134452]\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n0.0168\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n0.0144\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n0.0120\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n0.0096\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n0.0072\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n0.0048\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u259a      \u2596                                                           \u2502\n0.0024\u2524 \u259a\u2584\u2584\u2584\u2584\u259e\u259d\u2580\u2580\u2584\u259e\u2584\u259a\u259e\u259a\u2584\u259a\u259e\u259a\u2584\u2584\u2584\u2584\u2584\u2580\u2580\u259a\u2584\u2580\u2580\u2584\u2584\u2584\u259e\u2584\u2584\u2584\u2584\u2584\u259a\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2580\u259a\u2584\u2584\u2584\u259e\u2580\u259e\u2584\u2580\u2580\u259a\u2584\u2584\u259e\u259a\u259e\u2502\n\u2514\u2500\u252c\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2518\n2 5  11 16 20   27 32 36  43  48 53   61   68  74   81 86  91  98\ntrain_dtb                          train/iter\n[2024-11-28 13:44:52.920733][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dtb.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_dtb.txt\ntrain_loss [2024-11-28-134452]\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n1821.1\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n1575.1\u2524\u258c                                                                  \u2502\n\u2502\u258c                                                                  \u2502\n\u2502\u259a                                                                  \u2502\n1329.0\u2524\u2590                                                                  \u2502\n\u2502\u259d\u2596                                                                 \u2502\n1082.9\u2524 \u258c                                                                 \u2502\n\u2502 \u2590                                                                 \u2502\n\u2502 \u259d\u2596                                                                \u2502\n836.8\u2524  \u259a                                                                \u2502\n\u2502   \u2580\u2596                                                              \u2502\n\u2502    \u259d\u2580\u259a\u2584\u2584\u2584 \u2596                                                       \u2502\n590.7\u2524          \u2580\u259d\u2580\u2580\u2580\u259a\u2584\u2584\u2584\u2584\u2584\u2596                                             \u2502\n\u2502                     \u259d\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2584\u2584\u2584\u2584\u2584\u2584\u2584\u2584                              \u2502\n\u2502                                     \u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u259a\u2584\u2584\u2584\u2584\u2584\u2584  \u2597            \u2502\n344.7\u2524                                                    \u2580\u2580\u2598\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2580\u2584\u2584\u2584\u2584\u2502\n\u2514\u2500\u252c\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2518\n2 5  11 16 20   27 32 36  43  48 53   61   68  74   81 86  91  98\ntrain_loss                         train/iter\n[2024-11-28 13:44:52.939625][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_loss.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_loss.txt\ntrain_sps [2024-11-28-134452]\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n21038.9\u2524  \u2596\u2597\u2584\u259e\u2596                 \u2596   \u2596  \u2597\u259a   \u2596    \u2597   \u2597                 \u2596  \u2502\n\u2502 \u2590\u259d\u2598  \u258c   \u2596\u2597\u258c  \u2597\u258c\u2597 \u2597\u258c\u2597\u259e\u259f\u258c  \u259e\u258c\u2597\u259e\u259f \u259c \u259f\u259d\u2596 \u2584\u2580\u2580\u2584\u2584\u259a\u259b\u2584\u258c\u2584\u259a\u2597\u2599\u259a\u2597\u2596 \u2596\u259f   \u259e\u259e\u258c  \u2502\n\u2502 \u258c    \u258c \u2584\u259e\u259d\u259f\u259a\u2584\u259e\u2580\u259a\u259c\u259e\u2598\u259d\u2598 \u259d\u258c \u2597\u2598\u2599\u2580\u258c  \u2590\u2590  \u259a\u2580\u2588     \u2598 \u259c  \u2598\u259d \u2598\u259d\u259f\u259d\u259c \u2597\u2580\u2598 \u258c\u2597\u259a\u2502\n18073.5\u2524 \u258c    \u258c\u2590     \u2590\u258c  \u2590\u258c     \u259d\u2580\u259e \u259d    \u259d\u258c    \u259d               \u259d \u259d\u2584\u2598   \u259d\u2598 \u2502\n\u2502\u2590     \u259a\u2598      \u2598  \u259d\u258c                                               \u2502\n\u2502\u2590                                                                 \u2502\n15108.1\u2524\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n12142.7\u2524\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n9177.3\u2524\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n6211.9\u2524\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n\u2502\u258c                                                                 \u2502\n3246.6\u2524\u258c                                                                 \u2502\n\u2514\u2500\u252c\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2518\n2 5  11 16 20  27 31 36   43 48 53 57 61  68  74   81 86  91  98\ntrain_sps                           train/iter\n[2024-11-28 13:44:52.955997][INFO][plot.py:220] - Appending plot to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_sps.txt\ntext saved in /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/test-dist-plots/tplot/train_sps.txt\n[2024-11-28 13:44:53.002178][INFO][test_dist.py:246] - dataset=&lt;xarray.Dataset&gt; Size: 5kB\nDimensions:     (draw: 99)\nCoordinates:\n* draw        (draw) int64 792B 0 1 2 3 4 5 6 7 8 ... 91 92 93 94 95 96 97 98\nData variables:\ntrain_iter  (draw) int64 792B 1 2 3 4 5 6 7 8 9 ... 92 93 94 95 96 97 98 99\ntrain_dt    (draw) float64 792B 0.01971 0.004083 ... 0.003326 0.003474\ntrain_dtf   (draw) float64 792B 0.002959 0.0008221 ... 0.0008038 0.0007404\ntrain_dtb   (draw) float64 792B 0.01675 0.003261 ... 0.002522 0.002733\ntrain_loss  (draw) float32 396B 1.821e+03 1.348e+03 ... 347.3 346.5\ntrain_sps   (draw) float64 792B 3.247e+03 1.567e+04 ... 1.925e+04 1.842e+04\n\n_     ._   __/__   _ _  _  _ _/_   Recorded: 13:44:35  Samples:  2127\n/_//_/// /_\\ / //_// / //_'/ //     Duration: 17.440    CPU time: 29.088\n/   _/                      v5.0.0\n\nProfile at /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/src/ezpz/profile.py:101\n\n17.440 &lt;module&gt;  ezpz/test_dist.py:1\n\u2514\u2500 17.440 main  ezpz/test_dist.py:177\n\u251c\u2500 10.558 build_model_and_optimizer  ezpz/test_dist.py:136\n\u2502  \u2514\u2500 10.547 DistributedDataParallel.__init__  torch/nn/parallel/distributed.py:622\n\u2502     \u2514\u2500 10.502 _verify_param_shape_across_processes  torch/distributed/utils.py:266\n\u2502        \u2514\u2500 10.502 PyCapsule._verify_params_across_processes  &lt;built-in&gt;\n\u251c\u2500 3.256 History.plot_all  ezpz/history.py:636\n\u2502  \u251c\u2500 1.809 savefig  matplotlib/pyplot.py:974\n\u2502  \u2502     [38 frames hidden]  matplotlib, PIL, &lt;built-in&gt;, numpy\n\u2502  \u251c\u2500 0.895 &lt;module&gt;  seaborn/__init__.py:1\n\u2502  \u2502     [8 frames hidden]  seaborn, scipy\n\u2502  \u251c\u2500 0.227 History.get_dataset  ezpz/history.py:752\n\u2502  \u2502  \u2514\u2500 0.183 History.to_DataArray  ezpz/history.py:712\n\u2502  \u2502     \u2514\u2500 0.183 DataArray.__init__  xarray/core/dataarray.py:437\n\u2502  \u2502           [5 frames hidden]  xarray\n\u2502  \u2514\u2500 0.179 make_ridgeplots  ezpz/plot.py:900\n\u251c\u2500 2.016 _forward_step  ezpz/test_dist.py:193\n\u2502  \u2514\u2500 1.963 DistributedDataParallel._wrapped_call_impl  torch/nn/modules/module.py:1528\n\u2502        [4 frames hidden]  torch\n\u2502           1.945 Network._call_impl  torch/nn/modules/module.py:1534\n\u2502           \u2514\u2500 1.943 Network.forward  ezpz/test_dist.py:128\n\u2502              \u2514\u2500 1.943 Sequential._wrapped_call_impl  torch/nn/modules/module.py:1528\n\u2502                    [6 frames hidden]  torch, &lt;built-in&gt;\n\u251c\u2500 0.716 &lt;module&gt;  ambivalent/__init__.py:1\n\u2502     [20 frames hidden]  ambivalent, requests, urllib3, http, ...\n\u2514\u2500 0.495 _backward_step  ezpz/test_dist.py:198\n\u2514\u2500 0.457 Tensor.backward  torch/_tensor.py:466\n[3 frames hidden]  torch, &lt;built-in&gt;\n\n\n[2024-11-28 13:44:54.356012][INFO][profile.py:115] - Saving pyinstrument profile output to: /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/ezpz_pyinstrument_profiles\n[2024-11-28 13:44:54.356642][INFO][profile.py:123] - PyInstrument profile saved (as html) to:  /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-11-28-134454.html\n[2024-11-28 13:44:54.357100][INFO][profile.py:131] - PyInstrument profile saved (as text) to:  /lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/ezpz_pyinstrument_profiles/pyinstrument-profile-2024-11-28-134454.txt\n[2024-11-28 13:44:54.716119][INFO][profile.py:143] - Finished with pyinstrument profiler. Took: 17.44008s\n[2024-11-28 13:44:54.717891][INFO][test_dist.py:269] - [0] runtime=73.419312s\nwandb: \ud83d\ude80 View run driven-wind-683 at: https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/4mwyy84l\nwandb: Find logs at: ../../../../../../lus/gila/projects/Aurora_deployment/foremans/projects/saforem2/ezpz/wandb/run-20241128_134434-4mwyy84l/logs\nApplication ecd9868b resources: utime=2078s stime=374s maxrss=2509188KB inblock=786752 oublock=12104 minflt=13378945 majflt=181980 nvcsw=1704995 nivcsw=216931\ntook: 0h:01m:32s\n</code></pre>"},{"location":"hf-trainer/","title":"Language Model Training with \ud83c\udf4b <code>ezpz</code> and \ud83e\udd17 HF Trainer","text":"<p>The <code>src/ezpz/hf_trainer.py</code> module provides a mechanism for distributed training with \ud83e\udd17 huggingface / transformers.</p> <p>In particular, it allows for distributed training using the <code>transformers.Trainer</code> object with any<sup>1</sup> (compatible) combination of {<code>models</code>, <code>datasets</code>}.</p>"},{"location":"hf-trainer/#getting-started","title":"\ud83d\udc23 Getting Started","text":"<ol> <li> <p>\ud83c\udfe1 Setup environment (on ANY {Intel, NVIDIA, AMD} accelerator)</p> <pre><code>source &lt;(curl -s 'https://raw.githubusercontent.com/saforem2/ezpz/refs/heads/main/src/ezpz/bin/utils.sh')\nezpz_setup_env\n</code></pre> </li> <li> <p>\ud83d\udce6 Install dependencies:</p> <ol> <li> <p>Install \ud83c\udf4b <code>ezpz</code> (from GitHub):</p> <pre><code>python3 -m pip install \"git+https://github.com/saforem2/ezpz\" --require-virtualenv\n</code></pre> </li> <li> <p>Update {<code>transformers</code>, <code>evaluate</code>}:</p> <pre><code>python3 -m pip install --upgrade transformers evaluate\n</code></pre> </li> </ol> </li> <li> <p>\ud83d\ude80 Launch training:</p> <pre><code>python3 -m ezpz.launch -m ezpz.hf_trainer \\\n  --dataset_name stanfordnlp/imdb \\\n  --model_name_or_path meta-llama/Llama-3.2-1B \\\n  --bf16 \\\n  --do_train \\\n  --report-to=wandb \\\n  --logging-steps=1 \\\n  --include-tokens-per-second=true \\\n  --auto-find-batch-size=true \\\n  --output_dir=outputs/ezpz-hf-trainer/$(date \"+%Y-%m-%d-%H%M%S\") \\\n  --ddp-backend=$(echo \"$([ $(ezpz_get_machine_name)==\"aurora\" ] &amp;&amp; echo \"ccl\" || echo \"nccl\")\")\n</code></pre> <ul> <li>\ud83e\ude84 Magic: <p>Behind the scenes, this will \ud83e\ude84 automagically determine   the specifics of the running job, and use this information to   construct (and subsequently run) the appropriate:  </p> <pre><code>mpiexec &lt;mpi-args&gt; $(which python3) &lt;cmd-to-launch&gt;\n</code></pre> <p>across all of our available accelerators.</p> <ul> <li>\u2795 Tip: <p>Call:</p> <pre><code>python3 -m ezpz.hf_trainer --help\n</code></pre> <p>to see the full list of supported arguments.</p> <p>In particular, any <code>transformers.TrainingArguments</code> should be supported.</p> </li>"},{"location":"hf-trainer/#deepspeed-support","title":"\ud83d\ude80 DeepSpeed Support","text":"<p>Additionally, DeepSpeed is fully supported and can be configured by specifying the path to a compatible DeepSpeed Config JSON file, e.g.:</p> <ol> <li> <p>Build a DeepSpeed config:</p> <pre><code>python3 -c 'import ezpz; ezpz.utils.write_deepspeed_zero12_auto_config(zero_stage=2)'\n</code></pre> </li> <li> <p>Train:</p> <pre><code>python3 -m ezpz.launch -m ezpz.hf_trainer \\\n  --dataset_name stanfordnlp/imdb \\\n  --model_name_or_path meta-llama/Llama-3.2-1B \\\n  --bf16 \\\n  --do_train \\\n  --report-to=wandb \\\n  --logging-steps=1 \\\n  --include-tokens-per-second=true \\\n  --auto-find-batch-size=true \\\n  --deepspeed=ds_configs/deepspeed_zero2_auto_config.json\n</code></pre> </li> </ol> <p>\ud83d\ude0e 2 ez</p> <ol> <li> <p>See the full list of supported models at: https://hf.co/models?filter=text-generation \u21a9</p> </li> </ol>"},{"location":"init/","title":"\ud83c\udfe1 Home","text":"<p>Documentation for \ud83c\udf4b <code>ezpz</code>.</p>"},{"location":"launch/","title":"\ud83d\ude80 Launch","text":"<p>Launch python from python.</p>"},{"location":"launch/#example","title":"\ud83d\udcdd Example","text":"<pre><code>source &lt;(curl -s https://raw.githubusercontent.com/saforem2/ezpz/refs/heads/main/src/ezpz/bin/utils.sh) &amp;&amp; ezpz_setup_env\npython3 -m pip install \"git+https://github.com/saforem2/ezpz\"\npython3 -m ezpz.launch -m ezpz.test_dist\n</code></pre> <p>This will launch <code>ezpz/test_dist.py</code> across all available resources in your {PBS, Slurm} job.</p> Sequence Diagram <pre><code>sequenceDiagram\n  participant User\n  participant ezpz.launch\n  participant Launcher (mpiexec/srun/mpirun)\n  participant Distributed Application (ezpz.test_dist)\n\n  User-&gt;&gt;ezpz.launch: Executes `python3 -m ezpz.launch -m ezpz.test_dist`\n  ezpz.launch-&gt;&gt;Launcher (mpiexec/srun/mpirun): Detects environment and builds launch command\n  Launcher (mpiexec/srun/mpirun)-&gt;&gt;Distributed Application (ezpz.test_dist): Launches distributed training job\n  Distributed Application (ezpz.test_dist)-&gt;&gt;Distributed Application (ezpz.test_dist): Performs distributed computation\n  Distributed Application (ezpz.test_dist)--&gt;&gt;User: Training progress and metrics (via WandB)\n</code></pre> \ud83e\ude84 Magic <p>Explicitly, this will use the default \"launcher\" depending on availability:</p> <ul> <li>ALCF (PBS Pro): <code>mpiexec</code></li> <li>Slurm: <code>srun</code></li> <li>Unknown: <code>mpirun</code></li> </ul> <p>and automatically pull in the specifics about the currently active job when building the appropriate <code>{srun, mpi{exec,run}}</code> command.</p> <ul> <li>For example, on any of the ALCF systems, it will automatically:</li> <li>Identify <code>\"${PBS_NODEFILE}\"</code> (by looking at <code>hostname</code> of currently active node)</li> <li>Use this to calculate: - <code>NHOSTS</code> - <code>NGPUS_PER_HOST</code> - <code>WORLD_SIZE</code> <code>= NGPUS = NHOSTS * NGPUS_PER_HOST</code></li> <li>With this information, we can construct the full <code>mpiexec ...</code>   command needed to launch our distributed application, e.g.:</li> </ul> <pre><code>python3 -c 'import ezpz.pbs; print(ezpz.pbs.build_launch_cmd())'\n# on 2 nodes of Aurora @ ALCF:\n# mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/3878985.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\n</code></pre>"},{"location":"launch/#aurora","title":"\ud83c\udf0c Aurora","text":"<ul> <li>Command:</li> </ul> <pre><code>python3 -m ezpz.launch -m ezpz.test_dist\n</code></pre> <ul> <li> <p>Output: <pre><code>#[\ud83d\udc0d aurora_nre_models_frameworks-2024.2.1_u1](\ud83d\udc7b aurora_nre_models_frameworks-2024.2.1_u1)\n#[08:54:56 AM][x4317c7s7b0n0][/flare/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856]\n$ python3 -m ezpz.launch -m ezpz.test_dist --tp 4 --pp 3\n[2025-04-01 08:55:21,413] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:55:29,530] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:06][I][ezpz/launch:56:__main__] Job ID: 3842171\n[2025-04-01 08:56:08][I][ezpz/launch:62:__main__] Node file: /var/spool/pbs/aux/3842171.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n[2025-04-01 08:56:08][I][ezpz/launch:72:__main__] Building command to execute from: '{launch_cmd}' + '{python}' + '{cmd_to_launch}'\n\nlaunch_cmd=mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/3842171.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\npython=/lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/venvs/aurora_nre_models_frameworks-2024.2.1_u1/bin/python3\ncmd_to_launch=-m ezpz.test_dist --tp 4 --pp 3\n\n[2025-04-01 08:56:08][I][ezpz/launch:90:__main__] Evaluating:\nmpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/3842171.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16 /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/venvs/aurora_nre_models_frameworks-2024.2.1_u1/bin/python3 -m ezpz.test_dist --tp 4 --pp 3\nDisabling local launch: multi-node application\nConnected to tcp://x4317c7s6b0n0.hostmgmt2317.cm.aurora.alcf.anl.gov:7919\nLaunching application 7ceb32d4-e849-4fc3-ad6d-abcb7bad3494\n[2025-04-01 08:56:13,276] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,310] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,311] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,312] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,313] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,314] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,320] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,328] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,328] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,336] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,497] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,497] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,497] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,497] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,497] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,497] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,497] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,497] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,498] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,498] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,848] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,849] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,894] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:56:13,895] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,428] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,447] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,451] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,454] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,455] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,456] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,458] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,458] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,459] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,459] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,459] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:35,459] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,144] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,144] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,148] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,148] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,148] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,148] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,148] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,148] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,148] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,149] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,148] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:57:48,149] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to xpu (auto detect)\n[2025-04-01 08:58:40][I][ezpz/dist:557] Using get_torch_device_type()='xpu' with backend='ccl'\n[2025-04-01 08:58:45][I][tp/__init__:148:ezpz.tp] TP: 4, PP: 3, CP: 1, DP: 2\n[2025-04-01 08:58:45][I][ezpz/dist:873] Using device='xpu' with backend='ddp' + 'ccl' for distributed training.\n2025:04:01-08:58:45:(123380) |CCL_WARN| value of CCL_PROCESS_LAUNCHER changed to be pmix (default:hydra)\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][ 8/23] [pp:2/2][tp:0/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][ 7/23] [pp:1/2][tp:3/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][ 4/23] [pp:1/2][tp:0/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][ 5/23] [pp:1/2][tp:1/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][ 6/23] [pp:1/2][tp:2/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][10/23] [pp:2/2][tp:2/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][ 9/23] [pp:2/2][tp:1/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][11/23] [pp:2/2][tp:3/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][20/23] [pp:2/2][tp:0/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][16/23] [pp:1/2][tp:0/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][17/23] [pp:1/2][tp:1/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][18/23] [pp:1/2][tp:2/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][19/23] [pp:1/2][tp:3/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][22/23] [pp:2/2][tp:2/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][23/23] [pp:2/2][tp:3/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][21/23] [pp:2/2][tp:1/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][ 0/23] [pp:0/2][tp:0/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][ 2/23] [pp:0/2][tp:2/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][ 1/23] [pp:0/2][tp:1/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s6b0n0'][ 3/23] [pp:0/2][tp:3/3][dp:0/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][12/23] [pp:0/2][tp:0/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][14/23] [pp:0/2][tp:2/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][13/23] [pp:0/2][tp:1/3][dp:1/1]\n[2025-04-01 08:58:45][I][ezpz/dist:923] ['x4317c7s7b0n0'][15/23] [pp:0/2][tp:3/3][dp:1/1]\n[2025-04-01 08:58:46][I][ezpz/test_dist:395:__main__] model=\nNetwork(\n  (layers): Sequential(\n    (0): Linear(in_features=128, out_features=1024, bias=True)\n    (1): Linear(in_features=1024, out_features=512, bias=True)\n    (2): Linear(in_features=512, out_features=256, bias=True)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): Linear(in_features=128, out_features=128, bias=True)\n  )\n)\n[2025-04-01 08:58:58][I][ezpz/dist:1100] Setting up wandb from rank=0\n[2025-04-01 08:58:58][I][ezpz/dist:1101] Using=WB PROJECT=ezpz.test_dist\nwandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\nwandb: Currently logged in as: foremans (aurora_gpt) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.19.8\nwandb: Run data is saved locally in /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/wandb/run-20250401_085858-q1ob71v0\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run young-brook-1229\nwandb: \u2b50\ufe0f View project at https://wandb.ai/aurora_gpt/ezpz.test_dist\nwandb: \ud83d\ude80 View run at https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/q1ob71v0\n[2025-04-01 08:58:59][I][ezpz/dist:1129] W&amp;B RUN=[young-brook-1229](https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/q1ob71v0)\n[2025-04-01 08:58:59][I][ezpz/dist:299] Updating wandb.run: young-brook-1229 config with \"DIST_INFO\"\n[2025-04-01 08:58:59][I][ezpz/dist:1168] Running on machine='Aurora'\n[2025-04-01 08:58:59][I][ezpz/test_dist:219:__main__] config:\n{\n  \"backend\": \"DDP\",\n  \"batch_size\": 64,\n  \"cp\": 1,\n  \"dtype\": \"bfloat16\",\n  \"input_size\": 128,\n  \"layer_sizes\": [\n    1024,\n    512,\n    256,\n    128\n  ],\n  \"log_freq\": 1,\n  \"output_size\": 128,\n  \"pp\": 3,\n  \"print_freq\": 10,\n  \"pyinstrument_profiler\": false,\n  \"tp\": 4,\n  \"train_iters\": 100,\n  \"warmup\": 2\n}\n[rank23]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank12]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank13]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank16]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank17]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank19]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank22]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank14]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank15]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank18]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank20]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank21]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank4]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank5]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank10]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank11]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank0]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank1]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank2]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank3]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank6]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank7]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank8]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[rank9]:[W reducer.cpp:69] Warning: measureDifference between two events is not supported on XPU backend! (function operator())\n[2025-04-01 08:59:03][I][ezpz/test_dist:192:__main__] Warmup complete at step 2\n[2025-04-01 08:59:03][I][ezpz/test_dist:170:__main__] iter=10 loss=752.000000 dtf=0.000528 dtb=0.001079\n[2025-04-01 08:59:03][I][ezpz/test_dist:170:__main__] iter=20 loss=652.000000 dtf=0.000482 dtb=0.001007\n[2025-04-01 08:59:03][I][ezpz/test_dist:170:__main__] iter=30 loss=596.000000 dtf=0.000475 dtb=0.001008\n[2025-04-01 08:59:03][I][ezpz/test_dist:170:__main__] iter=40 loss=564.000000 dtf=0.000486 dtb=0.000990\n[2025-04-01 08:59:03][I][ezpz/test_dist:170:__main__] iter=50 loss=520.000000 dtf=0.000492 dtb=0.000989\n[2025-04-01 08:59:03][I][ezpz/test_dist:170:__main__] iter=60 loss=494.000000 dtf=0.000476 dtb=0.001019\n[2025-04-01 08:59:03][I][ezpz/test_dist:170:__main__] iter=70 loss=456.000000 dtf=0.000495 dtb=0.000969\n[2025-04-01 08:59:03][I][ezpz/test_dist:170:__main__] iter=80 loss=426.000000 dtf=0.000488 dtb=0.000988\n[2025-04-01 08:59:03][I][ezpz/test_dist:170:__main__] iter=90 loss=396.000000 dtf=0.000496 dtb=0.000966\n[2025-04-01 08:59:03][I][ezpz/history:704] Saving iter plot to: /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/plots/mplot\n[2025-04-01 08:59:04][I][ezpz/history:704] Saving loss plot to: /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/plots/mplot\n[2025-04-01 08:59:04][I][ezpz/history:704] Saving dtf plot to: /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/plots/mplot\n[2025-04-01 08:59:04][I][ezpz/history:704] Saving dtb plot to: /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/plots/mplot\n[2025-04-01 08:59:04][I][ezpz/history:602] Saving tplots to /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot\n                    loss [2025-04-01-085904]\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n1592.0\u2524\u258c                                                   \u2502\n      \u2502\u258c                                                   \u2502\n1389.3\u2524\u258c                                                   \u2502\n      \u2502\u258c                                                   \u2502\n      \u2502\u259a                                                   \u2502\n1186.7\u2524\u2590                                                   \u2502\n      \u2502\u259d\u2596                                                  \u2502\n 984.0\u2524 \u258c                                                  \u2502\n      \u2502 \u259a                                                  \u2502\n 781.3\u2524  \u258c                                                 \u2502\n      \u2502  \u259d\u2580\u259a\u2584\u2584                                             \u2502\n      \u2502       \u2580\u259a\u259a\u259e\u2584\u2584\u2596\u2596                                     \u2502\n 578.7\u2524             \u259d\u259d\u2580\u2580\u2580\u2584\u259a\u2584\u2584\u2584\u2584\u2596 \u2596                         \u2502\n      \u2502                        \u259d\u2580\u259d\u2580\u2580\u2580\u2580\u2580\u259a\u2584\u2584\u2584\u2584\u2584\u2584             \u2502\n 376.0\u2524                                       \u2580\u2580\u2580\u2580\u2580\u2580\u2580\u259a\u2584\u2584\u2584\u2584\u2584\u2502\n      \u2514\u2500\u252c\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2518\n      0 2 6  14 20 25   34 40 47 51 57   67  75  81 87 93\nloss                           iter\ntext saved in /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot/loss.txt\n                      dtf [2025-04-01-085905]\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n0.000671\u2524\u258c                                                 \u2502\n        \u2502\u258c                                 \u2596               \u2502\n0.000637\u2524\u258c   \u2596                            \u2590\u258c               \u2502\n        \u2502\u258c  \u2590\u258c                            \u2590\u258c     \u2596         \u2502\n        \u2502\u258c  \u2590\u258c    \u2597    \u2597    \u259f    \u2597\u258c    \u2596  \u2590\u258c\u2596   \u2590\u258c    \u259f    \u2502\n0.000604\u2524\u258c\u2596\u2596\u2590\u258c    \u2588    \u2588    \u2588    \u2590\u258c   \u2590\u258c  \u2590\u2588\u258c   \u2590\u258c    \u2588    \u2502\n        \u2502\u2588\u2588\u258c\u2590\u258c    \u2588    \u2588    \u2588    \u2590\u258c   \u2590\u258c  \u2590\u2588\u258c   \u2590\u258c    \u2588    \u2502\n0.000570\u2524\u259d\u259c\u2590\u2590\u258c    \u2588    \u2588    \u2588    \u2590\u258c   \u2590\u258c  \u2590\u2588\u258c   \u2590\u258c    \u2588    \u2502\n        \u2502   \u2588\u258c\u259e\u259f  \u2588    \u2588    \u2588    \u2590\u258c   \u2590\u258c\u2597\u258c\u2590\u2588\u258c   \u2590\u258c    \u2588    \u2502\n0.000537\u2524   \u2588\u258c\u258c\u2590  \u258c\u258c\u2597\u2596 \u259b\u2596   \u259b\u2584  \u2596\u258c\u258c   \u2590\u259a\u258c\u258c\u2590\u2588\u258c   \u2590\u259a    \u2588    \u2502\n        \u2502   \u259c\u259a\u258c\u2590\u2597\u2584\u258c\u2599\u2598\u258c\u2596\u258c\u2599\u258c\u2597 \u258c\u2590 \u2590\u258c\u258c\u2590\u2597\u259c \u2590\u259d\u258c\u258c\u259f\u2588\u2599\u258c\u259f\u2597\u2590\u259d\u2596\u2584\u258c \u258c\u258c\u2596\u259e\u258c\u2502\n        \u2502    \u259d\u258c\u259d\u258c\u2590\u258c\u2588 \u259c\u258c\u258c\u259c\u259a\u259b\u2596\u258c\u259d\u259e\u2588\u258c\u258c \u259c\u2590\u259f\u2590  \u2588 \u2588\u259d\u259a\u259c\u2588\u2590 \u259c \u259a\u2596\u258c\u259c\u259d\u258c\u259a\u2502\n0.000503\u2524        \u2590\u258c\u259d  \u259a\u258c   \u258c\u258c  \u259d\u258c\u258c  \u259d\u2588\u2590  \u259d \u259c   \u259c\u2590    \u259a\u258c    \u2502\n        \u2502        \u259d\u258c   \u2590\u258c   \u258c\u258c   \u2599\u2598   \u259d\u259f        \u2590\u259e          \u2502\n0.000470\u2524              \u2598   \u259d    \u259c     \u259d         \u2598          \u2502\n        \u2514\u2500\u252c\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2518\n        0 2 6  14   25   34 40 47 51 57   67  75 81 87 93\ndtf                             iter\ntext saved in /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot/dtf.txt\n                    dtf [2025-04-01-085905]\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n37.0\u2524           \u2588\u2588\u2588\u2588\u2588                                      \u2502\n    \u2502           \u2588\u2588\u2588\u2588\u2588                                      \u2502\n30.8\u2524           \u2588\u2588\u2588\u2588\u2588                                      \u2502\n    \u2502           \u2588\u2588\u2588\u2588\u2588                                      \u2502\n    \u2502           \u2588\u2588\u2588\u2588\u2588                                      \u2502\n24.7\u2524           \u2588\u2588\u2588\u2588\u2588                                      \u2502\n    \u2502           \u2588\u2588\u2588\u2588\u2588                                      \u2502\n18.5\u2524           \u2588\u2588\u2588\u2588\u2588                                      \u2502\n    \u2502     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                      \u2502\n12.3\u2524     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                \u2502\n    \u2502     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                           \u2502\n 6.2\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588           \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588      \u2588\u2588\u2588\u2588\u2588\u2502\n 0.0\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2502\n    \u2514\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2518\n  0.000461    0.000516      0.000570     0.000625  0.000679\nfreq                           dtf\ntext saved in /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot/dtf-hist.txt\n                      dtb [2025-04-01-085905]\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n0.001541\u2524\u258c                             \u2596                   \u2502\n        \u2502\u258c                            \u2590\u258c                   \u2502\n0.001445\u2524\u258c                            \u2590\u258c                   \u2502\n        \u2502\u258c                            \u2590\u258c                   \u2502\n        \u2502\u258c                            \u2590\u258c                   \u2502\n0.001349\u2524\u258c                            \u2590\u258c                   \u2502\n        \u2502\u258c                            \u2590\u258c                   \u2502\n0.001253\u2524\u2590                            \u2590\u258c                  \u2596\u2502\n        \u2502\u2590                            \u2590\u258c                 \u2590\u258c\u2502\n0.001157\u2524\u259d\u2596    \u2597\u258c   \u2596  \u2597\u258c  \u2597          \u2590\u258c                 \u2590\u258c\u2502\n        \u2502 \u259d\u258c  \u2597\u2588\u258c  \u2590\u258c  \u2590\u258c  \u2588        \u2596\u259f\u2590\u258c\u2596                \u2590\u258c\u2502\n        \u2502  \u259a\u2597\u2597\u2598\u259c\u259a \u2597\u259f\u258c  \u259e\u259a\u2597 \u2588\u2597     \u259e\u259f\u258c\u2588\u2590\u259d\u259d\u2596               \u2590\u258c\u2502\n0.001062\u2524   \u2598\u2580   \u259a\u258c\u259d\u259d\u2580\u2596\u258c \u2598\u259c\u2588\u258c\u2580\u2584\u2584\u259f\u2590 \u259d\u259d\u259c\u2590  \u259a\u2596\u2597\u259a\u259e\u2584  \u2584 \u2584\u259a\u2596\u259e\u2584\u259e\u259e\u259a\u2502\n        \u2502        \u259d\u258c   \u259a\u258c   \u259c\u258c   \u2590\u258c    \u2580   \u2590\u2590   \u259c\u2590 \u2580\u259d \u258c\u258c    \u2502\n0.000966\u2524                   \u2598    \u2598         \u259c    \u2580    \u259d\u258c    \u2502\n        \u2514\u2500\u252c\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2518\n        0 2 6  14   25   34 40 47 51 57   67  75 81 87 93\ndtb                             iter\ntext saved in /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot/dtb.txt\n                    dtb [2025-04-01-085905]\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n55.0\u2524     \u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n    \u2502     \u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n45.8\u2524     \u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n    \u2502     \u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n    \u2502     \u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n36.7\u2524     \u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n    \u2502     \u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n27.5\u2524     \u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n    \u2502     \u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n18.3\u2524     \u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                      \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                      \u2502\n 9.2\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                           \u2588\u2588\u2588\u2588\u2588\u2502\n 0.0\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                 \u2588\u2588\u2588\u2588\u2588\u2502\n    \u2514\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2518\n  0.00094      0.00110       0.00125      0.00141   0.00157\nfreq                           dtb\ntext saved in /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot/dtb-hist.txt\n[2025-04-01 08:59:05][I][ezpz/utils:192] Saving dataset to: /lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/outputs/ezpz.test_dist/ezpz.test_dist/train_dataset.h5\n[2025-04-01 08:59:05][I][ezpz/test_dist:186:__main__] dataset=&lt;xarray.Dataset&gt; Size: 3kB\nDimensions:  (draw: 97)\nCoordinates:\n  * draw     (draw) int64 776B 0 1 2 3 4 5 6 7 8 ... 88 89 90 91 92 93 94 95 96\nData variables:\n    iter     (draw) int64 776B 3 4 5 6 7 8 9 10 11 ... 92 93 94 95 96 97 98 99\n    loss     (draw) float32 388B 1.592e+03 1.232e+03 1.048e+03 ... 388.0 378.0\n    dtf      (draw) float64 776B 0.0006705 0.0005739 ... 0.0005295 0.0005092\n    dtb      (draw) float64 776B 0.001541 0.001264 0.00117 ... 0.001247 0.001055\n[2025-04-01 08:59:05][I][ezpz/test_dist:459:__main__] Took: 24.42 seconds\nwandb:\nwandb: \ud83d\ude80 View run young-brook-1229 at: https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/q1ob71v0\nwandb: Find logs at: ../../../../../../../lus/flare/projects/datascience/foremans/projects/saforem2/tmp/2025-04-01-084856/wandb/run-20250401_085858-q1ob71v0/logs\nApplication 7ceb32d4 resources: utime=853s stime=315s maxrss=2431600KB inblock=19633858 oublock=1032 minflt=6598818 majflt=132990 nvcsw=1389710 nivcsw=5263346\n[2025-04-01 08:59:07][I][ezpz/launch:93:__main__] Command took 179.43 seconds to run.\ntook: 0h:04m:01s\n</code></pre>"},{"location":"launch/#polaris","title":"\u2b50 Polaris","text":"<ul> <li>Command:</li> </ul> <pre><code>python3 -m ezpz.launch -m ezpz.test_dist\n</code></pre> <ul> <li> <p>Output: <pre><code>(\ud83d\udc7b 2024-04-29)\n#[09:22:22 AM][x3006c0s19b0n0][/e/d/f/p/s/t/ezpz][\ud83c\udf31 feat/python-launcher][\ud83d\udce6\u2713] [\u23f1\ufe0f 58s]\n$ python3 -m ezpz.launch -m ezpz.test_dist --tp 2 --pp 2\n[2025-04-01 09:22:32,869] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n[WARNING]  sparse_attn requires a torch version &gt;= 1.5 and &lt; 2.0 but detected 2.3\n[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n[2025-04-01 09:22:37][I][ezpz/launch:56:__main__] Job ID: 4094162\n[2025-04-01 09:22:38][I][ezpz/launch:62:__main__] Node file: /var/spool/pbs/aux/4094162.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov\n[2025-04-01 09:22:38][I][ezpz/launch:72:__main__] Building command to execute from: '{launch_cmd}' + '{python}' + '{cmd_to_launch}'\n\nlaunch_cmd=mpiexec --verbose --envall -n 8 -ppn 4 --hostfile /var/spool/pbs/aux/4094162.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16\npython=/lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/venvs/2024-04-29/bin/python3\ncmd_to_launch=-m ezpz.test_dist --tp 2 --pp 2\n\n[2025-04-01 09:22:38][I][ezpz/launch:90:__main__] Evaluating:\nmpiexec --verbose --envall -n 8 -ppn 4 --hostfile /var/spool/pbs/aux/4094162.polaris-pbs-01.hsn.cm.polaris.alcf.anl.gov --cpu-bind depth -d 16 /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/venvs/2024-04-29/bin/python3 -m ezpz.test_dist --tp 2 --pp 2\nConnected to tcp://x3006c0s19b0n0.hsn.cm.polaris.alcf.anl.gov:7919\nLaunching application 269d722b-ce74-4fef-92a4-76644aadeccc\nUsing PMI port 57027,57028\n[2025-04-01 09:22:44,418] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-04-01 09:22:44,418] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-04-01 09:22:44,418] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-04-01 09:22:44,419] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-04-01 09:22:45,292] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-04-01 09:22:45,292] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-04-01 09:22:45,292] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[2025-04-01 09:22:45,292] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n[WARNING]  sparse_attn requires a torch version &gt;= 1.5 and &lt; 2.0 but detected 2.3\n[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n[WARNING]  sparse_attn requires a torch version &gt;= 1.5 and &lt; 2.0 but detected 2.3\n[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n[WARNING]  sparse_attn requires a torch version &gt;= 1.5 and &lt; 2.0 but detected 2.3\n[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n[WARNING]  sparse_attn requires a torch version &gt;= 1.5 and &lt; 2.0 but detected 2.3\n[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n[2025-04-01 09:22:48][I][ezpz/dist:557] Using get_torch_device_type()='cuda' with backend='nccl'\n[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n[WARNING]  sparse_attn requires a torch version &gt;= 1.5 and &lt; 2.0 but detected 2.3\n[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n[WARNING]  sparse_attn requires a torch version &gt;= 1.5 and &lt; 2.0 but detected 2.3\n[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n[WARNING]  sparse_attn requires a torch version &gt;= 1.5 and &lt; 2.0 but detected 2.3\n[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n[WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n[WARNING]  sparse_attn requires a torch version &gt;= 1.5 and &lt; 2.0 but detected 2.3\n[WARNING]  using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n[2025-04-01 09:22:49][I][tp/__init__:148:ezpz.tp] TP: 2, PP: 2, CP: 1, DP: 2\n[2025-04-01 09:22:49][I][ezpz/dist:873] Using device='cuda' with backend='ddp' + 'nccl' for distributed training.\n[2025-04-01 09:22:51][I][ezpz/dist:923] ['x3006c0s19b0n0'][3/7] [pp:1/1][tp:1/1][dp:0/1]\n[2025-04-01 09:22:51][I][ezpz/dist:923] ['x3006c0s19b0n0'][2/7] [pp:1/1][tp:0/1][dp:0/1]\n[2025-04-01 09:22:51][I][ezpz/dist:923] ['x3006c0s1b0n0'][6/7] [pp:1/1][tp:0/1][dp:1/1]\n[2025-04-01 09:22:51][I][ezpz/dist:923] ['x3006c0s1b0n0'][7/7] [pp:1/1][tp:1/1][dp:1/1]\n[2025-04-01 09:22:51][I][ezpz/dist:923] ['x3006c0s19b0n0'][1/7] [pp:0/1][tp:1/1][dp:0/1]\n[2025-04-01 09:22:52][I][ezpz/dist:923] ['x3006c0s1b0n0'][5/7] [pp:0/1][tp:1/1][dp:1/1]\n[2025-04-01 09:22:52][I][ezpz/dist:923] ['x3006c0s19b0n0'][0/7] [pp:0/1][tp:0/1][dp:0/1]\n[2025-04-01 09:22:52][I][ezpz/dist:923] ['x3006c0s1b0n0'][4/7] [pp:0/1][tp:0/1][dp:1/1]\n[2025-04-01 09:22:52][I][ezpz/test_dist:395:__main__] model=\nNetwork(\n  (layers): Sequential(\n    (0): Linear(in_features=128, out_features=1024, bias=True)\n    (1): Linear(in_features=1024, out_features=512, bias=True)\n    (2): Linear(in_features=512, out_features=256, bias=True)\n    (3): Linear(in_features=256, out_features=128, bias=True)\n    (4): Linear(in_features=128, out_features=128, bias=True)\n  )\n)\n[2025-04-01 09:22:53][I][ezpz/dist:1100] Setting up wandb from rank=0\n[2025-04-01 09:22:53][I][ezpz/dist:1101] Using=WB PROJECT=ezpz.test_dist\nwandb: Currently logged in as: foremans (aurora_gpt). Use `wandb login --relogin` to force relogin\nwandb: wandb version 0.19.8 is available!  To upgrade, please run:\nwandb:  $ pip install wandb --upgrade\nwandb: Tracking run with wandb version 0.16.6\nwandb: Run data is saved locally in /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/wandb/run-20250401_092255-7vcfnxnn\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run deep-frog-1232\nwandb: \u2b50\ufe0f View project at https://wandb.ai/aurora_gpt/ezpz.test_dist\nwandb: \ud83d\ude80 View run at https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/7vcfnxnn\n[2025-04-01 09:22:55][I][ezpz/dist:1129] W&amp;B RUN=[deep-frog-1232](https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/7vcfnxnn)\n[2025-04-01 09:22:55][I][ezpz/dist:299] Updating wandb.run: deep-frog-1232 config with \"DIST_INFO\"\n[2025-04-01 09:22:56][I][ezpz/dist:1168] Running on machine='Polaris'\n[2025-04-01 09:22:56][I][ezpz/test_dist:219:__main__] config:\n{\n  \"backend\": \"DDP\",\n  \"batch_size\": 64,\n  \"cp\": 1,\n  \"dtype\": \"bfloat16\",\n  \"input_size\": 128,\n  \"layer_sizes\": [\n    1024,\n    512,\n    256,\n    128\n  ],\n  \"log_freq\": 1,\n  \"output_size\": 128,\n  \"pp\": 2,\n  \"print_freq\": 10,\n  \"pyinstrument_profiler\": false,\n  \"tp\": 2,\n  \"train_iters\": 100,\n  \"warmup\": 2\n}\n[2025-04-01 09:22:56][I][ezpz/test_dist:192:__main__] Warmup complete at step 2\n[2025-04-01 09:22:56][I][ezpz/test_dist:170:__main__] iter=10 loss=724.000000 dtf=0.000386 dtb=0.000711\n[2025-04-01 09:22:56][I][ezpz/test_dist:170:__main__] iter=20 loss=652.000000 dtf=0.000325 dtb=0.000742\n[2025-04-01 09:22:56][I][ezpz/test_dist:170:__main__] iter=30 loss=600.000000 dtf=0.000327 dtb=0.000713\n[2025-04-01 09:22:56][I][ezpz/test_dist:170:__main__] iter=40 loss=568.000000 dtf=0.000334 dtb=0.000705\n[2025-04-01 09:22:56][I][ezpz/test_dist:170:__main__] iter=50 loss=544.000000 dtf=0.000340 dtb=0.000660\n[2025-04-01 09:22:56][I][ezpz/test_dist:170:__main__] iter=60 loss=506.000000 dtf=0.000325 dtb=0.000650\n[2025-04-01 09:22:56][I][ezpz/test_dist:170:__main__] iter=70 loss=468.000000 dtf=0.000320 dtb=0.000665\n[2025-04-01 09:22:56][I][ezpz/test_dist:170:__main__] iter=80 loss=434.000000 dtf=0.000316 dtb=0.000709\n[2025-04-01 09:22:56][I][ezpz/test_dist:170:__main__] iter=90 loss=420.000000 dtf=0.000317 dtb=0.000694\n[2025-04-01 09:22:56][I][ezpz/history:704] Saving iter plot to: /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/plots/mplot\n[2025-04-01 09:22:56][I][ezpz/history:704] Saving loss plot to: /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/plots/mplot\n[2025-04-01 09:22:57][I][ezpz/history:704] Saving dtf plot to: /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/plots/mplot\n[2025-04-01 09:22:57][I][ezpz/history:704] Saving dtb plot to: /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/plots/mplot\n[2025-04-01 09:22:57][I][ezpz/history:602] Saving tplots to /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot\n                    loss [2025-04-01-092257]\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n1504.0\u2524\u258c                                                   \u2502\n      \u2502\u258c                                                   \u2502\n1317.3\u2524\u258c                                                   \u2502\n      \u2502\u258c                                                   \u2502\n      \u2502\u259a                                                   \u2502\n1130.7\u2524\u2590                                                   \u2502\n      \u2502\u2590                                                   \u2502\n 944.0\u2524 \u258c                                                  \u2502\n      \u2502 \u2590                                                  \u2502\n 757.3\u2524  \u259a                                                 \u2502\n      \u2502   \u2580\u2580\u259a\u2584\u2596                                            \u2502\n      \u2502       \u259d\u2580\u2580\u2580\u2584\u259a\u2584\u2584\u2596                                    \u2502\n 570.7\u2524               \u259d\u2580\u2580\u2580\u2580\u2580\u2580\u259a\u2584\u2584\u2584\u2584\u2584\u2596                       \u2502\n      \u2502                            \u259d\u2580\u2580\u2580\u2580\u2580\u259a\u2584\u2584\u2584\u2584\u2584 \u2596\u2596         \u2502\n 384.0\u2524                                        \u2580\u259d\u259d\u2580\u2580\u2580\u2580\u259a\u2584\u2580\u2584\u2584\u2502\n      \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2518\n      0  4  12 17 23   33 38 44 50 55 61  68 75 80  88 94\nloss                           iter\ntext saved in /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot/loss.txt\n                      dtf [2025-04-01-092257]\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n0.000508\u2524\u2597\u258c                                                \u2502\n        \u2502\u2590\u258c                                                \u2502\n0.000475\u2524\u2590\u258c                                                \u2502\n        \u2502\u2590\u258c                                                \u2502\n        \u2502\u2588\u258c                                                \u2502\n0.000443\u2524\u2588\u258c               \u2596                                \u2502\n        \u2502\u259d\u258c              \u2590\u258c                                \u2502\n0.000411\u2524 \u258c              \u2590\u258c                                \u2502\n        \u2502 \u258c              \u2590\u258c                                \u2502\n0.000379\u2524 \u258c\u259f\u259f            \u2590\u258c                                \u2502\n        \u2502 \u259d\u259b\u2588            \u2590\u258c                                \u2502\n        \u2502   \u259d\u2596           \u2590\u258c                                \u2502\n0.000347\u2524    \u258c \u2597\u258c    \u2596   \u259f\u258c \u2597    \u2596               \u2596    \u2597\u258c  \u2597\u2502\n        \u2502    \u259d\u2580\u259f\u259a\u259e\u2584\u2584\u2590\u259a \u259f\u2590\u259c\u259a\u2597\u2580\u2584\u259f\u2597\u2590\u259d\u2596 \u2597 \u2597\u258c \u2596\u2597 \u2584   \u2590\u259a \u2597 \u2597\u2590\u2590 \u2597\u258c\u2502\n0.000314\u2524           \u2598 \u2580 \u2598  \u2580  \u2598\u2598\u2580 \u259d\u259e\u2598\u259a\u2598\u259d\u259f\u259d\u258c\u2580 \u259a\u259e\u2580\u259c \u2580\u2598\u2580\u2580\u258c \u259a\u258c\u2598\u2502\n        \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2518\n        0  4  12   23   33 38 44 50 55 61 68 73 80  88 94\ndtf                             iter\ntext saved in /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot/dtf.txt\n                    dtf [2025-04-01-092257]\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n75.0\u2524\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n62.5\u2524\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n50.0\u2524\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n37.5\u2524\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n25.0\u2524\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n12.5\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                      \u2502\n0.0\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588      \u2588\u2588\u2588\u2588\u2588\u2502\n    \u2514\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2518\n  0.000306    0.000358      0.000411     0.000464  0.000516\nfreq                           dtf\ntext saved in /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot/dtf-hist.txt\n                      dtb [2025-04-01-092257]\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n0.000966\u2524                \u259f                                 \u2502\n        \u2502                \u2588                                 \u2502\n0.000913\u2524\u2597\u258c              \u2588                                 \u2502\n        \u2502\u2590\u258c              \u2588                                 \u2502\n        \u2502\u2590\u258c              \u2588                                 \u2502\n0.000861\u2524\u258c\u258c              \u2588                                 \u2502\n        \u2502\u2598\u258c              \u2588                                 \u2502\n0.000808\u2524 \u2590              \u2588                                 \u2502\n        \u2502  \u2599\u258c            \u2588                                 \u2502\n0.000755\u2524  \u259d\u258c            \u2588  \u2597                              \u2502\n        \u2502   \u258c \u259f   \u2596\u259f     \u2588  \u2588                    \u259f  \u2597\u259f \u2597\u2596  \u2502\n        \u2502   \u259a\u259a\u2580\u2596\u2597\u259f\u259d\u259c   \u259f \u2588 \u2596\u2588                  \u2596 \u258c\u258c \u2588\u2588\u2597\u2598\u258c \u2597\u2502\n0.000703\u2524      \u259d\u2598   \u259a\u2580\u259e \u2580\u2598\u2588\u259d\u259c \u2596               \u2590\u258c\u259e\u258c\u2590\u2597\u259c\u259b\u259e \u259d\u2599\u2598\u2502\n        \u2502                 \u259c \u259d\u259f\u258c \u2596 \u2584 \u2596  \u2596\u2596\u2597\u258c\u2596\u259e\u2596\u259e\u259c  \u259d\u259e \u2598   \u259d \u2502\n0.000650\u2524                    \u259d\u259d\u2580\u259d\u2580 \u2580\u259d\u2580\u259c\u259d\u259d\u2598\u259d\u259d\u2598\u259d             \u2502\n        \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u252c\u2500\u2500\u2518\n        0  4  12   23   33 38 44 50 55 61 68 73 80  88 94\ndtb                             iter\ntext saved in /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot/dtb.txt\n                    dtb [2025-04-01-092257]\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n38.0\u2524\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n31.7\u2524\u2588\u2588\u2588\u2588\u2588                                                 \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n25.3\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n19.0\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                           \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                      \u2502\n12.7\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                      \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                      \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                      \u2502\n 6.3\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                      \u2502\n    \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                      \u2502\n 0.0\u2524\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588     \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2502\n    \u2514\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2518\n  0.00064      0.00072       0.00081      0.00089   0.00098\nfreq                           dtb\ntext saved in /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/plots/tplot/dtb-hist.txt\n[2025-04-01 09:22:57][I][ezpz/utils:192] Saving dataset to: /lus/eagle/projects/datascience/foremans/projects/saforem2/tmp/ezpz/outputs/ezpz.test_dist/ezpz.test_dist/train_dataset.h5\n[2025-04-01 09:22:57][I][ezpz/test_dist:186:__main__] dataset=&lt;xarray.Dataset&gt; Size: 3kB\nDimensions:  (draw: 97)\nCoordinates:\n  * draw     (draw) int64 776B 0 1 2 3 4 5 6 7 8 ... 88 89 90 91 92 93 94 95 96\nData variables:\n    iter     (draw) int64 776B 3 4 5 6 7 8 9 10 11 ... 92 93 94 95 96 97 98 99\n    loss     (draw) float32 388B 1.504e+03 1.144e+03 976.0 ... 396.0 388.0 384.0\n    dtf      (draw) float64 776B 0.0004546 0.0004246 ... 0.0003218 0.0003382\n    dtb      (draw) float64 776B 0.0008328 0.0008702 ... 0.0006997 0.0007125\n[2025-04-01 09:22:57][I][ezpz/test_dist:459:__main__] Took: 9.68 seconds\nwandb: \\ 0.089 MB of 0.089 MB uploaded\nwandb: Run history:\nwandb:  dtb \u2588\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\nwandb:  dtf \u2588\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\nwandb: iter \u2581\u2581\u2581\u2581\u2582\u2582\u2582\u2582\u2582\u2583\u2583\u2583\u2583\u2583\u2583\u2584\u2584\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588\nwandb: loss \u2588\u2584\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2582\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\u2581\nwandb:\nwandb: Run summary:\nwandb:  dtb 0.00071\nwandb:  dtf 0.00034\nwandb: iter 99\nwandb: loss 384.0\nwandb:\nwandb: \ud83d\ude80 View run deep-frog-1232 at: https://wandb.ai/aurora_gpt/ezpz.test_dist/runs/7vcfnxnn\nwandb: \u2b50\ufe0f View project at: https://wandb.ai/aurora_gpt/ezpz.test_dist\nwandb: Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20250401_092255-7vcfnxnn/logs\nApplication 269d722b resources: utime=90s stime=97s maxrss=2275848KB inblock=8344 oublock=2248 minflt=2426300 majflt=827 nvcsw=640812 nivcsw=350270\n[2025-04-01 09:23:07][I][ezpz/launch:93:__main__] Command took 29.55 seconds to run.\n\nreal   42.30s\nuser   11.50s\nsys    8.41s\n</code></pre>"},{"location":"notes/","title":"\ud83d\udcdd Notes","text":""},{"location":"notes/#2024-12-30","title":"2024-12-30","text":"<p>Launch and train across all your accelerators, using your favorite framework + backend combo.</p> <p><code>ezpz</code> simplifies the process of:</p> <ul> <li> <p>Setting up + launching distributed training: <ul> <li> <p><code>import ezpz as ez</code> <ul> <li> <p><code>RANK =</code> <code>ez.setup_torch(backend=backend)</code>   [for <code>backend</code> \\(\\in\\) {<code>DDP</code>, <code>deepspeed</code>, <code>horovod</code>}]{.dim-text}</p> </li> <li> <p><code>RANK =</code> <code>ez.get_rank()</code></p> </li> <li> <p><code>LOCAL_RANK =</code> <code>ez.get_local_rank()</code></p> </li> <li> <p><code>WORLD_SIZE =</code> <code>ez.get_world_size()</code></p> </li> </ul> <p>[(see <code>ezpz/dist.py</code> for more details).]{.dim-text}</p> <ul> <li> <p>Using your favorite framework: <ul> <li> <p><code>framework=pytorch</code> + <code>backend={DDP, deepspeed, horovod}</code></p> </li> <li> <p><code>framework=tensorflow</code> + <code>backend=horovod</code></p> </li> <li> <p><code>ez.get_torch_device()</code>: {<code>cuda</code>, <code>xpu</code>, <code>mps</code>, <code>cpu</code>}</p> </li> <li> <p><code>ez.get_torch_backend()</code>: {<code>nccl</code>, <code>ccl</code>, <code>gloo</code>}</p> </li> </ul> <p>2ez \ud83d\ude0e. (see frameworks for additional details)</p> <ul> <li> <p>Writing device agnostic code: <ul> <li> <p><code>ezpz.get_torch_device()</code> <pre><code>&gt;&gt;&gt; import ezpz as ez\n&gt;&gt;&gt; DEVICE = ez.get_torch_device()\n&gt;&gt;&gt; model = torch.nn.Linear(10, 10)\n&gt;&gt;&gt; model.to(DEVICE)\n&gt;&gt;&gt; x = torch.randn((10, 10), device=DEVICE)\n&gt;&gt;&gt; y = model(x)\n&gt;&gt;&gt; y.device\ndevice(type='mps', index=0)\n</code></pre> <ul> <li> <p>Using <code>wandb</code>: <ul> <li><code>ez.setup_wandb(project_name='ezpz')</code></li> </ul> <ul> <li>Full support for any {<code>device</code> + <code>framework</code> + <code>backend</code>}:<ul> <li>device: {<code>GPU</code>, <code>XPU</code>, <code>MPS</code>, <code>CPU</code>}</li> <li>framework: {<code>torch</code>, <code>deepspeed</code>, <code>horovod</code>, <code>tensorflow</code>}</li> <li>backend: {<code>DDP</code>, <code>deepspeed</code>, <code>horovod</code>}</li> </ul> </li> </ul>"},{"location":"notes/#2024-11-06","title":"2024-11-06","text":"<ul> <li> Save <code>PBS_*</code> env to <code>~/pbs_jobenvs/${PBS_JOBID}.env</code> when dumping vars in <code>utils.sh</code></li> </ul>"},{"location":"notes/#getting-started","title":"Getting Started","text":"<p>There are two main, distinct components of <code>ezpz</code>:</p> <ol> <li>Shell interface</li> <li>Python Library</li> </ol>"},{"location":"notes/#shell-interface","title":"Shell Interface","text":"<ul> <li><code>bin/utils.sh</code>:</li> <li>Provides various (<code>bash</code> / shell) helper functions to make life easy</li> <li> <p>Designed to be <code>source</code>-d, e.g.</p> <pre><code>source ezpz/src/ezpz/bin/utils.sh\n</code></pre> </li> <li> <p>All functions prefixed with <code>ezpz_</code></p> </li> </ul> <p>To use:</p> <pre><code>git clone https://github.com/saforem2/ezpz deps/ezpz\n# on ALCF:\nexport PBS_O_WORKDIR=$(pwd)\nsource deps/ezpz/src/ezpz/bin/utils.sh\nezpz_setup_python\n# from a compute node:\nezpz_setup_job\n</code></pre>"},{"location":"notes/#python-library","title":"Python Library","text":"<p>WIP</p>"},{"location":"notes/#old","title":"Old","text":"Old:  ## Startup Files  In your `{.bashrc,.zshrc}`, you can:  <pre><code>ezpz_setup_alcf() {\n    file=$(mktemp)\n    curl -Ls https://raw.githubusercontent.com/saforem2/ezpz/main/src/ezpz/bin/utils.sh &gt; \"${file}\"\n    echo \"Saving 'utils.sh' to ${file} and sourcing...\"\n    source \"${file}\" || exit\n    hn=$(hostname)\n    setup_alcf\n}\n\nhn=$(hostname)\nif [[ \"${hn}\" == x1 || \"${hn}\" == x]]\nif [[ $(hostname) == x3* || $(hostname) == polaris* ]]; then\n  \nelif [[ $(hostname) == x4* || $(hostname) == aurora* ]]; then\nelif [[ $(hostname) == x1* || $(hostname) == uan* ]]; then\nelif [[ $(hostname) == bastion* ]]; then\nelse\nfi\n\nMACHINE=$(echo \"${machine}\" | tr '[:upper:]' '[:lower:]')\nexport PATH=\"${HOME}/bin/${MACHINE}:${PATH}\"\nexport HISTFILE=\"$HOME/.zsh_history-${MACHINE}\"\n# export CODESTATS_API_KEY=\"SFMyNTY.YzJGdFptOXlaVzFoYmc9PSMjTWpBNE1UST0.NQ4Oy3FSJcT4nMaMlVnYcnCtPc2mqImViSGiIxyJFrg\"\nexport ZSH_COMPDUMP=\"${ZSH}/cache/.zcompdump-${MACHINE}\"\n</code></pre>  1. Clone `ezpz` + navigate into it:      <pre><code>git clone https://github.com/saforem2/ezpz\ncd ezpz\n</code></pre>  2. Source [`src/ezpz/bin/utils.sh`](https://github.com/saforem2/ezpz/blob/main/src/ezpz/bin/utils.sh)      <pre><code>#[\ud83c\udf0c][01:16:07 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450\n$ export PBS_O_WORKDIR=$(pwd) &amp;&amp; source src/ezpz/bin/utils.sh\nUsing WORKING_DIR: /home/foremans/2024-07-10-131541/ezpz\n</code></pre>  3. Setup `python`:      <pre><code>#[\ud83c\udf0c][01:16:17 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450\n$ setup_python\nNo conda_prefix OR virtual_env found in environment...\nSetting up conda...\nmachine name: aurora\n\nThe following have been reloaded with a version change:\n  1) intel_compute_runtime/release/821.36 =&gt; intel_compute_runtime/release/803.29\n  2) oneapi/eng-compiler/2024.04.15.002 =&gt; oneapi/release/2024.1\n\nFound conda at: /opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1\nNo VIRTUAL_ENV found in environment!\n    - Trying to setup from /opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1\n    - Using VENV_DIR=/home/foremans/2024-07-10-131541/ezpz/venvs/aurora_nre_models_frameworks-2024.1\n\n    - Creating a new virtual env on top of aurora_nre_models_frameworks-2024.1 in /home/foremans/2024-07-10-131541/ezpz/venvs/aurora_nre_models_frameworks-2024.1\n[python] Using: /home/foremans/2024-07-10-131541/ezpz/venvs/aurora_nre_models_frameworks-2024.1/bin/python3\n</code></pre>  4. Setup ALCF:      1. via `bash` script:        <code>.jobenv</code>: <pre><code>#[aurora_nre_models_frameworks-2024.1](\ud83d\udc7b aurora_nre_models_frameworks-2024.1)\n#[\ud83c\udf0c][01:16:45 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450 [\u23f1 13s]\n$ setup_alcf\n\n[ezpz/bin/utils.sh]\n\n[2024-07-10-131719]\n    \u2022 USER=foremans\n    \u2022 MACHINE=aurora\n    \u2022 HOST=x4017c4s5b0n0\n\n[setupHost]\n    \u2022 Using hostfile: /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n    \u2022 Found in environment:\n        \u2022 HOSTFILE: /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n        \u2022 Writing PBS vars to: /home/foremans/.pbsenv\n\n[save_pbs_env]\n    \u2022 Using:\n        \u2022 hostfile: /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n        \u2022 jobenv_file: /home/foremans/.pbsenv\n      to calculate:\n        \u2022 num_hosts: 2\n        \u2022 num_gpus_per_host: 12\n        \u2022 num_gpus: 24\n        \u2022 DIST_LAUNCH: mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\n    \u2022 Setting:\n        \u2022 HOSTFILE: /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n        \u2022 JOBENV_FILE: /home/foremans/.pbsenv\n\n[HOSTS]\n    \u2022 [host:0] - x4017c4s5b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov\n    \u2022 [host:1] - x4017c4s6b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov\n\n[DIST INFO]\n    \u2022 HOSTFILE=/var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n    \u2022 NHOSTS=2\n    \u2022 NGPU_PER_HOST=12\n    \u2022 NGPUS=24\n    \u2022 DIST_LAUNCH=mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\n\n[LAUNCH]:\n    \u2022 To launch across all available GPUs, use: launch\n      launch = mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\n</code></pre>       2. via `python`:        <code>.jobenv</code>: <pre><code>#[aurora_nre_models_frameworks-2024.1](\ud83d\udc7b aurora_nre_models_frameworks-2024.1)\n#[\ud83c\udf0c][01:20:20 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450\n$ python3 -m ezpz.jobs\n2024-07-10 13:21:51,992 - numexpr.utils - INFO - Note: detected 208 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n2024-07-10 13:21:51,992 - numexpr.utils - INFO - Note: NumExpr detected 208 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n2024-07-10 13:21:51,992 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n/home/foremans/2024-07-10-131541/ezpz/venvs/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n  from pandas.core.computation.check import NUMEXPR_INSTALLED\n[2024-07-10 13:21:54.534132][INFO][__init__:156] - Setting logging level to 'INFO' on 'RANK == 0'\n[2024-07-10 13:21:54.537096][INFO][__init__:157] - Setting logging level to 'CRITICAL' on all others 'RANK != 0'\n[2024-07-10 13:21:54.537529][INFO][__init__:160] - To disable this behavior, and log from ALL ranks (not recommended), set: 'export LOG_FROM_ALL_RANKS=1'  in your environment, and re-run.\n[2024-07-10 13:21:54.564493][INFO][dist:95] -\n\n[dist_info]:\n  \u2022 FRAMEWORK=pytorch\n  \u2022 DEVICE=xpu\n  \u2022 DEVICE_ID=xpu:0\n  \u2022 DISTRIBUTED_BACKEND=ccl\n  \u2022 GPUS_PER_NODE=12\n  \u2022 HOSTS=['x4017c4s5b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov', 'x4017c4s6b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov']\n  \u2022 HOSTFILE=/var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n  \u2022 HOSTNAME=x4017c4s5b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov\n  \u2022 LOCAL_RANK=0\n  \u2022 MACHINE=Aurora\n  \u2022 NUM_NODES=2\n  \u2022 NGPUS=24\n  \u2022 NGPUS_AVAILABLE=24\n  \u2022 NODE_ID=0\n  \u2022 RANK=0\n  \u2022 SCHEDULER=PBS\n  \u2022 WORLD_SIZE_TOTAL=24\n  \u2022 WORLD_SIZE_IN_USE=1\n  \u2022 LAUNCH_CMD=mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\n\n\n[2024-07-10 13:21:54.591833][INFO][jobs:164] - Saving job env to /home/foremans/PBS-jobs/698077/.jobenv\n[2024-07-10 13:21:54.596525][INFO][jobs:164] - Saving job env to /home/foremans/2024-07-10-131541/ezpz/.jobenv\n[2024-07-10 13:21:54.613725][INFO][jobs:354] - Caught pbs_jobid='698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov', pbs_nodefile=PosixPath('/var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov') from env. Saving jobenv!\n[2024-07-10 13:21:54.655237][WARNING][jobs:144] - /home/foremans/PBS-jobs/698077  already in /home/foremans/PBS-jobs.log,  not appending !!\n[2024-07-10 13:21:54.655766][INFO][jobs:369] - Writing PBS env vars to  /home/foremans/PBS-jobs/698077 / jobenv{.sh, .yaml, .json}\n[2024-07-10 13:21:54.666092][INFO][jobs:241] - Saving job env to /home/foremans/PBS-jobs/698077/jobenv.sh\n[2024-07-10 13:21:54.682342][INFO][jobs:258] - Saving job env to /home/foremans/PBS-jobs/698077/jobenv.json\n[2024-07-10 13:21:54.700122][INFO][jobs:271] - Saving job env to /home/foremans/PBS-jobs/698077/jobenv.yaml\n[2024-07-10 13:21:54.707680][CRITICAL][jobs:381] -\nRun:\n\n    source .jobenv\n\nto set these environment variables.\n\n6.59s user 8.17s system 16% cpu 1:27.78s total\n</code></pre> <code>.jobenv</code>: <pre><code>#[aurora_nre_models_frameworks-2024.1](\ud83d\udc7b aurora_nre_models_frameworks-2024.1)\n#[\ud83c\udf0c][01:21:58 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450 [\u23f1 1m27s]\n$ cat .jobenv\n#!/bin/bash --login\nFRAMEWORK=\"pytorch\"\nDEVICE=\"xpu\"\nDEVICE_ID=\"xpu:0\"\nDISTRIBUTED_BACKEND=\"ccl\"\nGPUS_PER_NODE=\"12\"\nHOSTS=\"[x4017c4s5b0n0, x4017c4s6b0n0]\"\nHOSTFILE=\"/var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\"\nHOSTNAME=\"x4017c4s5b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov\"\nLOCAL_RANK=\"0\"\nMACHINE=\"Aurora\"\nNUM_NODES=\"2\"\nNGPUS=\"24\"\nNGPUS_AVAILABLE=\"24\"\nNODE_ID=\"0\"\nRANK=\"0\"\nSCHEDULER=\"PBS\"\nWORLD_SIZE_TOTAL=\"24\"\nWORLD_SIZE_IN_USE=\"1\"\nLAUNCH_CMD=\"mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\"\nPBS_O_HOME=\"/home/foremans\"\nPBS_O_LANG=\"en_US.UTF-8\"\nPBS_O_LOGNAME=\"foremans\"\nPBS_O_PATH=\"/home/foremans/micromamba/condabin:/home/foremans/homebrew/bin:/home/foremans/homebrew/sbin:/home/foremans/bin/aurora:/opt/cray/pals/1.3.3/bin:/opt/cray/libfabric/1.15.2.0/bin:/opt/aurora/24.086.0/support/tools/gpu_validation:/opt/aurora/24.086.0/intel-gpu-umd/821.36/bin:/opt/aurora/24.086.0/CNDA/mpich/20231026/mpich-ofi-all-icc-default-pmix-gpu-drop20231026/bin:/opt/aurora/24.086.0/support/tools/mpi_wrapper_utils:/opt/aurora/24.086.0/CNDA/oneapi/dpcpp-ct/eng-20240227/bin:/opt/aurora/24.086.0/oneapi/advisor/latest/bin64:/opt/aurora/24.086.0/oneapi/vtune/latest/bin64:/opt/aurora/24.086.0/oneapi/debugger/latest/opt/debugger/bin:/opt/aurora/24.086.0/CNDA/oneapi/mkl/develop_20240229/bin:/opt/aurora/24.086.0/CNDA/oneapi/compiler/eng-20240227/bin:/opt/aurora/24.086.0/spack/gcc/0.7.0/install/linux-sles15-x86_64/gcc-12.2.0/gcc-12.2.0-jf4ov3v3scg7dvd76qhsuugl3jp42gfn/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/home/foremans/.local/bin:/home/foremans/bin:/usr/local/bin:/usr/bin:/bin:/opt/c3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/pbs/bin:/sbin:/home/foremans/.local/share/kitty-ssh-kitten/kitty/bin:/home/foremans/.cargo/bin:/home/foremans/.fzf/bin:/home/foremans/.luarocks/bin\"\nPBS_O_MAIL=\"/var/spool/mail/foremans\"\nPBS_O_SHELL=\"/bin/zsh\"\nPBS_O_TZ=\"America/Chicago\"\nPBS_O_HOST=\"aurora-uan-0009.hostmgmt1000.cm.aurora.alcf.anl.gov\"\nPBS_O_WORKDIR=\"/home/foremans/2024-07-10-131541/ezpz\"\nPBS_O_SYSTEM=\"Linux\"\nPBS_O_QUEUE=\"lustre_scaling\"\nPBS_JOBID_SHORT=\"698077.aurora\"\nPBS_HOOK_RESOURCES=\"eJydUNFuwyAM/KFNIixtoyHe9gl9tyhxEhYCzECr/P2cpZO67W0SD9h3vjs7I12RYEQ7RxiyblTeO1Nc8EfjarzrYXAe85oLLlnfKU/fw8p4H29grI01FLAT92EwzldC1tnRgKMp7oqwlZa/MWzYzVAPXOIYadVvLlvCDTO03sGyJvwFXCoFoE1DC2UrEbLtg+7zSyeOx/bQHmQn1JTsAm4xI2obl1QLZ6gUyUDBXEAK2YqTkGcpxaFpoD/JoZOtCjbVrNvmqIIDwhwrWdT7pAqxR1u0VJFPtMXhIMkbJmTOUJBUovjOFEjkIrmyMpfi5n0xduZr+q8L+10lzy7BBYOdFkNzZrESi/GPOwl146q4BbXoXoXgpz4qVoR/7rcP/3H+BG1nxmU=\"\nPBS_JOBNAME=\"STDIN\"\nPBS_JOBID=\"698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\"\nPBS_QUEUE=\"lustre_scaling\"\nPBS_JOBCOOKIE=\"5D073B7E1C16CA8D16018CC9224570E3\"\nPBS_NODENUM=\"0\"\nPBS_TASKNUM=\"1\"\nPBS_MOMPORT=\"15003\"\nPBS_NODEFILE=\"/var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\"\nPBS_ACCOUNT=\"Aurora_Deployment\"\nPBS_JOBDIR=\"/home/foremans\"\nPBS_ENVIRONMENT=\"PBS_INTERACTIVE\"\nNHOSTS=\"2\"\nNGPU_PER_HOST=\"12\"\nBACKEND=\"ccl\"\nalias launch=\"mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\"\necho \"$(which launch)\"\n</code></pre>    ## Custom hostfile  ### Bash  <pre><code>#[aurora_nre_models_frameworks-2024.1](\ud83d\udc7b aurora_nre_models_frameworks-2024.1)\n#[\ud83c\udf0c][01:25:25 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450\n$ head -1 \"$PBS_NODEFILE\" &gt; nodefile &amp;&amp; cat nodefile\nx4017c4s5b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov\n\n#[aurora_nre_models_frameworks-2024.1](\ud83d\udc7b aurora_nre_models_frameworks-2024.1)\n#[\ud83c\udf0c][01:25:28 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450\n$ setup_alcf nodefile\n\n[ezpz/bin/utils.sh]\n\n[2024-07-10-132537]\n    \u2022 USER=foremans\n    \u2022 MACHINE=aurora\n    \u2022 HOST=x4017c4s5b0n0\n\n[setupHost]\n    \u2022 Caught 1 arguments\n    \u2022 Caught 1 arguments\n    \u2022 hostfile=nodefile\n        \u2022 Writing PBS vars to: /home/foremans/.pbsenv\n\n[save_pbs_env]\n    \u2022 Caught 1 arguments\n\n    \u2022 Caught hostfile != PBS_NODEFILE\n        \u2022 hostfile: nodefile\n        \u2022 PBS_NODEFILE: /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n\n    \u2022 Using:\n        \u2022 hostfile: nodefile\n        \u2022 jobenv_file: /home/foremans/.pbsenv\n      to calculate:\n        \u2022 num_hosts: 1\n        \u2022 num_gpus_per_host: 12\n        \u2022 num_gpus: 12\n        \u2022 DIST_LAUNCH: mpiexec --verbose --envall -n 12 -ppn 12 --hostfile nodefile --cpu-bind depth -d 16\n    \u2022 Setting:\n        \u2022 HOSTFILE: nodefile\n        \u2022 JOBENV_FILE: /home/foremans/.pbsenv\n\n[HOSTS]\n    \u2022 [host:0] - x4017c4s5b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov\n\n[DIST INFO]\n    \u2022 HOSTFILE=nodefile\n    \u2022 NHOSTS=1\n    \u2022 NGPU_PER_HOST=12\n    \u2022 NGPUS=12\n    \u2022 DIST_LAUNCH=mpiexec --verbose --envall -n 12 -ppn 12 --hostfile nodefile --cpu-bind depth -d 16\n\n[LAUNCH]:\n    \u2022 To launch across all available GPUs, use: launch\n      launch = mpiexec --verbose --envall -n 12 -ppn 12 --hostfile nodefile --cpu-bind depth -d 16\n</code></pre>  ### Python  <pre><code>#[aurora_nre_models_frameworks-2024.1](\ud83d\udc7b aurora_nre_models_frameworks-2024.1)\n#[\ud83c\udf0c][01:26:10 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450 [\u23f1 6s]\n$ python3 -m ezpz.jobs --hostfile nodefile\n2024-07-10 13:26:41,045 - numexpr.utils - INFO - Note: detected 208 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n2024-07-10 13:26:41,045 - numexpr.utils - INFO - Note: NumExpr detected 208 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n2024-07-10 13:26:41,045 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n/home/foremans/2024-07-10-131541/ezpz/venvs/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n  from pandas.core.computation.check import NUMEXPR_INSTALLED\n[2024-07-10 13:26:41.973940][INFO][__init__:156] - Setting logging level to 'INFO' on 'RANK == 0'\n[2024-07-10 13:26:41.976941][INFO][__init__:157] - Setting logging level to 'CRITICAL' on all others 'RANK != 0'\n[2024-07-10 13:26:41.977373][INFO][__init__:160] - To disable this behavior, and log from ALL ranks (not recommended), set: 'export LOG_FROM_ALL_RANKS=1'  in your environment, and re-run.\n[2024-07-10 13:26:41.990751][WARNING][dist:1127] - Mismatch in `ngpus_in_use` and `ngpus_available` ngpus_in_use=12 vs. ngpus_available=24\n[2024-07-10 13:26:41.991378][INFO][dist:95] -\n\n[dist_info]:\n  \u2022 FRAMEWORK=pytorch\n  \u2022 DEVICE=xpu\n  \u2022 DEVICE_ID=xpu:0\n  \u2022 DISTRIBUTED_BACKEND=ccl\n  \u2022 GPUS_PER_NODE=12\n  \u2022 HOSTS=['x4017c4s5b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov']\n  \u2022 HOSTFILE=/home/foremans/2024-07-10-131541/ezpz/nodefile\n  \u2022 HOSTNAME=x4017c4s5b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov\n  \u2022 LOCAL_RANK=0\n  \u2022 MACHINE=Aurora\n  \u2022 NUM_NODES=1\n  \u2022 NGPUS=12\n  \u2022 NGPUS_AVAILABLE=24\n  \u2022 NODE_ID=0\n  \u2022 RANK=0\n  \u2022 SCHEDULER=PBS\n  \u2022 WORLD_SIZE_TOTAL=24\n  \u2022 WORLD_SIZE_IN_USE=1\n  \u2022 LAUNCH_CMD=mpiexec --verbose --envall -n 12 -ppn 12 --hostfile nodefile --cpu-bind depth -d 16\n\n\n[2024-07-10 13:26:41.999545][WARNING][dist:1127] - Mismatch in `ngpus_in_use` and `ngpus_available` ngpus_in_use=12 vs. ngpus_available=24\n[2024-07-10 13:26:42.002941][WARNING][dist:1127] - Mismatch in `ngpus_in_use` and `ngpus_available` ngpus_in_use=12 vs. ngpus_available=24\n[2024-07-10 13:26:42.017104][WARNING][dist:1127] - Mismatch in `ngpus_in_use` and `ngpus_available` ngpus_in_use=12 vs. ngpus_available=24\n[2024-07-10 13:26:42.017647][INFO][jobs:164] - Saving job env to /home/foremans/PBS-jobs/698077/.jobenv\n[2024-07-10 13:26:42.022741][INFO][jobs:164] - Saving job env to /home/foremans/2024-07-10-131541/ezpz/.jobenv\n[2024-07-10 13:26:42.027785][CRITICAL][jobs:381] -\nRun:\n\n    source .jobenv\n\nto set these environment variables.\n\n6.55s user 7.58s system 218% cpu 6.474s total\n</code></pre> <pre><code>#[aurora_nre_models_frameworks-2024.1](\ud83d\udc7b aurora_nre_models_frameworks-2024.1)\n#[\ud83c\udf0c][01:26:54 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450 [\u23f1 6s]\n$ cat .jobenv\n#!/bin/bash --login\nFRAMEWORK=\"pytorch\"\nDEVICE=\"xpu\"\nDEVICE_ID=\"xpu:0\"\nDISTRIBUTED_BACKEND=\"ccl\"\nGPUS_PER_NODE=\"12\"\nHOSTS=\"[x4017c4s5b0n0]\"\nHOSTFILE=\"nodefile\"\nHOSTNAME=\"x4017c4s5b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov\"\nLOCAL_RANK=\"0\"\nMACHINE=\"Aurora\"\nNUM_NODES=\"1\"\nNGPUS=\"12\"\nNGPUS_AVAILABLE=\"24\"\nNODE_ID=\"0\"\nRANK=\"0\"\nSCHEDULER=\"PBS\"\nWORLD_SIZE_TOTAL=\"24\"\nWORLD_SIZE_IN_USE=\"1\"\nLAUNCH_CMD=\"mpiexec --verbose --envall -n 12 -ppn 12 --hostfile nodefile --cpu-bind depth -d 16\"\nPBS_O_HOME=\"/home/foremans\"\nPBS_O_LANG=\"en_US.UTF-8\"\nPBS_O_LOGNAME=\"foremans\"\nPBS_O_PATH=\"/home/foremans/micromamba/condabin:/home/foremans/homebrew/bin:/home/foremans/homebrew/sbin:/home/foremans/bin/aurora:/opt/cray/pals/1.3.3/bin:/opt/cray/libfabric/1.15.2.0/bin:/opt/aurora/24.086.0/support/tools/gpu_validation:/opt/aurora/24.086.0/intel-gpu-umd/821.36/bin:/opt/aurora/24.086.0/CNDA/mpich/20231026/mpich-ofi-all-icc-default-pmix-gpu-drop20231026/bin:/opt/aurora/24.086.0/support/tools/mpi_wrapper_utils:/opt/aurora/24.086.0/CNDA/oneapi/dpcpp-ct/eng-20240227/bin:/opt/aurora/24.086.0/oneapi/advisor/latest/bin64:/opt/aurora/24.086.0/oneapi/vtune/latest/bin64:/opt/aurora/24.086.0/oneapi/debugger/latest/opt/debugger/bin:/opt/aurora/24.086.0/CNDA/oneapi/mkl/develop_20240229/bin:/opt/aurora/24.086.0/CNDA/oneapi/compiler/eng-20240227/bin:/opt/aurora/24.086.0/spack/gcc/0.7.0/install/linux-sles15-x86_64/gcc-12.2.0/gcc-12.2.0-jf4ov3v3scg7dvd76qhsuugl3jp42gfn/bin:/opt/clmgr/sbin:/opt/clmgr/bin:/opt/sgi/sbin:/opt/sgi/bin:/home/foremans/.local/bin:/home/foremans/bin:/usr/local/bin:/usr/bin:/bin:/opt/c3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/pbs/bin:/sbin:/home/foremans/.local/share/kitty-ssh-kitten/kitty/bin:/home/foremans/.cargo/bin:/home/foremans/.fzf/bin:/home/foremans/.luarocks/bin\"\nPBS_O_MAIL=\"/var/spool/mail/foremans\"\nPBS_O_SHELL=\"/bin/zsh\"\nPBS_O_TZ=\"America/Chicago\"\nPBS_O_HOST=\"aurora-uan-0009.hostmgmt1000.cm.aurora.alcf.anl.gov\"\nPBS_O_WORKDIR=\"/home/foremans/2024-07-10-131541/ezpz\"\nPBS_O_SYSTEM=\"Linux\"\nPBS_O_QUEUE=\"lustre_scaling\"\nPBS_JOBID_SHORT=\"698077.aurora\"\nPBS_HOOK_RESOURCES=\"eJydUNFuwyAM/KFNIixtoyHe9gl9tyhxEhYCzECr/P2cpZO67W0SD9h3vjs7I12RYEQ7RxiyblTeO1Nc8EfjarzrYXAe85oLLlnfKU/fw8p4H29grI01FLAT92EwzldC1tnRgKMp7oqwlZa/MWzYzVAPXOIYadVvLlvCDTO03sGyJvwFXCoFoE1DC2UrEbLtg+7zSyeOx/bQHmQn1JTsAm4xI2obl1QLZ6gUyUDBXEAK2YqTkGcpxaFpoD/JoZOtCjbVrNvmqIIDwhwrWdT7pAqxR1u0VJFPtMXhIMkbJmTOUJBUovjOFEjkIrmyMpfi5n0xduZr+q8L+10lzy7BBYOdFkNzZrESi/GPOwl146q4BbXoXoXgpz4qVoR/7rcP/3H+BG1nxmU=\"\nPBS_JOBNAME=\"STDIN\"\nPBS_JOBID=\"698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\"\nPBS_QUEUE=\"lustre_scaling\"\nPBS_JOBCOOKIE=\"5D073B7E1C16CA8D16018CC9224570E3\"\nPBS_NODENUM=\"0\"\nPBS_TASKNUM=\"1\"\nPBS_MOMPORT=\"15003\"\nPBS_NODEFILE=\"/var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\"\nPBS_ACCOUNT=\"Aurora_Deployment\"\nPBS_JOBDIR=\"/home/foremans\"\nPBS_ENVIRONMENT=\"PBS_INTERACTIVE\"\nNHOSTS=\"1\"\nNGPU_PER_HOST=\"12\"\nBACKEND=\"ccl\"\nalias launch=\"mpiexec --verbose --envall -n 12 -ppn 12 --hostfile nodefile --cpu-bind depth -d 16\"\necho \"$(which launch)\"\n</code></pre>   To reset after using custom hostfile:  <pre><code>#[aurora_nre_models_frameworks-2024.1](\ud83d\udc7b aurora_nre_models_frameworks-2024.1)\n#[\ud83c\udf0c][01:27:39 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450\n$ unset hostfile HOSTFILE\n\n#[aurora_nre_models_frameworks-2024.1](\ud83d\udc7b aurora_nre_models_frameworks-2024.1)\n#[\ud83c\udf0c][01:27:41 PM][foremans@x4017c4s5b0n0][\u2026/ezpz][\ud83c\udf31 jobs-rewrite]via \u2a01 v1.3.450\n$ setup_alcf\n\n[ezpz/bin/utils.sh]\n\n[2024-07-10-132744]\n    \u2022 USER=foremans\n    \u2022 MACHINE=aurora\n    \u2022 HOST=x4017c4s5b0n0\n\n[setupHost]\n    \u2022 Using hostfile: /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n    \u2022 Found in environment:\n        \u2022 Writing PBS vars to: /home/foremans/.pbsenv\n\n[save_pbs_env]\n    \u2022 Using:\n        \u2022 hostfile: /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n        \u2022 jobenv_file: /home/foremans/.pbsenv\n      to calculate:\n        \u2022 num_hosts: 2\n        \u2022 num_gpus_per_host: 12\n        \u2022 num_gpus: 24\n        \u2022 DIST_LAUNCH: mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\n    \u2022 Setting:\n        \u2022 HOSTFILE: /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n        \u2022 JOBENV_FILE: /home/foremans/.pbsenv\n\n[HOSTS]\n    \u2022 [host:0] - x4017c4s5b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov\n    \u2022 [host:1] - x4017c4s6b0n0.hostmgmt2017.cm.aurora.alcf.anl.gov\n\n[DIST INFO]\n    \u2022 HOSTFILE=/var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov\n    \u2022 NHOSTS=2\n    \u2022 NGPU_PER_HOST=12\n    \u2022 NGPUS=24\n    \u2022 DIST_LAUNCH=mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\n\n[LAUNCH]:\n    \u2022 To launch across all available GPUs, use: launch\n      launch = mpiexec --verbose --envall -n 24 -ppn 12 --hostfile /var/spool/pbs/aux/698077.aurora-pbs-0001.hostmgmt.cm.aurora.alcf.anl.gov --cpu-bind depth -d 16\n</code></pre>"},{"location":"parallelism/","title":"\ud83d\udd78\ufe0f Parallelism Support","text":""},{"location":"parallelism/#examples-from-aurora","title":"Examples from Aurora","text":"<p>Running some simple examples with different <code>--tp</code>, <code>--cp</code>, and <code>--pp</code> values.</p> <ul> <li><code>TP = 1</code>, <code>CP = 4</code>, <code>PP = 2</code>, <code>DP = 3</code></li> </ul> <pre><code>$ launch python3 -Wignore -m ezpz.test_dist --tp 1 --cp 4 --pp 2\n# ...clipped...\n[2024-12-31 15:36:13.333215][INFO][__init__.py:146] - &gt; initializing model parallel with size 1\n[2024-12-31 15:36:13.333942][INFO][__init__.py:151] - &gt; initializing context parallel with size 4\n[2024-12-31 15:36:13.334476][INFO][__init__.py:156] - &gt; initializing pipeline with size 2\n[2024-12-31 15:36:13.334971][INFO][__init__.py:159] - &gt; initializing ddp with size 3\n[2024-12-31 15:36:14.402809][INFO][dist.py:846] - [ 0/23]: [cp:0/3][pp:0/1][dp:0/2]\n[2024-12-31 15:36:14.402209][INFO][dist.py:846] - [ 3/23]: [cp:3/3][pp:0/1][dp:0/2]\n[2024-12-31 15:36:14.402211][INFO][dist.py:846] - [ 1/23]: [cp:1/3][pp:0/1][dp:0/2]\n[2024-12-31 15:36:14.402197][INFO][dist.py:846] - [ 7/23]: [cp:3/3][pp:1/1][dp:0/2]\n[2024-12-31 15:36:14.402239][INFO][dist.py:846] - [ 4/23]: [cp:0/3][pp:1/1][dp:0/2]\n[2024-12-31 15:36:14.402224][INFO][dist.py:846] - [ 5/23]: [cp:1/3][pp:1/1][dp:0/2]\n[2024-12-31 15:36:14.402200][INFO][dist.py:846] - [ 9/23]: [cp:1/3][pp:0/1][dp:1/2]\n[2024-12-31 15:36:14.402223][INFO][dist.py:846] - [10/23]: [cp:2/3][pp:0/1][dp:1/2]\n[2024-12-31 15:36:14.402229][INFO][dist.py:846] - [ 2/23]: [cp:2/3][pp:0/1][dp:0/2]\n[2024-12-31 15:36:14.402216][INFO][dist.py:846] - [ 8/23]: [cp:0/3][pp:0/1][dp:1/2]\n[2024-12-31 15:36:14.402206][INFO][dist.py:846] - [11/23]: [cp:3/3][pp:0/1][dp:1/2]\n[2024-12-31 15:36:14.402208][INFO][dist.py:846] - [21/23]: [cp:1/3][pp:1/1][dp:2/2]\n[2024-12-31 15:36:14.402256][INFO][dist.py:846] - [12/23]: [cp:0/3][pp:1/1][dp:1/2]\n[2024-12-31 15:36:14.402312][INFO][dist.py:846] - [ 6/23]: [cp:2/3][pp:1/1][dp:0/2]\n[2024-12-31 15:36:14.402233][INFO][dist.py:846] - [13/23]: [cp:1/3][pp:1/1][dp:1/2]\n[2024-12-31 15:36:14.402255][INFO][dist.py:846] - [14/23]: [cp:2/3][pp:1/1][dp:1/2]\n[2024-12-31 15:36:14.402234][INFO][dist.py:846] - [15/23]: [cp:3/3][pp:1/1][dp:1/2]\n[2024-12-31 15:36:14.402252][INFO][dist.py:846] - [16/23]: [cp:0/3][pp:0/1][dp:2/2]\n[2024-12-31 15:36:14.402235][INFO][dist.py:846] - [17/23]: [cp:1/3][pp:0/1][dp:2/2]\n[2024-12-31 15:36:14.402209][INFO][dist.py:846] - [19/23]: [cp:3/3][pp:0/1][dp:2/2]\n[2024-12-31 15:36:14.402218][INFO][dist.py:846] - [20/23]: [cp:0/3][pp:1/1][dp:2/2]\n[2024-12-31 15:36:14.402243][INFO][dist.py:846] - [22/23]: [cp:2/3][pp:1/1][dp:2/2]\n[2024-12-31 15:36:14.402211][INFO][dist.py:846] - [23/23]: [cp:3/3][pp:1/1][dp:2/2]\n[2024-12-31 15:36:14.402291][INFO][dist.py:846] - [18/23]: [cp:2/3][pp:0/1][dp:2/2]\n</code></pre> <ul> <li><code>TP = CP = PP = 2</code>, <code>DP = 3</code></li> </ul> <pre><code>$ launch python3 -Wignore -m ezpz.test_dist --tp 2 --cp 2 --pp 2 #--dtype=float32\n# ...clipped...\n[2024-12-31 15:19:37.033562][INFO][__init__.py:146] - &gt; initializing model parallel with size 2\n[2024-12-31 15:19:37.034083][INFO][__init__.py:151] - &gt; initializing context parallel with size 2\n[2024-12-31 15:19:37.034451][INFO][__init__.py:156] - &gt; initializing pipeline with size 2\n[2024-12-31 15:19:37.034792][INFO][__init__.py:159] - &gt; initializing ddp with size 3\n# ...clipped...\n[2024-12-31 15:19:38.239822][INFO][dist.py:824] - Using device='xpu' with backend='DDP' + 'ccl' for distributed training.\n[2024-12-31 15:19:38.240412][INFO][dist.py:846] - [ 0/23]: [cp:0/1][pp:0/1][tp:0/1][dp:0/2]\n[2024-12-31 15:19:38.239840][INFO][dist.py:846] - [ 1/23]: [cp:0/1][pp:0/1][tp:1/1][dp:0/2]\n[2024-12-31 15:19:38.239826][INFO][dist.py:846] - [ 2/23]: [cp:1/1][pp:0/1][tp:0/1][dp:0/2]\n[2024-12-31 15:19:38.239838][INFO][dist.py:846] - [ 4/23]: [cp:0/1][pp:1/1][tp:0/1][dp:0/2]\n[2024-12-31 15:19:38.239820][INFO][dist.py:846] - [ 6/23]: [cp:1/1][pp:1/1][tp:0/1][dp:0/2]\n[2024-12-31 15:19:38.239835][INFO][dist.py:846] - [ 7/23]: [cp:1/1][pp:1/1][tp:1/1][dp:0/2]\n[2024-12-31 15:19:38.239822][INFO][dist.py:846] - [ 8/23]: [cp:0/1][pp:0/1][tp:0/1][dp:1/2]\n[2024-12-31 15:19:38.239818][INFO][dist.py:846] - [11/23]: [cp:1/1][pp:0/1][tp:1/1][dp:1/2]\n[2024-12-31 15:19:38.239836][INFO][dist.py:846] - [ 3/23]: [cp:1/1][pp:0/1][tp:1/1][dp:0/2]\n[2024-12-31 15:19:38.239845][INFO][dist.py:846] - [ 5/23]: [cp:0/1][pp:1/1][tp:1/1][dp:0/2]\n[2024-12-31 15:19:38.239829][INFO][dist.py:846] - [ 9/23]: [cp:0/1][pp:0/1][tp:1/1][dp:1/2]\n[2024-12-31 15:19:38.239822][INFO][dist.py:846] - [10/23]: [cp:1/1][pp:0/1][tp:0/1][dp:1/2]\n[2024-12-31 15:19:38.239831][INFO][dist.py:846] - [12/23]: [cp:0/1][pp:1/1][tp:0/1][dp:1/2]\n[2024-12-31 15:19:38.239814][INFO][dist.py:846] - [18/23]: [cp:1/1][pp:0/1][tp:0/1][dp:2/2]\n[2024-12-31 15:19:38.239816][INFO][dist.py:846] - [20/23]: [cp:0/1][pp:1/1][tp:0/1][dp:2/2]\n[2024-12-31 15:19:38.239827][INFO][dist.py:846] - [23/23]: [cp:1/1][pp:1/1][tp:1/1][dp:2/2]\n[2024-12-31 15:19:38.239831][INFO][dist.py:846] - [13/23]: [cp:0/1][pp:1/1][tp:1/1][dp:1/2]\n[2024-12-31 15:19:38.239826][INFO][dist.py:846] - [14/23]: [cp:1/1][pp:1/1][tp:0/1][dp:1/2]\n[2024-12-31 15:19:38.239856][INFO][dist.py:846] - [15/23]: [cp:1/1][pp:1/1][tp:1/1][dp:1/2]\n[2024-12-31 15:19:38.239848][INFO][dist.py:846] - [16/23]: [cp:0/1][pp:0/1][tp:0/1][dp:2/2]\n[2024-12-31 15:19:38.239849][INFO][dist.py:846] - [17/23]: [cp:0/1][pp:0/1][tp:1/1][dp:2/2]\n[2024-12-31 15:19:38.239814][INFO][dist.py:846] - [19/23]: [cp:1/1][pp:0/1][tp:1/1][dp:2/2]\n[2024-12-31 15:19:38.239812][INFO][dist.py:846] - [21/23]: [cp:0/1][pp:1/1][tp:1/1][dp:2/2]\n[2024-12-31 15:19:38.239817][INFO][dist.py:846] - [22/23]: [cp:1/1][pp:1/1][tp:0/1][dp:2/2]\n</code></pre> <ul> <li><code>TP = CP = 2</code>, <code>PP = 1</code>, <code>DP = 6</code></li> </ul> <pre><code>$ launch python3 -Wignore -m ezpz.test_dist --tp 2 --cp 2\n# ...clipped...\n[2024-12-31 15:29:21.697491][INFO][__init__.py:146] - &gt; initializing model parallel with size 2\n[2024-12-31 15:29:21.698012][INFO][__init__.py:151] - &gt; initializing context parallel with size 2\n[2024-12-31 15:29:21.698377][INFO][__init__.py:156] - &gt; initializing pipeline with size 1\n[2024-12-31 15:29:21.698745][INFO][__init__.py:159] - &gt; initializing ddp with size 6\n# ...clipped...\n[2024-12-31 15:29:22.900343][INFO][dist.py:846] - [ 0/23]: [cp:0/1][tp:0/1][dp:0/5]\n[2024-12-31 15:29:22.899759][INFO][dist.py:846] - [ 2/23]: [cp:1/1][tp:0/1][dp:0/5]\n[2024-12-31 15:29:22.899758][INFO][dist.py:846] - [ 1/23]: [cp:0/1][tp:1/1][dp:0/5]\n[2024-12-31 15:29:22.899760][INFO][dist.py:846] - [ 5/23]: [cp:0/1][tp:1/1][dp:1/5]\n[2024-12-31 15:29:22.899758][INFO][dist.py:846] - [ 6/23]: [cp:1/1][tp:0/1][dp:1/5]\n[2024-12-31 15:29:22.899745][INFO][dist.py:846] - [ 7/23]: [cp:1/1][tp:1/1][dp:1/5]\n[2024-12-31 15:29:22.899740][INFO][dist.py:846] - [ 8/23]: [cp:0/1][tp:0/1][dp:2/5]\n[2024-12-31 15:29:22.899743][INFO][dist.py:846] - [ 9/23]: [cp:0/1][tp:1/1][dp:2/5]\n[2024-12-31 15:29:22.899741][INFO][dist.py:846] - [10/23]: [cp:1/1][tp:0/1][dp:2/5]\n[2024-12-31 15:29:22.899741][INFO][dist.py:846] - [11/23]: [cp:1/1][tp:1/1][dp:2/5]\n[2024-12-31 15:29:22.899759][INFO][dist.py:846] - [ 3/23]: [cp:1/1][tp:1/1][dp:0/5]\n[2024-12-31 15:29:22.899760][INFO][dist.py:846] - [ 4/23]: [cp:0/1][tp:0/1][dp:1/5]\n[2024-12-31 15:29:22.899756][INFO][dist.py:846] - [19/23]: [cp:1/1][tp:1/1][dp:4/5]\n[2024-12-31 15:29:22.899760][INFO][dist.py:846] - [21/23]: [cp:0/1][tp:1/1][dp:5/5]\n[2024-12-31 15:29:22.899777][INFO][dist.py:846] - [12/23]: [cp:0/1][tp:0/1][dp:3/5]\n[2024-12-31 15:29:22.899775][INFO][dist.py:846] - [13/23]: [cp:0/1][tp:1/1][dp:3/5]\n[2024-12-31 15:29:22.899787][INFO][dist.py:846] - [14/23]: [cp:1/1][tp:0/1][dp:3/5]\n[2024-12-31 15:29:22.899791][INFO][dist.py:846] - [15/23]: [cp:1/1][tp:1/1][dp:3/5]\n[2024-12-31 15:29:22.899781][INFO][disto.py:846] - [16/23]: [cp:0/1][tp:0/1][dp:4/5]\n[2024-12-31 15:29:22.899782][INFO][dist.py:846] - [17/23]: [cp:0/1][tp:1/1][dp:4/5]\n[2024-12-31 15:29:22.899798][INFO][dist.py:846] - [18/23]: [cp:1/1][tp:0/1][dp:4/5]\n[2024-12-31 15:29:22.899755][INFO][dist.py:846] - [20/23]: [cp:0/1][tp:0/1][dp:5/5]\n[2024-12-31 15:29:22.899758][INFO][dist.py:846] - [22/23]: [cp:1/1][tp:0/1][dp:5/5]\n[2024-12-31 15:29:22.899758][INFO][dist.py:846] - [23/23]: [cp:1/1][tp:1/1][dp:5/5]\n</code></pre> World Size TP CP PL DP 24 1 1 1 24 24 2 1 1 12 24 1 2 1 12 24 1 1 2 12 24 2 2 1 6 24 2 1 2 6 24 1 2 2 6 24 4 1 1 6 24 1 4 1 6 24 1 1 4 6 24 4 2 1 3 24 4 1 2 3 24 2 4 1 3 24 2 1 4 3 24 1 4 2 3 24 1 2 4 3 24 4 2 2 3 24 2 4 2 3 24 2 2 2 3"},{"location":"pbs/","title":"\ud83c\udf4b <code>ezpz</code>: PBS Job Management","text":""},{"location":"pbs/#determine-details-of-currently-active-job","title":"\ud83e\udd14 Determine Details of Currently Active Job","text":"<ol> <li>Find all currently running<sup>1</sup> jobs owned by the user.</li> <li> <p>For each of these running jobs, build a dictionary of the form:</p> <pre><code>&gt;&gt;&gt; jobs = ezpz.pbs.get_users_running_pbs_jobs()\n&gt;&gt;&gt; jobs\n{\n    jobid_A: [host_A0, host_A1, host_A2, ..., host_AN],\n    jobid_B: [host_B0, host_B1, host_B2, ..., host_BN],\n    ...,\n}\n</code></pre> </li> <li> <p>Look for our <code>hostname</code> in the list of hosts for each job.</p> </li> <li> <p>If found, we know we are participating in that job.</p> </li> <li> <p>Once we have the <code>PBS_JOBID</code> of the job containing our <code>hostname</code>,    we can find the <code>hostfile</code> for that job.</p> </li> <li>The <code>hostfile</code> is located in <code>/var/spool/pbs/aux/</code>.</li> <li> <p>The filename is of the form <code>jobid.hostname</code>.</p> </li> <li> <p>\u2705 Done!</p> </li> </ol> <p>Example:</p> <pre><code>jobid = ezpz.pbs.get_pbs_jobid_of_active_job()\nnum_nodes = len(jobs[jobid])\nworld_size = num_nodes * ezpz.get_gpus_per_node()\n</code></pre> <ol> <li> <p>| - Running: Can have multiple PBS jobs running at the same time - Active: Can only have one active PBS job at a time     - This is the job that we are currently running on \u21a9</p> </li> </ol>"},{"location":"python-library/","title":"\ud83d\udc0d Python Library","text":"<ul> <li>\ud83d\udc0d Python Library</li> <li>\ud83d\udc40 Overview</li> <li>Install</li> </ul>"},{"location":"python-library/#overview","title":"\ud83d\udc40 Overview","text":"<p>Launch and train across all your accelerators, using your favorite framework + backend combo.</p> <p><code>ezpz</code> simplifies the process of:</p> <ul> <li> <p>Setting up + launching distributed training: <ul> <li> <p><code>import ezpz as ez</code> <ul> <li> <p><code>RANK =</code> <code>ez.setup_torch(backend=backend)</code>   [for <code>backend</code> \\(\\in\\) {<code>DDP</code>, <code>deepspeed</code>, <code>horovod</code>}]{.dim-text}</p> </li> <li> <p><code>RANK =</code> <code>ez.get_rank()</code></p> </li> <li> <p><code>LOCAL_RANK =</code> <code>ez.get_local_rank()</code></p> </li> <li> <p><code>WORLD_SIZE =</code> <code>ez.get_world_size()</code></p> </li> </ul> <p>[(see <code>ezpz/dist.py</code> for more details).]{.dim-text}</p> <ul> <li> <p>Using your favorite framework: <ul> <li> <p><code>framework=pytorch</code> + <code>backend={DDP, deepspeed, horovod}</code></p> </li> <li> <p><code>framework=tensorflow</code> + <code>backend=horovod</code></p> </li> <li> <p><code>ez.get_torch_device()</code>: {<code>cuda</code>, <code>xpu</code>, <code>mps</code>, <code>cpu</code>}</p> </li> <li> <p><code>ez.get_torch_backend()</code>: {<code>nccl</code>, <code>ccl</code>, <code>gloo</code>}</p> </li> </ul> <p>2ez \ud83d\ude0e. (see frameworks for additional details)</p> <ul> <li> <p>Writing device agnostic code: <ul> <li> <p><code>ezpz.get_torch_device()</code> <pre><code>&gt;&gt;&gt; import ezpz as ez\n&gt;&gt;&gt; DEVICE = ez.get_torch_device()\n&gt;&gt;&gt; model = torch.nn.Linear(10, 10)\n&gt;&gt;&gt; model.to(DEVICE)\n&gt;&gt;&gt; x = torch.randn((10, 10), device=DEVICE)\n&gt;&gt;&gt; y = model(x)\n&gt;&gt;&gt; y.device\ndevice(type='mps', index=0)\n</code></pre> <ul> <li> <p>Using <code>wandb</code>: <ul> <li><code>ez.setup_wandb(project_name='ezpz')</code></li> </ul> <ul> <li>Full support for any {<code>device</code> + <code>framework</code> + <code>backend</code>}:<ul> <li>device: {<code>GPU</code>, <code>XPU</code>, <code>MPS</code>, <code>CPU</code>}</li> <li>framework: {<code>torch</code>, <code>deepspeed</code>, <code>horovod</code>, <code>tensorflow</code>}</li> <li>backend: {<code>DDP</code>, <code>deepspeed</code>, <code>horovod</code>}</li> </ul> </li> </ul>"},{"location":"python-library/#install","title":"Install","text":"<p>To install<sup>1</sup>:</p> <pre><code>python3 -m pip install -e \"git+https://github.com/saforem2/ezpz#egg=ezpz\" --require-virtualenv\n</code></pre> <ul> <li>\ud83d\udcc2 <code>ezpz</code> / <code>src</code> / <code>ezpz/</code></li> <li>\ud83d\udcc2     <code>bin/</code>:<ul> <li><code>utils.sh</code>:   Shell utilities for <code>ezpz</code></li> </ul> </li> <li>\ud83d\udcc2     <code>conf/</code>:<ul> <li>\u2699\ufe0f   <code>config.yaml</code>:   Default <code>TrainConfig</code> object</li> <li>\u2699\ufe0f   <code>ds_config.json</code>:   DeepSpeed configuration</li> </ul> </li> <li>\ud83d\udcc2     <code>log/</code>:     Logging configuration.</li> <li>\ud83d\udc0d     <code>__about__.py</code>:     Version information</li> <li>\ud83d\udc0d     <code>__init__.py</code>:     Main module</li> <li>\ud83d\udc0d     <code>__main__.py</code>:     Entry point</li> <li>\ud83d\udc0d     <code>configs.py</code>:     Configuration module</li> <li>\ud83d\udc0d<code>cria.py</code>:     Baby Llama</li> <li>\ud83d\udc0d<code>dist.py</code>:     Distributed training module</li> <li>\ud83d\udc0d<code>history.py</code>:     History module</li> <li>\ud83d\udc0d<code>jobs.py</code>:     Jobs module</li> <li>\ud83d\udc0d<code>model.py</code>:     Model module</li> <li>\ud83d\udc0d<code>plot.py</code>:     Plot modul</li> <li>\ud83d\udc0d<code>profile.py</code>:     Profile module</li> <li>\ud83d\udc0d<code>runtime.py</code>:     Runtime module</li> <li>\ud83d\udc0d<code>test.py</code>:     Test module</li> <li>\ud83d\udc0d<code>test_dist.py</code>:     Distributed training test module</li> <li>\ud83d\udc0d<code>train.py</code>:     train module</li> <li>\ud83d\udc0d<code>trainer.py</code>:     trainer module</li> <li>\ud83d\udc0d<code>utils.py</code>:     utility module</li> </ul> <pre><code>\ud83d\udcc2 /ezpz/src/ezpz/\n\u2523\u2501\u2501 \ud83d\udcc2 bin/\n\u2503   \u2523\u2501\u2501 \ud83d\udcc4 affinity.sh\n\u2503   \u2523\u2501\u2501 \ud83d\udcc4 getjobenv\n\u2503   \u2523\u2501\u2501 \ud83d\udcc4 savejobenv\n\u2503   \u2523\u2501\u2501 \ud83d\udcc4 saveslurmenv\n\u2503   \u2523\u2501\u2501 \ud83d\udcc4 setup.sh\n\u2503   \u2523\u2501\u2501 \ud83d\udcc4 train.sh\n\u2503   \u2517\u2501\u2501 \ud83d\udcc4 utils.sh\n\u2523\u2501\u2501 \ud83d\udcc2 conf/\n\u2503   \u2523\u2501\u2501 \ud83d\udcc2 hydra/\n\u2503   \u2503   \u2517\u2501\u2501 \ud83d\udcc2 job_logging/\n\u2503   \u2503       \u2523\u2501\u2501 \u2699\ufe0f colorlog1.yaml\n\u2503   \u2503       \u2523\u2501\u2501 \u2699\ufe0f custom.yaml\n\u2503   \u2503       \u2517\u2501\u2501 \u2699\ufe0f enrich.yaml\n\u2503   \u2523\u2501\u2501 \ud83d\udcc2 logdir/\n\u2503   \u2503   \u2517\u2501\u2501 \u2699\ufe0f default.yaml\n\u2503   \u2523\u2501\u2501 \u2699\ufe0f config.yaml\n\u2503   \u2523\u2501\u2501 \ud83d\udcc4 ds_config.json\n\u2503   \u2517\u2501\u2501 \u2699\ufe0f ds_config.yaml\n\u2523\u2501\u2501 \ud83d\udcc2 log/\n\u2503   \u2523\u2501\u2501 \ud83d\udcc2 conf/\n\u2503   \u2503   \u2517\u2501\u2501 \ud83d\udcc2 hydra/\n\u2503   \u2503       \u2517\u2501\u2501 \ud83d\udcc2 job_logging/\n\u2503   \u2503           \u2517\u2501\u2501 \u2699\ufe0f enrich.yaml\n\u2503   \u2523\u2501\u2501 \ud83d\udc0d __init__.py\n\u2503   \u2523\u2501\u2501 \ud83d\udc0d __main__.py\n\u2503   \u2523\u2501\u2501 \ud83d\udc0d config.py\n\u2503   \u2523\u2501\u2501 \ud83d\udc0d console.py\n\u2503   \u2523\u2501\u2501 \ud83d\udc0d handler.py\n\u2503   \u2523\u2501\u2501 \ud83d\udc0d style.py\n\u2503   \u2523\u2501\u2501 \ud83d\udc0d test.py\n\u2503   \u2517\u2501\u2501 \ud83d\udc0d test_log.py\n\u2523\u2501\u2501 \ud83d\udc0d __about__.py\n\u2523\u2501\u2501 \ud83d\udc0d __init__.py\n\u2523\u2501\u2501 \ud83d\udc0d __main__.py\n\u2523\u2501\u2501 \ud83d\udc0d configs.py\n\u2523\u2501\u2501 \ud83d\udc0d cria.py\n\u2523\u2501\u2501 \ud83d\udc0d dist.py\n\u2523\u2501\u2501 \ud83d\udc0d history.py\n\u2523\u2501\u2501 \ud83d\udc0d jobs.py\n\u2523\u2501\u2501 \ud83d\udc0d loadjobenv.py\n\u2523\u2501\u2501 \ud83d\udc0d model.py\n\u2523\u2501\u2501 \ud83d\udc0d plot.py\n\u2523\u2501\u2501 \ud83d\udc0d profile.py\n\u2523\u2501\u2501 \ud83d\udc0d runtime.py\n\u2523\u2501\u2501 \ud83d\udc0d savejobenv.py\n\u2523\u2501\u2501 \ud83d\udc0d test.py\n\u2523\u2501\u2501 \ud83d\udc0d test_dist.py\n\u2523\u2501\u2501 \ud83d\udc0d train.py\n\u2523\u2501\u2501 \ud83d\udc0d trainer.py\n\u2517\u2501\u2501 \ud83d\udc0d utils.py\n</code></pre> <ol> <li> <p>Note the <code>--require-virtualenv</code> isn\u2019t strictly required, but I highly recommend to always try and work within a virtual environment, when possible.\u00a0\u21a9</p> </li> </ol>"},{"location":"shell-environment/","title":"\ud83c\udfd6\ufe0f Shell Environment","text":"<ul> <li>\ud83c\udfd6\ufe0f Shell Environment</li> <li>\ud83d\udc23 Getting Started<ul> <li>\ud83d\udee0\ufe0f Setup Python</li> <li>\ud83e\uddf0 Setup Job</li> </ul> </li> </ul>"},{"location":"shell-environment/#getting-started","title":"\ud83d\udc23 Getting Started","text":"<p>[!WARNING] The documentation below is a work in progress. Please feel free to provide input / suggest changes !</p> <p>[!NOTE] 1. Source the <code>src/ezpz/bin/utils.sh</code> file:</p> <pre><code>``` bash\nsource &lt;(curl -s https://raw.githubusercontent.com/saforem2/ezpz/refs/heads/main/src/ezpz/bin/utils.sh)\n```\n</code></pre> <ol> <li> <p>Use the <code>ezpz_setup_env</code> function to setup your environment:</p> <pre><code>ezpz_setup_env\n</code></pre> </li> </ol> <p>This will \ud83e\ude84 automagically:</p> <ol> <li>\ud83d\udc0d Setup Python: Load the appropriate module(s)    and put you inside a suitable python environment</li> <li>\ud83e\uddf0 Setup Job: Determine the resources available in the    current job and build a <code>launch</code> alias for launching executables</li> </ol> <p>We provide a variety of helper functions designed to make your life easier when working with job schedulers (e.g.\u00a0<code>PBS Pro</code> @ ALCF or <code>slurm</code> elsewhere).</p> <p>All of these functions are:</p> <ul> <li>located in <code>utils.sh</code></li> <li>prefixed with <code>ezpz_*</code> (e.g.\u00a0<code>ezpz_setup_python</code>)<sup>1</sup></li> </ul> <p>We would like to write our application in such a way that it is able to take full advantage of the resources allocated by the job scheduler.</p> <p>That is to say, we want to have a single script with the ability to dynamically <code>launch</code> python applications across any number of accelerators on any of the systems under consideration.</p> <p>In order to do this, there is some basic setup and information gathering that needs to occur.</p> <p>In particular, we need mechanisms for:</p> <ol> <li>Setting up a python environment</li> <li>Determining what system / machine we\u2019re on<ul> <li>+ what job scheduler we\u2019re using (e.g.\u00a0<code>PBS Pro</code> @ ALCF or   <code>slurm</code> elsewhere)</li> </ul> </li> <li>Determining how many nodes have been allocated in the current job     (<code>NHOSTS</code>)<ul> <li>+ Determining how many accelerators exist on each of these nodes   (<code>NGPU_PER_HOST</code>)</li> </ul> </li> </ol> <p>This allows us to calculate the total number of accelerators (GPUs) as: \\(N_{\\mathrm{GPU}} = N_{\\mathrm{HOST}} \\times n_{\\mathrm{GPU}}\\)</p> <p>where \\(n_{\\mathrm{GPU}} = N_{\\mathrm{GPU}} / N_{\\mathrm{HOST}}\\) is the number of GPUs per host.</p> <p>With this we have everything we need to build the appropriate {<code>mpi</code>{<code>run</code>, <code>exec</code>}, <code>slurm</code>} command for launching our python application across them.</p> <p>Now, there are a few functions in particular worth elaborating on.</p>   | Function                     | Description                                                                               | |------------------------------|-------------------------------------------------------------------------------------------| | `ezpz_setup_env`             | Wrapper around `ezpz_setup_python` `&amp;&amp;` `ezpz_setup_job`                                  | | `ezpz_setup_job`             | Determine {`NGPUS`, `NGPU_PER_HOST`, `NHOSTS`}, build `launch` command alias              | | `ezpz_setup_python`          | Wrapper around `ezpz_setup_conda` `&amp;&amp;` `ezpz_setup_venv_from_conda`                       | | `ezpz_setup_conda`           | Find and activate appropriate `conda` module to load[^2]                                  | | `ezpz_setup_venv_from_conda` | From `${CONDA_NAME}`, build or activate the virtual env located in `venvs/${CONDA_NAME}/` |  Table\u00a01: Shell Functions   <p>[!WARNING]</p>"},{"location":"shell-environment/#where-am-i","title":"Where am I?","text":"<p>Some of the <code>ezpz_*</code> functions (e.g.\u00a0<code>ezpz_setup_python</code>), will try to create / look for certain directories.</p> <p>In an effort to be explicit, these directories will be defined relative to a <code>WORKING_DIR</code> (e.g.\u00a0<code>\"${WORKING_DIR}/venvs/\"</code>)</p> <p>This <code>WORKING_DIR</code> will be assigned to the first non-zero match found below:</p> <ol> <li><code>PBS_O_WORKDIR</code>: If found in environment, paths will be relative     to this</li> <li><code>SLURM_SUBMIT_DIR</code>: Next in line. If not @ ALCF, maybe using     <code>slurm</code>\u2026</li> <li><code>$(pwd)</code>: Otherwise, no worries. Use your actual working     directory.</li> </ol>"},{"location":"shell-environment/#setup-python","title":"\ud83d\udee0\ufe0f Setup Python","text":"<pre><code>ezpz_setup_python\n</code></pre> <p>This will:</p> <ol> <li> <p>Automatically load and activate <code>conda</code> using the <code>ezpz_setup_conda</code>     function.</p> <p>How this is done, in practice, varies from machine to machine:</p> <ul> <li> <p>ALCF<sup>3</sup>: Automatically load the most recent <code>conda</code> module   and activate the base environment.</p> </li> <li> <p>Frontier: Load the appropriate AMD modules (e.g.\u00a0<code>rocm</code>,   <code>RCCL</code>, etc.), and activate base <code>conda</code></p> </li> <li> <p>Perlmutter: Load the appropriate <code>pytorch</code> module and activate   environment</p> </li> <li> <p>Unknown: In this case, we will look for a <code>conda</code>, <code>mamba</code>, or   <code>micromamba</code> executable, and if found, use that to activate the   base environment.</p> </li> </ul> </li> </ol> <p>[!TIP]</p> <p>Using your own <code>conda</code></p> <p>If you are already in a conda environment when calling <code>ezpz_setup_python</code> then it will try and use this instead.</p> <p>For example, if you have a custom <code>conda</code> env at <code>~/conda/envs/custom</code>, then this would bootstrap the <code>custom</code> conda environment and create the virtual env in <code>venvs/custom/</code></p> <ol> <li> <p>Build (or activate, if found) a virtual environment on top of (the     active) base <code>conda</code> environment.</p> <p>By default, it will try looking in:</p> <ul> <li><code>$PBS_O_WORKDIR</code>, otherwise</li> <li><code>${SLURM_SUBMIT_DIR}</code>, otherwise</li> <li><code>$(pwd)</code></li> </ul> <p>for a nested folder named <code>\"venvs/${CONDA_NAME}\"</code>.</p> <p>If this doesn\u2019t exist, it will attempt to create a new virtual environment at this location using:</p> <pre><code>python3 -m venv venvs/${CONDA_NAME} --system-site-packages\n</code></pre> <p>(where we\u2019ve pulled in the <code>--system-site-packages</code> from conda).</p> </li> </ol>"},{"location":"shell-environment/#setup-job","title":"\ud83e\uddf0 Setup Job","text":"<pre><code>ezpz_setup_job\n</code></pre> <p>Now that we are in a suitable python environment, we need to construct the command that we will use to run python on each of our accelerators.</p> <p>To do this, we need a few things:</p> <ol> <li>What machine we\u2019re on (and what scheduler is it using i.e.\u00a0{PBS,     SLURM})</li> <li>How many nodes are available in our active job</li> <li>How many GPUs are on each of those nodes</li> <li>What type of GPUs are they</li> </ol> <p>With this information, we can then use <code>mpi{exec,run}</code> or <code>srun</code> to launch python across all of our accelerators.</p> <p>Again, how this is done will vary from machine to machine and will depend on the job scheduler in use.</p> <p>To identify where we are, we look at our <code>$(hostname)</code> and see if we\u2019re running on one of the known machines:</p> <ul> <li>ALCF<sup>4</sup>: Using PBS Pro via <code>qsub</code> and <code>mpiexec</code> / <code>mpirun</code>.</li> <li><code>x4*</code>: Aurora</li> <li>Aurora: <code>x4*</code> (or <code>aurora*</code> on login nodes)</li> <li>Sunspot: <code>x1*</code> (or <code>uan*</code>)</li> <li>Sophia: <code>sophia-*</code></li> <li>Polaris / Sirius: <code>x3*</code><ul> <li>to determine between the two, we look at <code>\"${PBS_O_HOST}\"</code></li> </ul> </li> </ul> <ul> <li> <p>OLCF: Using Slurm via <code>sbatch</code> / <code>srun</code>.</p> </li> <li> <p><code>frontier*</code>: Frontier, using Slurm</p> </li> <li> <p><code>nid*</code>: Perlmutter, using Slurm</p> </li> <li> <p>Unknown machine: If <code>$(hostname)</code> does not match one of these patterns   we assume that we are running on an unknown machine and will try to   use <code>mpirun</code> as our generic launch command</p> </li> </ul> <p>Once we have this, we can:</p> <ol> <li> <p>Get <code>PBS_NODEFILE</code> from <code>$(hostname)</code>:</p> <ul> <li> <p><code>ezpz_qsme_running</code>: For each (running) job owned by <code>${USER}</code>,     print out both the jobid as well as a list of hosts the job is     running on, e.g.:</p> <pre><code>&lt;jobid0&gt; host00 host01 host02 host03 ...\n&lt;jobid1&gt; host10 host11 host12 host13 ...\n...\n</code></pre> </li> <li> <p><code>ezpz_get_pbs_nodefile_from_hostname</code>: Look for <code>$(hostname)</code> in     the output from the above command to determine our     <code>${PBS_JOBID}</code>.</p> <p>Once we\u2019ve identified our <code>${PBS_JOBID}</code> we then know the location of our <code>${PBS_NODEFILE}</code> since they are named according to:</p> <pre><code>jobid=$(ezpz_qsme_running | grep \"$(hostname)\" | awk '{print $1}')\nprefix=/var/spool/pbs/aux\nmatch=$(/bin/ls \"${prefix}\" | grep \"${jobid}\")\nhostfile=\"${prefix}/${match}\"\n</code></pre> </li> </ul> </li> <li> <p>Identify number of available accelerators:</p> </li> </ol> <ol> <li> <p>Plus this is useful for tab-completions in your shell, e.g.:</p> <p><pre><code>$ ezpz_&lt;TAB&gt;\nezpz_check_and_kill_if_running\nezpz_get_dist_launch_cmd\nezpz_get_job_env\n--More--\n</code></pre> \u21a9</p> </li> <li> <p>This is system dependent. See <code>ezpz_setup_conda</code> \u21a9</p> </li> <li> <p>Any of {Aurora, Polaris, Sophia, Sunspot, Sirius}\u00a0\u21a9</p> </li> <li> <p>At ALCF, if our <code>$(hostname)</code> starts with <code>x*</code>, we\u2019re on a compute node.\u00a0\u21a9</p> </li> </ol>"},{"location":"Code-Reference/config-reference/","title":"<code>ezpz.configs</code>","text":"<p>ezpz/configs.py</p>"},{"location":"Code-Reference/config-reference/#ezpz.configs.cmd_exists","title":"<code>cmd_exists(cmd)</code>","text":"<p>Check whether command exists.</p> <p>cmd_exists(\"ls\") True cmd_exists(\"hostname\") True</p> Source code in <code>src/ezpz/configs.py</code> <pre><code>def cmd_exists(cmd: str) -&gt; bool:\n    \"\"\"Check whether command exists.\n\n    &gt;&gt;&gt; cmd_exists(\"ls\")\n    True\n    &gt;&gt;&gt; cmd_exists(\"hostname\")\n    True\n    \"\"\"\n    return shutil.which(cmd) is not None\n</code></pre>"},{"location":"Code-Reference/config-reference/#ezpz.configs.print_config_tree","title":"<code>print_config_tree(cfg, resolve=True, save_to_file=True, verbose=True, style='tree', print_order=None, highlight=True, outfile=None)</code>","text":"<p>Prints the contents of a DictConfig as a tree structure using the Rich library.</p> <ul> <li>cfg: A DictConfig composed by Hydra.</li> <li>print_order: Determines in what order config components are printed.</li> <li>resolve: Whether to resolve reference fields of DictConfig.</li> <li>save_to_file: Whether to export config to the hydra output folder.</li> </ul> Source code in <code>src/ezpz/configs.py</code> <pre><code>def print_config_tree(\n    cfg: DictConfig,\n    resolve: bool = True,\n    save_to_file: bool = True,\n    verbose: bool = True,\n    style: str = \"tree\",\n    print_order: Optional[Sequence[str]] = None,\n    highlight: bool = True,\n    outfile: Optional[Union[str, os.PathLike, Path]] = None,\n) -&gt; Tree:\n    \"\"\"Prints the contents of a DictConfig as a tree structure using the Rich\n    library.\n\n    - cfg: A DictConfig composed by Hydra.\n    - print_order: Determines in what order config components are printed.\n    - resolve: Whether to resolve reference fields of DictConfig.\n    - save_to_file: Whether to export config to the hydra output folder.\n    \"\"\"\n    from rich.console import Console\n    from ezpz.log.config import STYLES\n    from rich.theme import Theme\n\n    name = cfg.get(\"_target_\", \"cfg\")\n    console = Console(record=True, theme=Theme(STYLES))\n    tree = Tree(label=name, highlight=highlight)\n    queue = []\n    # add fields from `print_order` to queue\n    if print_order is not None:\n        for field in print_order:\n            (\n                queue.append(field)\n                if field in cfg\n                else log.warning(\n                    f\"Field '{field}' not found in config. \"\n                    f\"Skipping '{field}' config printing...\"\n                )\n            )\n    # add all the other fields to queue (not specified in `print_order`)\n    for field in cfg:\n        if field not in queue:\n            queue.append(field)\n    # generate config tree from queue\n    for field in queue:\n        branch = tree.add(field, highlight=highlight)  # , guide_style=style)\n        config_group = cfg[field]\n        if isinstance(config_group, DictConfig):\n            branch_content = str(\n                OmegaConf.to_yaml(config_group, resolve=resolve)\n            )\n            branch.add(Text(branch_content, style=\"red\"))\n        else:\n            branch_content = str(config_group)\n            branch.add(Text(branch_content, style=\"blue\"))\n    if verbose or save_to_file:\n        console.print(tree)\n        if save_to_file:\n            outfpath = (\n                Path(os.getcwd()).joinpath(\"config_tree.log\")\n                if outfile is None\n                else Path(outfile)\n            )\n            console.save_text(outfpath.as_posix())\n    return tree\n</code></pre>"},{"location":"Code-Reference/config-reference/#ezpz.configs.print_json","title":"<code>print_json(json_str=None, console=None, *, data=None, indent=2, highlight=True, skip_keys=False, ensure_ascii=False, check_circular=True, allow_nan=True, default=None, sort_keys=False)</code>","text":"<p>Pretty prints JSON. Output will be valid JSON.</p> <p>Parameters:</p> Name Type Description Default <code>json_str</code> <code>Optional[str]</code> <p>A string containing JSON.</p> <code>None</code> <code>data</code> <code>Any</code> <p>If json is not supplied, then encode this data.</p> <code>None</code> <code>indent</code> <code>Union[None, int, str]</code> <p>Number of spaces to indent. Defaults to 2.</p> <code>2</code> <code>highlight</code> <code>bool</code> <p>Enable highlighting of output: Defaults to True.</p> <code>True</code> <code>skip_keys</code> <code>bool</code> <p>Skip keys not of a basic type. Defaults to False.</p> <code>False</code> <code>ensure_ascii</code> <code>bool</code> <p>Escape all non-ascii characters. Defaults to False.</p> <code>False</code> <code>check_circular</code> <code>bool</code> <p>Check for circular references. Defaults to True.</p> <code>True</code> <code>allow_nan</code> <code>bool</code> <p>Allow NaN and Infinity values. Defaults to True.</p> <code>True</code> <code>default</code> <code>Callable</code> <p>A callable that converts values that can not be encoded in to something that can be JSON encoded. Defaults to None.</p> <code>None</code> <code>sort_keys</code> <code>bool</code> <p>Sort dictionary keys. Defaults to False.</p> <code>False</code> Source code in <code>src/ezpz/configs.py</code> <pre><code>def print_json(\n    json_str: Optional[str] = None,\n    console: Optional[Console] = None,\n    *,\n    data: Any = None,\n    indent: Union[None, int, str] = 2,\n    highlight: bool = True,\n    skip_keys: bool = False,\n    ensure_ascii: bool = False,\n    check_circular: bool = True,\n    allow_nan: bool = True,\n    default: Optional[Callable[[Any], Any]] = None,\n    sort_keys: bool = False,\n) -&gt; None:\n    \"\"\"Pretty prints JSON. Output will be valid JSON.\n\n    Args:\n        json_str (Optional[str]): A string containing JSON.\n        data (Any): If json is not supplied, then encode this data.\n        indent (Union[None, int, str], optional): Number of spaces to indent.\n            Defaults to 2.\n        highlight (bool, optional): Enable highlighting of output:\n            Defaults to True.\n        skip_keys (bool, optional): Skip keys not of a basic type.\n            Defaults to False.\n        ensure_ascii (bool, optional): Escape all non-ascii characters.\n            Defaults to False.\n        check_circular (bool, optional): Check for circular references.\n            Defaults to True.\n        allow_nan (bool, optional): Allow NaN and Infinity values.\n            Defaults to True.\n        default (Callable, optional): A callable that converts values\n            that can not be encoded in to something that can be JSON\n            encoded.\n            Defaults to None.\n        sort_keys (bool, optional): Sort dictionary keys. Defaults to False.\n    \"\"\"\n    from ezpz.log.console import get_console\n    from rich.json import JSON\n\n    console = get_console() if console is None else console\n    if json_str is None:\n        json_renderable = JSON.from_data(\n            data,\n            indent=indent,\n            highlight=highlight,\n            skip_keys=skip_keys,\n            ensure_ascii=ensure_ascii,\n            check_circular=check_circular,\n            allow_nan=allow_nan,\n            default=default,\n            sort_keys=sort_keys,\n        )\n    else:\n        if not isinstance(json_str, str):\n            raise TypeError(\n                f\"json must be str. Did you mean print_json(data={json_str!r}) ?\"\n            )\n        json_renderable = JSON(\n            json_str,\n            indent=indent,\n            highlight=highlight,\n            skip_keys=skip_keys,\n            ensure_ascii=ensure_ascii,\n            check_circular=check_circular,\n            allow_nan=allow_nan,\n            default=default,\n            sort_keys=sort_keys,\n        )\n    assert console is not None and isinstance(console, Console)\n    log.info(Text(str(json_renderable)).render(console=console))\n</code></pre>"},{"location":"Code-Reference/dist-reference/","title":"dist module","text":"<p>dist.py</p> <p>Contains methods for initializing distributed communication.</p>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.check","title":"<code>check(framework='pytorch', backend='deepspeed', port='5432')</code>","text":"<p>Check if the framework is installed and working</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def check(\n    framework: str = \"pytorch\",\n    backend: str = \"deepspeed\",\n    port: int | str = \"5432\",\n):\n    \"\"\"Check if the framework is installed and working\"\"\"\n    from ezpz.configs import FRAMEWORKS\n\n    if framework in FRAMEWORKS[\"pytorch\"]:\n        _ = setup_torch(\n            backend=backend,\n            port=str(port),\n        )\n    elif framework in FRAMEWORKS[\"tensorflow\"]:\n        _ = setup_tensorflow()\n    else:\n        raise ValueError(f\"Unable to parse framework: {framework}\")\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_cpus_per_node","title":"<code>get_cpus_per_node()</code>","text":"<p>Get the number of CPUs per node</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_cpus_per_node() -&gt; int:\n    \"\"\"Get the number of CPUs per node\"\"\"\n    from sh import getconf as sh_getconf  # type:ignore noqa\n\n    return int(sh_getconf(\"_NPROCESSORS_ONLN\").rstrip(\"\\n\"))\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_gpus_per_node","title":"<code>get_gpus_per_node()</code>","text":"<p>Get the number of GPUs per node</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_gpus_per_node() -&gt; int:\n    \"\"\"Get the number of GPUs per node\"\"\"\n    # return torch.cuda.device_count() if torch.cuda.is_available() else (\n    #     (\n    #         ipex.xpu.device_count() if ipex is not None else (\n    #             get_cpus_per_node()\n    #         )\n    #     )\n    # )\n    # if _assert:\n    #     raise RuntimeError(\n    #         'No {X, G}pus found; but _assert specified. Returning !!'\n    #     )\n    # logger.warning('No {x,g}-pus found, returning' + f'{cpus_per_node}')\n    ngpu_per_host = os.environ.get(\"NGPU_PER_HOST\", None)\n    if ngpu_per_host is not None:\n        return int(ngpu_per_host)\n    if torch.cuda.is_available():\n        return torch.cuda.device_count()\n    if torch.xpu.is_available():\n        return torch.xpu.device_count()\n    if ipex is not None:\n        return ipex.xpu.device_count()  # type:ignore\n    return get_cpus_per_node()\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_hostfile_with_fallback","title":"<code>get_hostfile_with_fallback(hostfile=None)</code>","text":"<p>Get the hostfile from the environment or create one if it doesn't exist</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_hostfile_with_fallback(hostfile: Optional[PathLike] = None) -&gt; Path:\n    \"\"\"Get the hostfile from the environment or create one if it doesn't exist\"\"\"\n    from ezpz.configs import get_scheduler\n\n    scheduler = get_scheduler()\n    if scheduler.lower() == \"unknown\":\n        logger.debug(\"Unknown scheduler\")\n        hostfile = Path(os.getcwd()).joinpath('hostfile')\n    if scheduler.lower() == \"slurm\":\n        hostfile = make_hostfile_from_slurm_env()\n        assert Path(hostfile).is_file()\n    if hostfile is None:\n        hfp = os.environ.get(\n            \"PBS_NODEFILE\",\n            os.environ.get(\n                \"HOSTFILE\",\n                None,  # fallback_hostfile.as_posix()\n            ),\n        )\n        if (\n            hfp is None or not Path(hfp).is_file()\n            # and scheduler == 'PBS'\n        ):\n            if scheduler == \"PBS\":\n                hfp = Path(get_pbs_nodefile_from_qstat())\n            else:\n                # create makeshift hostfile containing 'localhost'\n                hfp = Path(os.getcwd()).joinpath(\"hostfile\")\n                hfp.touch(exist_ok=True)\n                write_localhost_to_hostfile(hfp)\n    else:\n        hfp = Path(hostfile)\n    assert hfp is not None and Path(hfp).is_file()\n    assert Path(hfp).is_file()\n    hostfile = Path(hfp).as_posix()\n    # if hfp is not None:\n    # hostfile, hosts = get_hosts_from_hostfile(hostfile)\n    # hosts = [h.split('.')[0] for h in hosts]\n    # if scheduler == 'PBS':\n    #     os.environ['PBS_NODEFILE'] = hostfile  # hfp.as_posix()\n    hfname = f\"{scheduler.upper()}_NODEFILE\"\n    if hfname not in os.environ:\n        os.environ |= {hfname: hostfile}\n    # os.environ[f'{scheduler.upper()}_NODEFILE'] = hostfile\n    return Path(hfp)\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_local_rank","title":"<code>get_local_rank()</code>","text":"<p>Return <code>get_rank() % get_gpus_per_node()</code></p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_local_rank() -&gt; int:\n    \"\"\"Return `get_rank() % get_gpus_per_node()`\"\"\"\n    return int(get_rank() % get_gpus_per_node())\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_node_index","title":"<code>get_node_index()</code>","text":"<p>Get the index of the current node in the hostfile</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_node_index() -&gt; int:\n    \"\"\"Get the index of the current node in the hostfile\"\"\"\n    return get_rank() % get_num_nodes()\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_num_nodes","title":"<code>get_num_nodes(hostfile=None)</code>","text":"<p>Get the number of nodes from the hostfile</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_num_nodes(hostfile: Optional[PathLike] = None) -&gt; int:\n    \"\"\"Get the number of nodes from the hostfile\"\"\"\n    num_nodes = os.environ.get(\"SLURM_NNODES\", None)\n    if num_nodes is not None:\n        return int(num_nodes)\n    hfp = get_hostfile_with_fallback(hostfile)\n    hosts = [h.split(\".\")[0] for h in get_nodes_from_hostfile(hfp)]\n    return len(hosts)\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_pbs_env","title":"<code>get_pbs_env(hostfile=None, verbose=None)</code>","text":"<p>Get the PBS environment variables</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_pbs_env(\n    hostfile: Optional[Union[str, Path]] = None,\n    verbose: Optional[bool] = None,\n) -&gt; dict[str, str]:\n    \"\"\"Get the PBS environment variables\"\"\"\n    from ezpz.configs import get_scheduler\n\n    assert get_scheduler() == \"PBS\"\n    pbsenv = {k: v for k, v in dict(os.environ).items() if \"PBS\" in k}\n    if hostfile is None:\n        hostfile = pbsenv.get(\"PBS_NODEFILE\", get_pbs_nodefile_from_qstat())\n    if (hfp := Path(hostfile)).is_file():\n        pbsenv |= {\n            f\"{k.upper()}\": f\"{v}\" for k, v in get_pbs_launch_info(hfp).items()\n        }\n        pbsenv |= {\"LAUNCH_CMD\": get_pbs_launch_cmd(hostfile=hostfile)}\n    os.environ |= pbsenv\n    if verbose and get_rank() == 0:\n        # logger.debug(f'pbsenv={json.dumps(pbsenv, indent=4, sort_keys=True)}')\n        log_dict_as_bulleted_list(pbsenv, name=\"pbsenv\")\n    return pbsenv\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_pbs_jobid_from_qstat","title":"<code>get_pbs_jobid_from_qstat()</code>","text":"<p>Get the PBS job ID from qstat</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_pbs_jobid_from_qstat() -&gt; int:\n    \"\"\"Get the PBS job ID from qstat\"\"\"\n    from ezpz.configs import get_scheduler\n\n    assert get_scheduler() == \"PBS\"\n    try:\n        from sh import qstat as sh_qstat  # pyright:ignore\n    except Exception as exc:\n        raise exc\n    qstat_out = sh_qstat(\"-u\", os.environ.get(\"USER\")).split(\"\\n\")[2:-1]\n    return int(qstat_out[-1].split(\".\")[0])\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_pbs_launch_cmd","title":"<code>get_pbs_launch_cmd(ngpus=None, nhosts=None, ngpu_per_host=None, hostfile=None)</code>","text":"<p>Get the PBS launch command</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_pbs_launch_cmd(\n    ngpus: Optional[int] = None,\n    nhosts: Optional[int] = None,\n    ngpu_per_host: Optional[int] = None,\n    hostfile: Optional[PathLike] = None,\n) -&gt; str:\n    \"\"\"Get the PBS launch command\"\"\"\n    nhosts = get_num_nodes(hostfile=hostfile) if nhosts is None else nhosts\n    ngpu_per_host = (\n        get_gpus_per_node() if ngpu_per_host is None else ngpu_per_host\n    )\n    ngpus_available = get_world_size_total() if ngpus is None else ngpus\n    ngpus_in_use = nhosts * ngpu_per_host\n    hfp = Path(\n        get_hostfile_with_fallback(hostfile) if hostfile is None else hostfile\n    )\n    if ngpus_available != (ngpus_in_use):\n        logger.warning(\n            \"Mismatch in `ngpus_in_use` and `ngpus_available` \"\n            f\"{ngpus_in_use=} vs. {ngpus_available=}\"\n        )\n    return \" \".join(\n        [\n            \"mpiexec\",\n            \"--verbose\",\n            \"--envall\",\n            # f'-n {ngpus}',\n            f\"-n {ngpus_in_use}\",\n            f\"-ppn {ngpu_per_host}\",\n            f\"--hostfile {hfp.as_posix()}\",\n            \"--cpu-bind depth\",\n            \"-d 16\",\n        ]\n    )\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_pbs_launch_info","title":"<code>get_pbs_launch_info(hostfile=None)</code>","text":"<p>Get the PBS launch info</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_pbs_launch_info(\n    hostfile: Optional[str | Path] = None,  # type:ignore[reportDeprecated]\n) -&gt; dict[str, str]:\n    \"\"\"Get the PBS launch info\"\"\"\n    from ezpz.configs import get_scheduler\n\n    assert get_scheduler() == \"PBS\"\n    if hostfile is None:\n        hostfile = os.environ.get(\"PBS_NODEFILE\", get_pbs_nodefile_from_qstat())\n    assert hostfile is not None\n    hfp = Path(hostfile)\n    # hostfile = os.environ.get(\"PBS_NODEFILE\", None)\n    # if hostfile is None:\n    #     hostfile = (\n    #             get_pbs_nodefile_from_qstat() if hostfile is None else\n    #             Path(hostfile)\n    #     )\n    # assert hostfile is not None\n    # hf = Path(hostfile)\n    # assert hostfile is not None and hf.is_file()\n    # hfp = Path(hostfile)\n    hosts = get_nodes_from_hostfile(hfp)\n    hosts = [h.split(\".\")[0] for h in hosts]\n    nhosts = len(hosts)\n    ngpu_per_host = get_gpus_per_node()\n    # ngpus = nhosts * ngpu_per_host\n    ngpus_available = get_world_size(total=True)\n    ngpus = nhosts * ngpu_per_host\n    world_size_total = get_world_size_total()\n    # if ngpus != world_size_total:\n    #     logger.warning('Disagreement in total world size!!')\n    #     logger.warning(' '.join([\n    #         f'{get_world_size(total=True)=}',\n    #         f' vs. {get_world_size_total()=}'\n    #     ]))\n    #     logger.warning(' '.join([\n    #         'Mismatch in: ',\n    #         f'{ngpus=} vs. {ngpu_per_host=} * {nhosts=}'\n    #     ]))\n    launch_cmd = get_pbs_launch_cmd(hostfile=hostfile)\n    return {\n        \"HOSTFILE\": hfp.as_posix(),\n        \"HOSTS\": (\n            f\"[{', '.join(hosts)}]\"\n            if nhosts &lt; 1000\n            else \"[truncated (&gt;1000 nodes)]\"\n        ),\n        \"NHOSTS\": f\"{nhosts}\",\n        \"NGPU_PER_HOST\": f\"{ngpu_per_host}\",\n        \"NGPUS\": f\"{ngpus}\",\n        \"NGPUS_AVAILABLE\": f\"{ngpus_available}\",\n        \"MACHINE\": get_machine(),\n        \"DEVICE\": get_torch_device_type(),\n        \"BACKEND\": get_torch_backend(),\n        \"LAUNCH_CMD\": launch_cmd,\n        \"world_size_total\": f\"{world_size_total}\",\n    }\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_pbs_nodefile_from_qstat","title":"<code>get_pbs_nodefile_from_qstat()</code>","text":"<p>Get the PBS nodefile from qstat</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_pbs_nodefile_from_qstat() -&gt; Path:\n    \"\"\"Get the PBS nodefile from qstat\"\"\"\n    from ezpz.configs import get_scheduler\n\n    assert get_scheduler() == \"PBS\"\n    nodefile = os.environ.get(\"PBS_NODEFILE\", None)\n    if nodefile is not None and (nf := Path(nodefile)).is_file():\n        return nf\n    pbs_jobid = get_pbs_jobid_from_qstat()\n    matches = [\n        i\n        for i in Path(\"/var/spool/pbs/aux/\").rglob(f\"*{pbs_jobid}*\")\n        if i.is_file()\n    ]\n    assert len(matches) == 1\n    return matches[0]\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_rank","title":"<code>get_rank()</code>","text":"<p>Get current MPI rank</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_rank() -&gt; int:\n    \"\"\"Get current MPI rank\"\"\"\n    return int(MPI.COMM_WORLD.Get_rank())\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_running_jobs_from_qstat","title":"<code>get_running_jobs_from_qstat()</code>","text":"<p>Get the running jobs from qstat</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_running_jobs_from_qstat() -&gt; list[int]:\n    \"\"\"Get the running jobs from qstat\"\"\"\n    try:\n        from sh import qstat as shqstat  # type: ignore\n    except Exception as e:\n        raise e\n    return [\n        int(i.split(\".\")[0])\n        for i in shqstat(\"-u\", os.environ.get(\"USER\")).split(\"\\n\")[2:-1]\n        if \" R \" in i\n    ]\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_torch_backend_on_xpu","title":"<code>get_torch_backend_on_xpu()</code>","text":"<p>Deal with breaking change introduced in torch 2.6:</p> <p>See: https://github.com/pytorch/pytorch/pull/141856</p> <p>Example:</p> <pre><code>```python\n&gt;&gt;&gt; torch_version = float('.'join(torch.__version__.split('.')[:2]))\n&gt;&gt;&gt; if torch_version &gt;= 2.6:\n&gt;&gt;&gt;     backend = 'xccl'\n&gt;&gt;&gt; else:\n&gt;&gt;&gt;     backend = 'ccl'\n```\n</code></pre> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_torch_backend_on_xpu() -&gt; str:\n    \"\"\"Deal with breaking change introduced in torch 2.6:\n\n    See: https://github.com/pytorch/pytorch/pull/141856\n\n    Example:\n\n        ```python\n        &gt;&gt;&gt; torch_version = float('.'join(torch.__version__.split('.')[:2]))\n        &gt;&gt;&gt; if torch_version &gt;= 2.6:\n        &gt;&gt;&gt;     backend = 'xccl'\n        &gt;&gt;&gt; else:\n        &gt;&gt;&gt;     backend = 'ccl'\n        ```\n    \"\"\"\n    torch_version = get_torch_version_as_float()\n    assert torch.xpu.is_available()\n    if torch_version &gt; 2.5:\n        return 'xccl'\n    return 'ccl'\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_world_size_in_use","title":"<code>get_world_size_in_use()</code>","text":"<p>Get number of currently in use MPI ranks</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_world_size_in_use() -&gt; int:\n    \"\"\"Get number of currently in use MPI ranks\"\"\"\n    return int(MPI.COMM_WORLD.Get_size())\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.get_world_size_total","title":"<code>get_world_size_total()</code>","text":"<p>Calculate total AVAILABLE *PUs as:</p> <p>total = [num_hosts] * [num_*pu_per_host]</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_world_size_total() -&gt; int:\n    \"\"\"Calculate total AVAILABLE *PUs as:\n\n    total = [num_hosts] * [num_*pu_per_host]\n    \"\"\"\n    # nhosts = get_num_nodes()\n    # ngpu_per_host = get_gpus_per_node()\n    # return ngpu_per_host * nhosts\n    return get_gpus_per_node() * get_num_nodes()\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.log_dict_as_bulleted_list","title":"<code>log_dict_as_bulleted_list(d, name=None)</code>","text":"<p>Print dictionary as list</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def log_dict_as_bulleted_list(d: dict, name: Optional[str] = None):\n    \"\"\"Print dictionary as list\"\"\"\n    tag = name if name is not None else d.__qualname__\n    logger.info(\n        \"\\n\".join(\n            [\"\\n\", f\"[{tag}]:\"]\n            + [f\"  \u2022 {k}={v}\" for k, v in d.items()]\n            + [\"\\n\"]\n        )\n    )\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.make_hostfile_from_slurm_env","title":"<code>make_hostfile_from_slurm_env(outfile=None)</code>","text":"<p>Make a hostfile from the SLURM_NODELIST environment variable</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def make_hostfile_from_slurm_env(outfile: Optional[PathLike] = None) -&gt; Path:\n    \"\"\"Make a hostfile from the SLURM_NODELIST environment variable\"\"\"\n    nodes = os.environ.get(\"SLURM_NODELIST\", None)\n    # if nodes is not None:\n    assert nodes is not None\n    # machine = get_machine()\n    prefix, idxs = nodes.split(\"[\")\n    idxs = idxs.rstrip(\"]\")\n    idxs = \"-\".join(idxs.split(\",\")).split(\"-\")\n    nodelist = [f\"{prefix}{i}\" for i in idxs]\n    # idxs = (\n    #     nodes.split\n    # )\n    # idxs = (\n    #     nodes.lstrip('frontier').replace('[', '').replace(']', '').split('-')\n    # )\n    # nodelist = [f'frontier{i}' for i in idxs]\n    if outfile is None:\n        outfile = Path(os.getcwd()).joinpath(\"hostfile\")\n    else:\n        outfile = Path(outfile)\n    with outfile.open(\"w\") as f:\n        for node in nodelist:\n            f.write(f\"{node}\\n\")\n    return outfile\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.query_environment","title":"<code>query_environment()</code>","text":"<p>Query environment variables for info about distributed setup</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def query_environment() -&gt; dict[str, int]:\n    \"\"\"Query environment variables for info about distributed setup\"\"\"\n    ws = os.environ.get(\"WORLD_SIZE\", None)\n    r = os.environ.get(\"RANK\", None)\n    lr = os.environ.get(\"LOCAL_RANK\", None)\n    if ws is not None and r is not None and lr is not None:\n        return {\n            \"world_size\": int(ws),\n            \"rank\": int(r),\n            \"local_rank\": int(lr),\n            # 'machine': machine,\n        }\n    return {\n        \"world_size\": int(get_world_size()),\n        \"rank\": int(get_rank()),\n        \"local_rank\": int(get_local_rank()),\n    }\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.setup_tensorflow","title":"<code>setup_tensorflow(precision=None, ngpus=None)</code>","text":"<p>Initialize TensorFlow + Horovod for Distributed Training</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def setup_tensorflow(\n    precision: Optional[str] = None,\n    ngpus: Optional[int] = None,\n) -&gt; int:\n    \"\"\"Initialize TensorFlow + Horovod for Distributed Training\"\"\"\n    import tensorflow as tf  # type:ignore noqa\n\n    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n    import horovod.tensorflow as hvd  # type:ignore noqa\n\n    _ = None if hvd.is_initialized() else hvd.init()\n    # hvd.init() if not hvd.is_initialized() else None\n    if precision in [\n        \"fp16\",\n        \"float16\",\n        \"half\",\n        \"16\",\n        \"mixed_float16\",\n        # 'mixed_bfloat16'\n    ]:\n        tf.keras.mixed_precision.set_global_policy(  # pyright:ignore\n            \"mixed_float16\"\n        )\n    TF_FLOAT = tf.keras.backend.floatx()  # pyright:ignore\n    eager_mode = os.environ.get(\"TF_EAGER\", None)\n    if eager_mode is not None:\n        logger.info(\"Detected `TF_EAGER` from env. Running eagerly.\")\n        tf.config.run_functions_eagerly(True)\n\n    gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n    cpus = tf.config.experimental.list_physical_devices(\"CPU\")\n    if gpus:\n        try:\n            # Currently memory growth needs to be the same across GPUs\n            if ngpus is not None:\n                gpus = gpus[-ngpus:]\n\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            tf.config.experimental.set_visible_devices(\n                gpus[hvd.local_rank()],\n                \"GPU\",\n            )\n            _ = (  # pyright:ignore\n                tf.config.experimental.list_logical_devices(\"GPU\")\n            )\n        except RuntimeError as e:\n            logger.info(e)\n    elif cpus:\n        try:\n            # Currently, memory growth needs to be the same across GPUs\n            logical_cpus = tf.config.experimental.list_logical_devices(\"CPU\")\n            logger.info(\n                f\"{len(cpus)}, Physical CPUs and \"\n                f\"{len(logical_cpus)} Logical CPUs\"\n            )\n        except RuntimeError as e:\n            # Memory growth must be set before GPUs have been initialized\n            logger.info(e)\n    RANK = hvd.rank()\n    WORLD_SIZE = hvd.size()\n    LOCAL_RANK = hvd.local_rank()\n    # LOCAL_SIZE = hvd.local_size()\n    os.environ[\"RANK\"] = str(RANK)\n    os.environ[\"WORLD_SIZE\"] = str(WORLD_SIZE)\n    os.environ[\"LOCAL_RANK\"] = str(LOCAL_RANK)\n    # logger.info(f'RANK: {RANK} / {WORLD_SIZE-1}')\n    if RANK == 0:\n        logger.info(f\"Using {TF_FLOAT} precision\")\n    return RANK\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.setup_torch","title":"<code>setup_torch(backend=None, port=None, seed=None, timeout=None, verbose=False, tensor_parallel_size=1, pipeline_parallel_size=1, context_parallel_size=1, tensor_parallel_backend=None, pipeline_parallel_backend=None, context_parallel_backend=None, data_parallel_backend=None)</code>","text":"<p>Setup torch.</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def setup_torch(\n    backend: Optional[str] = None,\n    port: Optional[str | int] = None,\n    seed: Optional[int] = None,\n    timeout: Optional[str | int] = None,\n    verbose: Optional[bool] = False,\n    tensor_parallel_size: int = 1,\n    pipeline_parallel_size: int = 1,\n    context_parallel_size: int = 1,\n    tensor_parallel_backend: Optional[str] = None,\n    pipeline_parallel_backend: Optional[str] = None,\n    context_parallel_backend: Optional[str] = None,\n    data_parallel_backend: Optional[str] = None,\n) -&gt; int:\n    \"\"\"Setup torch.\"\"\"\n    device = get_torch_device()\n    # if ACCELERATOR_TYPE == 'NvidiaGPU' and device == 'cuda':\n    #     os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n    #     torch.backends.cudnn.deterministic = True     # type:ignore\n    #     torch.backends.cudnn.benchmark = True         # type:ignore\n    #     torch.backends.cudnn.allow_tf32 = True        # type:ignore\n    #     torch.backends.cuda.matmul.allow_tf32 = True  # type:ignore\n    # torch.use_deterministic_algorithms(True)\n    ws_from_env = os.environ.get(\"WORLD_SIZE\", None)\n    backend = \"DDP\" if backend is None else backend\n    backend = backend.lower()\n    if ws_from_env is not None and ws_from_env == \"1\":\n        logger.info(\n            f\"Running on a single {device}, not initializing torch.distributed!\"\n        )\n        rank = 0\n        world_size = 1\n        local_rank = 0\n        local_size = 1\n        num_nodes = 1\n    else:\n        dsetup = setup_torch_distributed(\n            backend=backend,\n            port=port,\n            timeout=timeout,\n            tensor_parallel_size=int(tensor_parallel_size),\n            pipeline_parallel_size=int(pipeline_parallel_size),\n            context_parallel_size=int(context_parallel_size),\n            tensor_parallel_backend=tensor_parallel_backend,\n            pipeline_parallel_backend=pipeline_parallel_backend,\n            context_parallel_backend=context_parallel_backend,\n            data_parallel_backend=data_parallel_backend,\n        )\n        rank = dsetup[\"rank\"]\n        world_size = dsetup[\"world_size\"]\n        local_rank = dsetup[\"local_rank\"]\n        local_size = get_gpus_per_node()\n        num_nodes = get_num_nodes()\n    os.environ[\"RANK\"] = str(rank)\n    os.environ[\"LOCAL_RANK\"] = str(local_rank)\n    os.environ[\"NUM_NODES\"] = str(num_nodes)\n    os.environ[\"LOCAL_SIZE\"] = str(local_size)\n    os.environ[\"WORLD_SIZE\"] = str(world_size)\n    # nthreads = os.environ.get('OMP_NUM_THREADS', None)\n    if ACCELERATOR_TYPE == \"IntelGPU\" and device == \"xpu\":\n        # logger.warning(f'Using {get_torch_device()}:{get_local_rank()}')\n        # os.environ['CCL_LOCAL_RANK'] = str(local_rank)\n        # os.environ['CCL_LOCAL_SIZE'] = str(local_size)\n        torch.xpu.set_device(local_rank)  # type:ignore\n    if seed is not None:\n        seed_everything(seed * (rank + 1) * (local_rank + 1))\n    if rank == 0:\n        if backend in {\"ds\", \"deepspeed\", \"dspeed\"}:\n            from ezpz.configs import git_ds_info\n\n            git_ds_info()\n        _ = get_dist_info(verbose=verbose)\n        if verbose:\n            _ = print_dist_setup()\n    if oneccl_bpt is not None:\n        logger.debug(f\"Using oneccl_bindings from: {oneccl_bpt.__file__}\")\n    if ipex is not None:\n        logger.debug(f\"Using ipex from: {ipex.__file__}\")\n    # if world_size &gt; 1:\n    #     tdist.barrier()\n\n    if rank == 0:\n        logger.info(\n            f\"Using {device=} with {backend=} \"\n            f\"+ '{get_torch_backend()}' \"\n            \"for distributed training.\"\n        )\n    lrank = len(str(world_size - 1))\n    # nz = lrank - len(str(rank))\n    hn = socket.gethostname()\n    psizes = [f\"['{hn}']\" + f\"[{rank:&gt;{lrank}}/{world_size - 1:&lt;{lrank}}] \"]\n    if (\n        tensor_parallel_size &gt; 1\n        or context_parallel_size &gt; 1\n        or pipeline_parallel_size &gt; 1\n    ):\n        import ezpz.tp\n\n        tprank = ezpz.tp.get_tensor_parallel_rank()\n        # tpranks = ezpz.tp.get_tensor_parallel_ranks()\n        tpsize = ezpz.tp.get_tensor_parallel_world_size()\n\n        dprank = ezpz.tp.get_data_parallel_rank()\n        # dpranks = ezpz.tp.get_data_parallel_ranks()\n        dpsize = ezpz.tp.get_data_parallel_world_size()\n\n        pprank = ezpz.tp.get_pipeline_parallel_rank()\n        # ppranks = ezpz.tp.get_pipeline_parallel_ranks()\n        ppsize = ezpz.tp.get_pipeline_parallel_world_size()\n\n        # cpranks = ezpz.tp.get_context_parallel_ranks()\n        cprank = ezpz.tp.get_context_parallel_rank()\n        cpsize = ezpz.tp.get_context_parallel_world_size()\n\n        if cpsize &gt; 1 or ppsize &gt; 1 or tpsize &gt; 1:\n            if cpsize &gt; 1:\n                lcp = len(str(cpsize - 1))\n                psizes.append(f\"[cp:{cprank:&gt;{lcp}}/{cpsize - 1:&lt;{lcp}}]\")\n                tdist.barrier(group=ezpz.tp.get_context_parallel_group())\n            if ppsize &gt; 1:\n                lpp = len(str(ppsize - 1))\n                psizes.append(f\"[pp:{pprank:&gt;{lpp}}/{ppsize - 1:&lt;{lpp}}]\")\n                tdist.barrier(group=ezpz.tp.get_pipeline_parallel_group())\n            if tpsize &gt; 1:\n                ltp = len(str(tpsize - 1))\n                psizes.append(f\"[tp:{tprank:&gt;{ltp}}/{tpsize - 1:&lt;{ltp}}]\")\n                tdist.barrier(group=ezpz.tp.get_tensor_parallel_group())\n            if dpsize &gt; 1:\n                ldp = len(str(dpsize - 1))\n                psizes.append(f\"[dp:{dprank:&gt;{ldp}}/{dpsize - 1:&lt;{ldp}}]\")\n                tdist.barrier(group=ezpz.tp.get_data_parallel_group())\n    # tdist.all_gather(psizes)\n    logger.info(\"\".join(psizes))\n    tdist.barrier()\n    # MPI.COMM_WORLD.Barrier()\n    return rank\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.setup_torch_distributed","title":"<code>setup_torch_distributed(backend=None, tensor_parallel_size=1, pipeline_parallel_size=1, context_parallel_size=1, tensor_parallel_backend=None, pipeline_parallel_backend=None, context_parallel_backend=None, data_parallel_backend=None, port=None, timeout=None)</code>","text":"<p>Returns {'world_size': int, 'rank': int, 'local_rank': int}</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def setup_torch_distributed(\n    backend: Optional[str] = None,\n    tensor_parallel_size: int = 1,\n    pipeline_parallel_size: int = 1,\n    context_parallel_size: int = 1,\n    tensor_parallel_backend: Optional[str] = None,\n    pipeline_parallel_backend: Optional[str] = None,\n    context_parallel_backend: Optional[str] = None,\n    data_parallel_backend: Optional[str] = None,\n    port: Optional[str | int] = None,\n    timeout: Optional[str | int] = None,\n) -&gt; dict[str, int]:\n    \"\"\"Returns {'world_size': int, 'rank': int, 'local_rank': int}\"\"\"\n    backend = \"DDP\" if backend is None else backend\n    assert backend.lower() in {\n        \"ddp\",\n        \"ds\",\n        \"deepspeed\",\n        \"horovod\",\n        \"hvd\",\n    }\n    timeout = (\n        3600\n        if timeout is None\n        else int(timeout)\n        if isinstance(timeout, str)\n        else timeout\n    )\n    port = (\n        \"1234\" if port is None else str(port) if isinstance(port, int) else port\n    )\n    rank = get_rank()\n    world_size = get_world_size()\n    local_rank = get_local_rank()\n    be = backend.lower()\n    # assert be in BACKENDS['pytorch']\n    if be == \"ddp\":\n        dsetup = setup_torch_DDP(port, timeout)\n        world_size = dsetup[\"world_size\"]\n        rank = dsetup[\"rank\"]\n        local_rank = dsetup[\"local_rank\"]\n        if torch.cuda.is_available():\n            torch.cuda.set_device(local_rank)\n    elif be in {\"deepspeed\", \"ds\"}:\n        init_deepspeed(timeout=timeout)\n        world_size = get_world_size()\n        rank = get_rank()\n        local_rank = get_local_rank()\n    elif be in {\"horovod\", \"hvd\"}:\n        import horovod.torch as hvd  # type:ignore noqa\n\n        _ = None if hvd.is_initialized() else hvd.init()\n        # hvd.init() if not hvd.is_initialized() else None\n        rank = hvd.rank()\n        world_size = hvd.size()\n        local_rank = hvd.local_rank()\n        if torch.cuda.is_available():\n            torch.cuda.set_device(hvd.local_rank())\n    else:\n        raise ValueError(f\"Unable to parse backend: {be=}\")\n\n    if (\n        tensor_parallel_size &gt; 1\n        or context_parallel_size &gt; 1\n        or pipeline_parallel_size &gt; 1\n    ):\n        ezpz.tp.initialize_tensor_parallel(\n            tensor_parallel_size=tensor_parallel_size,\n            pipeline_parallel_size=pipeline_parallel_size,\n            context_parallel_size=context_parallel_size,\n            tensor_parallel_backend=tensor_parallel_backend,\n            pipeline_parallel_backend=pipeline_parallel_backend,\n            context_parallel_backend=context_parallel_backend,\n            data_parallel_backend=data_parallel_backend,\n            timeout=timedelta(seconds=timeout),\n        )\n\n    os.environ[\"world_size\"] = str(world_size)\n    os.environ[\"RANK\"] = str(rank)\n    os.environ[\"LOCAL_RANK\"] = str(local_rank)\n\n    return {\"world_size\": world_size, \"rank\": rank, \"local_rank\": local_rank}\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.write_hostfile_from_list_of_hosts","title":"<code>write_hostfile_from_list_of_hosts(hosts, hostfile=None, rank_zero_only=True)</code>","text":"<p>Write a list of hosts to the hostfile</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def write_hostfile_from_list_of_hosts(\n    hosts: list[str],\n    hostfile: Optional[PathLike] = None,\n    rank_zero_only: bool = True,\n):\n    \"\"\"Write a list of hosts to the hostfile\"\"\"\n    hostfile = (\n        Path(hostfile).as_posix()\n        if hostfile is not None\n        else Path(os.getcwd()).joinpath(\"hostfile\").as_posix()\n    )\n    if (rank_zero_only and get_rank() == 0) or not rank_zero_only:\n        logger.info(f\"Writing to {hostfile}\")\n        with Path(hostfile).open(\"w\") as f:\n            for host in hosts:\n                f.write(f\"{host}\\n\")\n</code></pre>"},{"location":"Code-Reference/dist-reference/#ezpz.dist.write_localhost_to_hostfile","title":"<code>write_localhost_to_hostfile(hostfile)</code>","text":"<p>Write 'localhost' to the hostfile</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def write_localhost_to_hostfile(hostfile: PathLike):\n    \"\"\"Write 'localhost' to the hostfile\"\"\"\n    if get_rank() == 0:\n        logger.debug(\n            f\"Writing {(hostname := get_hostname())} \"\n            f\"to {Path(hostfile).as_posix()}\"\n        )\n        hostname = get_hostname()\n        with Path(hostfile).open(\"w\") as f:\n            f.write(f\"{hostname}\")\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/","title":"<code>ezpz.__init__</code>","text":"<p>This module is part of the <code>ezpz</code> package</p> <p>ezpz/init.py</p>"},{"location":"Code-Reference/ezpz-reference/#ezpz.Console","title":"<code>Console</code>","text":"<p>               Bases: <code>Console</code></p> <p>Extends rich Console class.</p> Source code in <code>src/ezpz/log/console.py</code> <pre><code>class Console(rich_console.Console):\n    \"\"\"Extends rich Console class.\"\"\"\n\n    def __init__(self, *args: str, redirect: bool = True, **kwargs: Any) -&gt; None:\n        \"\"\"\n        enrich console does soft-wrapping by default and this diverge from\n        original rich console which does not, creating hard-wraps instead.\n        \"\"\"\n        self.redirect = redirect\n\n        if \"soft_wrap\" not in kwargs:\n            kwargs[\"soft_wrap\"] = True\n\n        if \"theme\" not in kwargs:\n            kwargs['theme'] = get_theme()\n\n        if \"markup\" not in kwargs:\n            kwargs['markup'] = True\n\n        if \"width\" not in kwargs:\n            kwargs['width'] = 55510\n\n        # Unless user already mentioning terminal preference, we use our\n        # heuristic to make an informed decision.\n        if \"force_terminal\" not in kwargs:\n            kwargs[\"force_terminal\"] = should_do_markup(\n                stream=kwargs.get(\"file\", sys.stdout)\n            )\n\n        super().__init__(*args, **kwargs)\n        self.extended = True\n\n        if self.redirect:\n            if not hasattr(sys.stdout, \"rich_proxied_file\"):\n                sys.stdout = FileProxy(self, sys.stdout)  # type: ignore\n            if not hasattr(sys.stderr, \"rich_proxied_file\"):\n                sys.stderr = FileProxy(self, sys.stderr)  # type: ignore\n\n    # https://github.com/python/mypy/issues/4441\n    def print(self, *args, **kwargs) -&gt; None:  # type: ignore\n        \"\"\"Print override that respects user soft_wrap preference.\"\"\"\n        # Currently rich is unable to render ANSI escapes with print so if\n        # we detect their presence, we decode them.\n        # https://github.com/willmcgugan/rich/discussions/404\n        if args and isinstance(args[0], str) and \"\\033\" in args[0]:\n            text = format(*args) + \"\\n\"\n            decoder = AnsiDecoder()\n            args = list(decoder.decode(text))  # type: ignore\n        super().print(*args, **kwargs)\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.Console.__init__","title":"<code>__init__(*args, redirect=True, **kwargs)</code>","text":"<p>enrich console does soft-wrapping by default and this diverge from original rich console which does not, creating hard-wraps instead.</p> Source code in <code>src/ezpz/log/console.py</code> <pre><code>def __init__(self, *args: str, redirect: bool = True, **kwargs: Any) -&gt; None:\n    \"\"\"\n    enrich console does soft-wrapping by default and this diverge from\n    original rich console which does not, creating hard-wraps instead.\n    \"\"\"\n    self.redirect = redirect\n\n    if \"soft_wrap\" not in kwargs:\n        kwargs[\"soft_wrap\"] = True\n\n    if \"theme\" not in kwargs:\n        kwargs['theme'] = get_theme()\n\n    if \"markup\" not in kwargs:\n        kwargs['markup'] = True\n\n    if \"width\" not in kwargs:\n        kwargs['width'] = 55510\n\n    # Unless user already mentioning terminal preference, we use our\n    # heuristic to make an informed decision.\n    if \"force_terminal\" not in kwargs:\n        kwargs[\"force_terminal\"] = should_do_markup(\n            stream=kwargs.get(\"file\", sys.stdout)\n        )\n\n    super().__init__(*args, **kwargs)\n    self.extended = True\n\n    if self.redirect:\n        if not hasattr(sys.stdout, \"rich_proxied_file\"):\n            sys.stdout = FileProxy(self, sys.stdout)  # type: ignore\n        if not hasattr(sys.stderr, \"rich_proxied_file\"):\n            sys.stderr = FileProxy(self, sys.stderr)  # type: ignore\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.Console.print","title":"<code>print(*args, **kwargs)</code>","text":"<p>Print override that respects user soft_wrap preference.</p> Source code in <code>src/ezpz/log/console.py</code> <pre><code>def print(self, *args, **kwargs) -&gt; None:  # type: ignore\n    \"\"\"Print override that respects user soft_wrap preference.\"\"\"\n    # Currently rich is unable to render ANSI escapes with print so if\n    # we detect their presence, we decode them.\n    # https://github.com/willmcgugan/rich/discussions/404\n    if args and isinstance(args[0], str) and \"\\033\" in args[0]:\n        text = format(*args) + \"\\n\"\n        decoder = AnsiDecoder()\n        args = list(decoder.decode(text))  # type: ignore\n    super().print(*args, **kwargs)\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.History","title":"<code>History</code>","text":"Source code in <code>src/ezpz/history.py</code> <pre><code>class History:\n    def __init__(self, keys: Optional[list[str]] = None) -&gt; None:\n        self.keys = [] if keys is None else keys\n        self.history = {}\n\n    def _update(\n        self,\n        key: str,\n        val: Union[Any, ScalarLike, list, torch.Tensor, np.ndarray],\n    ):\n        try:\n            self.history[key].append(val)\n        except KeyError:\n            self.history[key] = [val]\n        return val\n\n    def update(\n        self,\n        metrics: dict,\n        precision: int = 6,\n        use_wandb: Optional[bool] = True,\n        commit: Optional[bool] = True,\n        summarize: Optional[bool] = True,\n    ) -&gt; str:\n        for key, val in metrics.items():\n            # if isinstance(val, (list, np.ndarray, torch.Tensor)):\n            #     val = grab_tensor(val)\n            try:\n                self.history[key].append(val)\n            except KeyError:\n                self.history[key] = [val]\n        if (\n            wandb is not None\n            and use_wandb\n            and not WANDB_DISABLED\n            and getattr(wandb, \"run\", None) is not None\n        ):\n            wandb.log(metrics, commit=commit)\n        if summarize:\n            return summarize_dict(metrics, precision=precision)\n        return \"\"\n\n    def _tplot(\n        self,\n        y: np.ndarray,\n        x: Optional[np.ndarray] = None,\n        xlabel: Optional[str] = None,\n        ylabel: Optional[str] = None,\n        append: bool = True,\n        title: Optional[str] = None,\n        verbose: bool = False,\n        outfile: Optional[str] = None,\n        logfreq: Optional[int] = None,\n        plot_type: Optional[str] = None,\n    ):\n        if xlabel is not None and ylabel == xlabel:\n            return\n        if len(y) &gt; 1:\n            x = x if x is not None else np.arange(len(y))\n            assert x is not None\n            ezplot.tplot(\n                y=y,\n                x=x,\n                xlabel=xlabel,\n                ylabel=ylabel,\n                logfreq=(1 if logfreq is None else logfreq),\n                append=append,\n                verbose=verbose,\n                outfile=outfile,\n                plot_type=plot_type,\n                title=title,\n                # plot_type=('scatter' if 'dt' in ylabel else None),\n            )\n        if ylabel is not None and \"dt\" in ylabel:\n            of = Path(outfile) if outfile is not None else None\n            if of is not None:\n                of = Path(of.parent).joinpath(f\"{of.stem}-hist{of.suffix}\")\n            ezplot.tplot(\n                y=y,\n                xlabel=ylabel,\n                title=title,\n                ylabel=\"freq\",\n                append=append,\n                verbose=verbose,\n                outfile=(of if of is not None else None),\n                plot_type=\"hist\",\n            )\n\n    def plot(\n        self,\n        val: np.ndarray,\n        key: Optional[str] = None,\n        warmup: Optional[float] = 0.0,\n        num_chains: Optional[int] = 128,\n        title: Optional[str] = None,\n        outdir: Optional[os.PathLike] = None,\n        subplots_kwargs: Optional[dict[str, Any]] = None,\n        plot_kwargs: Optional[dict[str, Any]] = None,\n    ):\n        \"\"\"\n        Plot a single variable from the history.\n\n        NOTE: The `warmup` argument can be used to drop the first `warmup`\n        iterations (as a percent of the total number of iterations) from the\n        plot.\n        \"\"\"\n        plot_kwargs = {} if plot_kwargs is None else plot_kwargs\n        subplots_kwargs = {} if subplots_kwargs is None else subplots_kwargs\n        figsize = subplots_kwargs.get(\"figsize\", ezplot.set_size())\n        subplots_kwargs.update({\"figsize\": figsize})\n        num_chains = 16 if num_chains is None else num_chains\n\n        # tmp = val[0]\n        arr = np.array(val)\n\n        subfigs = None\n        steps = np.arange(arr.shape[0])\n        if warmup is not None and warmup &gt; 0:\n            drop = int(warmup * arr.shape[0])\n            arr = arr[drop:]\n            steps = steps[drop:]\n\n        if len(arr.shape) == 2:\n            import seaborn as sns\n\n            _ = subplots_kwargs.pop(\"constrained_layout\", True)\n            figsize = (3 * figsize[0], 1.5 * figsize[1])\n\n            fig = plt.figure(figsize=figsize, constrained_layout=True)\n            subfigs = fig.subfigures(1, 2)\n\n            gs_kw = {\"width_ratios\": [1.33, 0.33]}\n            (ax, ax1) = subfigs[1].subplots(\n                1, 2, sharey=True, gridspec_kw=gs_kw\n            )\n            ax.grid(alpha=0.2)\n            ax1.grid(False)\n            color = plot_kwargs.get(\"color\", None)\n            label = r\"$\\langle$\" + f\" {key} \" + r\"$\\rangle$\"\n            ax.plot(\n                steps, arr.mean(-1), lw=1.5 * LW, label=label, **plot_kwargs\n            )\n            sns.kdeplot(y=arr.flatten(), ax=ax1, color=color, shade=True)\n            ax1.set_xticks([])\n            ax1.set_xticklabels([])\n            # ax1.set_yticks([])\n            # ax1.set_yticklabels([])\n            sns.despine(ax=ax, top=True, right=True)\n            sns.despine(ax=ax1, top=True, right=True, left=True, bottom=True)\n            # ax.legend(loc='best', frameon=False)\n            ax1.set_xlabel(\"\")\n            # ax1.set_ylabel('')\n            # ax.set_yticks(ax.get_yticks())\n            # ax.set_yticklabels(ax.get_yticklabels())\n            # ax.set_ylabel(key)\n            # _ = subfigs[1].subplots_adjust(wspace=-0.75)\n            axes = (ax, ax1)\n        else:\n            if len(arr.shape) == 1:\n                fig, ax = plt.subplots(**subplots_kwargs)\n                assert isinstance(ax, plt.Axes)\n                ax.plot(steps, arr, **plot_kwargs)\n                axes = ax\n            elif len(arr.shape) == 3:\n                fig, ax = plt.subplots(**subplots_kwargs)\n                assert isinstance(ax, plt.Axes)\n                cmap = plt.get_cmap(\"viridis\")\n                nlf = arr.shape[1]\n                for idx in range(nlf):\n                    # y = arr[:, idx, :].mean(-1)\n                    # pkwargs = {\n                    #     'color': cmap(idx / nlf),\n                    #     'label': f'{idx}',\n                    # }\n                    # ax.plot(steps, y, **pkwargs)\n                    label = plot_kwargs.pop(\"label\", None)\n                    if label is not None:\n                        label = f\"{label}-{idx}\"\n                    y = arr[:, idx, :]\n                    color = cmap(idx / y.shape[1])\n                    plot_kwargs[\"color\"] = cmap(idx / y.shape[1])\n                    if len(y.shape) == 2:\n                        # TOO: Plot chains\n                        if num_chains &gt; 0:\n                            for idx in range(min((num_chains, y.shape[1]))):\n                                _ = ax.plot(\n                                    steps,\n                                    y[:, idx],  # color,\n                                    lw=LW / 2.0,\n                                    alpha=0.8,\n                                    **plot_kwargs,\n                                )\n\n                        _ = ax.plot(\n                            steps,\n                            y.mean(-1),  # color=color,\n                            label=label,\n                            **plot_kwargs,\n                        )\n                    else:\n                        _ = ax.plot(\n                            steps,\n                            y,  # color=color,\n                            label=label,\n                            **plot_kwargs,\n                        )\n                axes = ax\n            else:\n                raise ValueError(\"Unexpected shape encountered\")\n\n            ax.set_ylabel(key)\n\n        if num_chains &gt; 0 and len(arr.shape) &gt; 1:\n            # lw = LW / 2.\n            for idx in range(min(num_chains, arr.shape[1])):\n                # ax = subfigs[0].subplots(1, 1)\n                # plot values of invidual chains, arr[:, idx]\n                # where arr[:, idx].shape = [ndraws, 1]\n                ax.plot(\n                    steps, arr[:, idx], alpha=0.5, lw=LW / 2.0, **plot_kwargs\n                )\n\n        ax.set_xlabel(\"draw\")\n        if title is not None:\n            fig.suptitle(title)\n\n        if outdir is not None:\n            # plt.savefig(Path(outdir).joinpath(f'{key}.svg'),\n            #             dpi=400, bbox_inches='tight')\n            outfile = Path(outdir).joinpath(f\"{key}.svg\")\n            if outfile.is_file():\n                tstamp = ezpz.get_timestamp()\n                pngdir = Path(outdir).joinpath(\"pngs\")\n                pngdir.mkdir(exist_ok=True, parents=True)\n                pngfile = pngdir.joinpath(f\"{key}-{tstamp}.png\")\n                svgfile = Path(outdir).joinpath(f\"{key}-{tstamp}.svg\")\n                plt.savefig(pngfile, dpi=400, bbox_inches=\"tight\")\n                plt.savefig(svgfile, dpi=400, bbox_inches=\"tight\")\n\n        return fig, subfigs, axes\n\n    def plot_dataArray(\n        self,\n        val: xr.DataArray,\n        key: Optional[str] = None,\n        warmup: Optional[float] = 0.0,\n        num_chains: Optional[int] = 0,\n        title: Optional[str] = None,\n        outdir: Optional[str] = None,\n        subplots_kwargs: Optional[dict[str, Any]] = None,\n        plot_kwargs: Optional[dict[str, Any]] = None,\n        verbose: bool = False,\n        line_labels: bool = False,\n        logfreq: Optional[int] = None,\n    ):\n        plot_kwargs = {} if plot_kwargs is None else plot_kwargs\n        subplots_kwargs = {} if subplots_kwargs is None else subplots_kwargs\n        ezplot.set_plot_style()\n        plt.rcParams[\"axes.labelcolor\"] = \"#bdbdbd\"\n        figsize = subplots_kwargs.get(\"figsize\", ezplot.set_size())\n        subplots_kwargs.update({\"figsize\": figsize})\n        subfigs = None\n        # if key == 'dt':\n        #     warmup = 0.2\n        arr = val.values  # shape: [nchains, ndraws]\n        # steps = np.arange(len(val.coords['draw']))\n        steps = val.coords[\"draw\"]\n        if warmup is not None and warmup &gt; 0.0:\n            drop = int(warmup * arr.shape[0])\n            arr = arr[drop:]\n            steps = steps[drop:]\n        if len(arr.shape) == 2:\n            fig, axes = ezplot.plot_combined(\n                val,\n                key=key,\n                num_chains=num_chains,\n                plot_kwargs=plot_kwargs,\n                subplots_kwargs=subplots_kwargs,\n            )\n        else:\n            if len(arr.shape) == 1:\n                fig, ax = ezplot.subplots(**subplots_kwargs)\n                try:\n                    ax.plot(steps, arr, **plot_kwargs)\n                except ValueError:\n                    try:\n                        ax.plot(steps, arr[~np.isnan(arr)], **plot_kwargs)\n                    except Exception:\n                        logger.error(f\"Unable to plot {key}! Continuing\")\n                _ = ax.grid(True, alpha=0.2)\n                axes = ax\n            elif len(arr.shape) == 3:\n                fig, ax = ezplot.subplots(**subplots_kwargs)\n                cmap = plt.get_cmap(\"viridis\")\n                y = val.mean(\"chain\")\n                for idx in range(len(val.coords[\"leapfrog\"])):\n                    pkwargs = {\n                        \"color\": cmap(idx / len(val.coords[\"leapfrog\"])),\n                        \"label\": f\"{idx}\",\n                    }\n                    ax.plot(steps, y[idx], **pkwargs)\n                axes = ax\n            else:\n                raise ValueError(\"Unexpected shape encountered\")\n            ax = plt.gca()\n            assert isinstance(ax, plt.Axes)\n            _ = ax.set_ylabel(key)\n            _ = ax.set_xlabel(\"draw\")\n            # if num_chains &gt; 0 and len(arr.shape) &gt; 1:\n            #     lw = LW / 2.\n            #     #for idx in range(min(num_chains, arr.shape[1])):\n            #     nchains = len(val.coords['chains'])\n            #     for idx in range(min(nchains, num_chains)):\n            #         # ax = subfigs[0].subplots(1, 1)\n            #         # plot values of invidual chains, arr[:, idx]\n            #         # where arr[:, idx].shape = [ndraws, 1]\n            #         ax.plot(steps, val\n            #                 alpha=0.5, lw=lw/2., **plot_kwargs)\n        if title is not None:\n            fig = plt.gcf()\n            _ = fig.suptitle(title)\n        if logfreq is not None:\n            ax = plt.gca()\n            xticks = ax.get_xticks()  # type: ignore\n            _ = ax.set_xticklabels(  # type: ignore\n                [f\"{logfreq * int(i)}\" for i in xticks]  # type: ignore\n            )\n        if outdir is not None:\n            dirs = {\n                \"png\": Path(outdir).joinpath(\"pngs/\"),\n                \"svg\": Path(outdir).joinpath(\"svgs/\"),\n            }\n            _ = [i.mkdir(exist_ok=True, parents=True) for i in dirs.values()]\n            # from l2hmc.configs import PROJECT_DIR\n            # from ezpz\n            if verbose:\n                logger.info(f\"Saving {key} plot to: {Path(outdir).resolve()}\")\n            for ext, d in dirs.items():\n                outfile = d.joinpath(f\"{key}.{ext}\")\n                plt.savefig(outfile, dpi=400, bbox_inches=\"tight\")\n        return (fig, subfigs, axes)\n\n    def plot_dataset(\n        self,\n        title: Optional[str] = None,\n        nchains: Optional[int] = None,\n        outdir: Optional[os.PathLike] = None,\n        dataset: Optional[xr.Dataset] = None,\n        data: Optional[dict] = None,\n        warmup: Optional[int | float] = None,\n        # subplots_kwargs: Optional[dict[str, Any]] = None,\n        # plot_kwargs: Optional[dict[str, Any]] = None,\n    ):\n        dataset = (\n            dataset\n            if dataset is not None\n            else (\n                self.get_dataset(\n                    data=(data if data is not None else self.history),\n                    warmup=warmup,\n                )\n            )\n        )\n        return ezplot.plot_dataset(\n            dataset=dataset,\n            nchains=nchains,\n            title=title,\n            outdir=outdir,\n        )\n\n    def plot_2d_xarr(\n        self,\n        xarr: xr.DataArray,\n        label: Optional[str] = None,\n        num_chains: Optional[int] = None,\n        title: Optional[str] = None,\n        outdir: Optional[os.PathLike] = None,\n        subplots_kwargs: Optional[dict[str, Any]] = None,\n        plot_kwargs: Optional[dict[str, Any]] = None,\n    ):\n        import seaborn as sns\n\n        plot_kwargs = {} if plot_kwargs is None else plot_kwargs\n        subplots_kwargs = {} if subplots_kwargs is None else subplots_kwargs\n        assert len(xarr.shape) == 2\n        assert \"draw\" in xarr.coords and \"chain\" in xarr.coords\n        num_chains = len(xarr.chain) if num_chains is None else num_chains\n        # _ = subplots_kwargs.pop('constrained_layout', True)\n        figsize = plt.rcParams.get(\"figure.figsize\", (8, 6))\n        figsize = (3 * figsize[0], 1.5 * figsize[1])\n        fig = plt.figure(figsize=figsize, constrained_layout=True)\n        subfigs = fig.subfigures(1, 2)\n        gs_kw = {\"width_ratios\": [1.33, 0.33]}\n        (ax, ax1) = subfigs[1].subplots(1, 2, sharey=True, gridspec_kw=gs_kw)\n        ax.grid(alpha=0.2)\n        ax1.grid(False)\n        color = plot_kwargs.get(\"color\", f\"C{np.random.randint(6)}\")\n        label = r\"$\\langle$\" + f\" {label} \" + r\"$\\rangle$\"\n        ax.plot(\n            xarr.draw.values,\n            xarr.mean(\"chain\"),\n            color=color,\n            lw=1.5 * LW,\n            label=label,\n            **plot_kwargs,\n        )\n        for idx in range(num_chains):\n            # ax = subfigs[0].subplots(1, 1)\n            # plot values of invidual chains, arr[:, idx]\n            # where arr[:, idx].shape = [ndraws, 1]\n            # ax0.plot(\n            #     xarr.draw.values,\n            #     xarr[xarr.chain == idx][0],\n            #     lw=1.,\n            #     alpha=0.7,\n            #     color=color\n            # )\n            ax.plot(\n                xarr.draw.values,\n                xarr[xarr.chain == idx][0],\n                color=color,\n                alpha=0.5,\n                lw=LW / 2.0,\n                **plot_kwargs,\n            )\n\n        axes = (ax, ax1)\n        sns.kdeplot(y=xarr.values.flatten(), ax=ax1, color=color, shade=True)\n        ax1.set_xticks([])\n        ax1.set_xticklabels([])\n        # ax1.set_yticks([])\n        # ax1.set_yticklabels([])\n        sns.despine(ax=ax, top=True, right=True)\n        sns.despine(ax=ax1, top=True, right=True, left=True, bottom=True)\n        # ax.legend(loc='best', frameon=False)\n        ax1.set_xlabel(\"\")\n        # ax1.set_ylabel('')\n        # ax.set_yticks(ax.get_yticks())\n        # ax.set_yticklabels(ax.get_yticklabels())\n        # ax.set_ylabel(key)\n        # _ = subfigs[1].subplots_adjust(wspace=-0.75)\n        # if num_chains &gt; 0 and len(arr.shape) &gt; 1:\n        # lw = LW / 2.\n        # num_chains = np.min([\n        #     16,\n        #     len(xarr.coords['chain']),\n        # ])\n        sns.despine(subfigs[0])\n        ax0 = subfigs[0].subplots(1, 1)\n        im = xarr.plot(ax=ax0)  # type:ignore\n        im.colorbar.set_label(label)  # type:ignore\n        # ax0.plot(\n        #     xarr.draw.values,\n        #     xarr.mean('chain'),\n        #     lw=2.,\n        #     color=color\n        # )\n        # for idx in range(min(num_chains, i.shape[1])):\n        ax.set_xlabel(\"draw\")\n        if title is not None:\n            fig.suptitle(title)\n\n        if outdir is not None:\n            assert label is not None\n            # plt.savefig(Path(outdir).joinpath(f'{key}.svg'),\n            #             dpi=400, bbox_inches='tight')\n            outfile = Path(outdir).joinpath(f\"{label}.svg\")\n            if outfile.is_file():\n                tstamp = ezpz.get_timestamp(\"%Y-%m-%d-%H%M%S\")\n                pngdir = Path(outdir).joinpath(\"pngs\")\n                pngdir.mkdir(exist_ok=True, parents=True)\n                pngfile = pngdir.joinpath(f\"{label}-{tstamp}.png\")\n                svgfile = Path(outdir).joinpath(f\"{label}-{tstamp}.svg\")\n                plt.savefig(pngfile, dpi=400, bbox_inches=\"tight\")\n                plt.savefig(svgfile, dpi=400, bbox_inches=\"tight\")\n\n    def tplot_all(\n        self,\n        outdir: Optional[os.PathLike] = None,\n        warmup: Optional[float] = 0.0,\n        append: bool = True,\n        xkey: Optional[str] = None,\n        dataset: Optional[xr.Dataset] = None,\n        data: Optional[dict] = None,\n        logfreq: Optional[int] = None,\n        plot_type: Optional[str] = None,\n        verbose: bool = False,\n    ):\n        dataset = (\n            dataset\n            if dataset is not None\n            else (\n                self.get_dataset(\n                    data=(data if data is not None else self.history),\n                    warmup=warmup,\n                )\n            )\n        )\n\n        outdir = Path(os.getcwd()) if outdir is None else Path(outdir)\n        logger.info(f\"Saving tplots to {outdir.as_posix()}\")\n        for _, (key, val) in enumerate(dataset.items()):\n            if (xkey is not None and key == xkey) or xkey in [\"iter\", \"draw\"]:\n                continue\n            if len(val.values) &gt; 0:\n                self._tplot(\n                    y=val.values,\n                    x=None,\n                    xlabel=\"iter\",\n                    plot_type=plot_type,\n                    ylabel=str(key),\n                    append=append,\n                    title=f\"{key} [{get_timestamp()}]\",\n                    verbose=verbose,\n                    outfile=outdir.joinpath(f\"{key}.txt\").as_posix(),\n                    logfreq=logfreq,\n                )\n            else:\n                logger.warning(\n                    f\"No data found in {key=}: {len(val.values)=} &lt;= 0\"\n                )\n\n    def plot_all(\n        self,\n        num_chains: int = 128,\n        warmup: Optional[float | int] = 0.0,\n        title: Optional[str] = None,\n        verbose: bool = False,\n        outdir: Optional[os.PathLike] = None,\n        subplots_kwargs: Optional[dict[str, Any]] = None,\n        plot_kwargs: Optional[dict[str, Any]] = None,\n        dataset: Optional[xr.Dataset] = None,\n        data: Optional[dict] = None,\n    ):\n        import seaborn as sns\n\n        plot_kwargs = {} if plot_kwargs is None else plot_kwargs\n        subplots_kwargs = {} if subplots_kwargs is None else subplots_kwargs\n\n        dataset = (\n            dataset\n            if dataset is not None\n            else (\n                self.get_dataset(\n                    data=(data if data is not None else self.history),\n                    warmup=warmup,\n                )\n            )\n        )\n\n        _ = ezplot.make_ridgeplots(\n            dataset,\n            outdir=outdir,\n            drop_nans=True,\n            drop_zeros=False,\n            num_chains=num_chains,\n            cmap=\"viridis\",\n            save_plot=(outdir is not None),\n        )\n\n        for idx, (key, val) in enumerate(dataset.data_vars.items()):\n            color = f\"C{idx % 9}\"\n            plot_kwargs[\"color\"] = color\n\n            fig, subfigs, ax = self.plot(\n                val=val.values.T.real,\n                key=str(key),\n                title=title,\n                outdir=outdir,\n                warmup=warmup,\n                num_chains=num_chains,\n                plot_kwargs=plot_kwargs,\n                subplots_kwargs=subplots_kwargs,\n            )\n            if fig is not None:\n                _ = sns.despine(\n                    fig, top=True, right=True, bottom=True, left=True\n                )\n\n            # _ = plt.grid(True, alpha=0.4)\n            if subfigs is not None:\n                # edgecolor = plt.rcParams['axes.edgecolor']\n                plt.rcParams[\"axes.edgecolor\"] = plt.rcParams[\"axes.facecolor\"]\n                ax = subfigs[0].subplots(1, 1)\n                # ax = fig[1].subplots(constrained_layout=True)\n                _ = xplt.pcolormesh(\n                    val, \"draw\", \"chain\", ax=ax, robust=True, add_colorbar=True\n                )\n                # im = val.plot(ax=ax, cbar_kwargs=cbar_kwargs)\n                # im.colorbar.set_label(f'{key}')  # , labelpad=1.25)\n                sns.despine(\n                    subfigs[0], top=True, right=True, left=True, bottom=True\n                )\n            if outdir is not None:\n                dirs = {\n                    \"png\": Path(outdir).joinpath(\"pngs/\"),\n                    \"svg\": Path(outdir).joinpath(\"svgs/\"),\n                }\n                _ = [\n                    i.mkdir(exist_ok=True, parents=True) for i in dirs.values()\n                ]\n                # if verbose:\n                logger.info(f\"Saving {key} plot to: {Path(outdir).resolve()}\")\n                for ext, d in dirs.items():\n                    outfile = d.joinpath(f\"{key}.{ext}\")\n                    if outfile.is_file():\n                        outfile = d.joinpath(f\"{key}-subfig.{ext}\")\n                    # logger.info(f\"Saving {key}.ext to: {outfile}\")\n                    if verbose:\n                        logger.info(\n                            f\"Saving {key} plot to: {outfile.resolve()}\"\n                        )\n                    plt.savefig(outfile, dpi=400, bbox_inches=\"tight\")\n            if is_interactive():\n                plt.show()\n\n        return dataset\n\n    def history_to_dict(self) -&gt; dict:\n        # return {k: np.stack(v).squeeze() for k, v in self.history.items()}\n        return {\n            k: torch.Tensor(v).numpy(force=True)\n            for k, v in self.history.items()\n        }\n\n    def to_DataArray(\n        self,\n        x: Union[list, np.ndarray, torch.Tensor],\n        warmup: Optional[float] = 0.0,\n    ) -&gt; xr.DataArray:\n        if isinstance(x, list) and isinstance(x[0], torch.Tensor):\n            x = torch.Tensor(x).numpy(force=True)\n        try:\n            arr = grab_tensor(x)\n        except ValueError:\n            arr = np.array(x).real\n            # arr = np.array(x)\n            logger.info(f\"len(x): {len(x)}\")\n            logger.info(f\"x[0].shape: {x[0].shape}\")\n            logger.info(f\"arr.shape: {arr.shape}\")\n        assert isinstance(arr, np.ndarray)\n        if warmup is not None and warmup &gt; 0 and len(arr) &gt; 0:\n            if isinstance(warmup, int):\n                warmup = warmup / len(arr)\n            # drop = int(warmup * arr.shape[0])\n            drop = int(warmup * len(arr))\n            arr = arr[drop:]\n        # steps = np.arange(len(arr))\n        if len(arr.shape) == 1:  # [ndraws]\n            ndraws = arr.shape[0]\n            dims = [\"draw\"]\n            coords = [np.arange(len(arr))]\n            return xr.DataArray(arr, dims=dims, coords=coords)  # type:ignore\n\n        if len(arr.shape) == 2:  # [nchains, ndraws]\n            arr = arr.T\n            nchains, ndraws = arr.shape\n            dims = (\"chain\", \"draw\")\n            coords = [np.arange(nchains), np.arange(ndraws)]\n            return xr.DataArray(arr, dims=dims, coords=coords)  # type:ignore\n\n        if len(arr.shape) == 3:  # [nchains, nlf, ndraws]\n            arr = arr.T\n            nchains, nlf, ndraws = arr.shape\n            dims = (\"chain\", \"leapfrog\", \"draw\")\n            coords = [np.arange(nchains), np.arange(nlf), np.arange(ndraws)]\n            return xr.DataArray(arr, dims=dims, coords=coords)  # type:ignore\n\n        else:\n            print(f\"arr.shape: {arr.shape}\")\n            raise ValueError(\"Invalid shape encountered\")\n\n    def get_dataset(\n        self,\n        data: Optional[dict[str, Union[list, np.ndarray, torch.Tensor]]] = None,\n        warmup: Optional[float] = 0.0,\n    ):\n        data = self.history_to_dict() if data is None else data\n        data_vars = {}\n        for key, val in data.items():\n            name = key.replace(\"/\", \"_\")\n            try:\n                data_vars[name] = self.to_DataArray(val, warmup)\n            except ValueError:\n                logger.error(f\"Unable to create DataArray for {key}! Skipping!\")\n                logger.error(f\"{key}.shape= {np.stack(val).shape}\")  # type:ignore\n        return xr.Dataset(data_vars)\n\n    def save_dataset(\n        self,\n        outdir: PathLike,\n        fname: str = \"dataset\",\n        use_hdf5: bool = True,\n        data: Optional[dict[str, Union[list, np.ndarray, torch.Tensor]]] = None,\n        dataset: Optional[xr.Dataset] = None,\n        warmup: Optional[int | float] = None,\n        **kwargs,\n    ) -&gt; Path:\n        dataset = (\n            dataset\n            if dataset is not None\n            else (\n                self.get_dataset(\n                    data=(data if data is not None else self.history),\n                    warmup=warmup,\n                )\n            )\n        )\n        return save_dataset(\n            dataset,\n            outdir=outdir,\n            fname=fname,\n            use_hdf5=use_hdf5,\n            **kwargs,\n        )\n\n    def finalize(\n        self,\n        outdir: Optional[PathLike] = None,\n        run_name: Optional[str] = None,\n        dataset_fname: Optional[str] = None,\n        num_chains: int = 128,\n        warmup: Optional[int | float] = 0.0,\n        verbose: bool = False,\n        save: bool = True,\n        plot: bool = True,\n        append_tplot: bool = True,\n        title: Optional[str] = None,\n        data: Optional[dict[str, Union[list, np.ndarray, torch.Tensor]]] = None,\n        dataset: Optional[xr.Dataset] = None,\n        xkey: Optional[str] = None,\n        plot_kwargs: Optional[dict[str, Any]] = None,\n        subplots_kwargs: Optional[dict[str, Any]] = None,\n        tplot_type: Optional[str] = None,\n    ) -&gt; xr.Dataset:\n        dataset = (\n            dataset\n            if dataset is not None\n            else (\n                self.get_dataset(\n                    data=(data if data is not None else self.history),\n                    warmup=warmup,\n                )\n            )\n        )\n        run_name = (\n            f\"History-{get_timestamp()}\" if run_name is None else run_name\n        )\n        fallback_outdir = Path(os.getcwd()).joinpath(\"outputs\")\n        if run_name is not None:\n            fallback_outdir = fallback_outdir.joinpath(\n                run_name, get_timestamp()\n            )\n        outdir = (\n            # Path(os.getcwd()).joinpath('outputs')\n            fallback_outdir if outdir is None else Path(outdir)\n        )\n        outdir = outdir.joinpath(run_name)\n        if plot:\n            plotdir = outdir.joinpath(\"plots\")\n            tplotdir = plotdir.joinpath(\"tplot\")\n            mplotdir = plotdir.joinpath(\"mplot\")\n            tplotdir.mkdir(exist_ok=True, parents=True)\n            mplotdir.mkdir(exist_ok=True, parents=True)\n            _ = self.plot_all(\n                dataset=dataset,\n                outdir=mplotdir,\n                verbose=verbose,\n                num_chains=num_chains,\n                warmup=warmup,\n                title=title,\n                plot_kwargs=plot_kwargs,\n                subplots_kwargs=subplots_kwargs,\n            )\n            _ = self.tplot_all(\n                dataset=dataset,\n                outdir=tplotdir,\n                warmup=warmup,\n                append=append_tplot,\n                plot_type=tplot_type,\n                xkey=xkey,\n                verbose=verbose,\n            )\n        if save:\n            fname = \"dataset\" if dataset_fname is None else dataset_fname\n            _ = self.save_dataset(dataset=dataset, outdir=outdir, fname=fname)\n        return dataset\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.History.plot","title":"<code>plot(val, key=None, warmup=0.0, num_chains=128, title=None, outdir=None, subplots_kwargs=None, plot_kwargs=None)</code>","text":"<p>Plot a single variable from the history.</p> <p>NOTE: The <code>warmup</code> argument can be used to drop the first <code>warmup</code> iterations (as a percent of the total number of iterations) from the plot.</p> Source code in <code>src/ezpz/history.py</code> <pre><code>def plot(\n    self,\n    val: np.ndarray,\n    key: Optional[str] = None,\n    warmup: Optional[float] = 0.0,\n    num_chains: Optional[int] = 128,\n    title: Optional[str] = None,\n    outdir: Optional[os.PathLike] = None,\n    subplots_kwargs: Optional[dict[str, Any]] = None,\n    plot_kwargs: Optional[dict[str, Any]] = None,\n):\n    \"\"\"\n    Plot a single variable from the history.\n\n    NOTE: The `warmup` argument can be used to drop the first `warmup`\n    iterations (as a percent of the total number of iterations) from the\n    plot.\n    \"\"\"\n    plot_kwargs = {} if plot_kwargs is None else plot_kwargs\n    subplots_kwargs = {} if subplots_kwargs is None else subplots_kwargs\n    figsize = subplots_kwargs.get(\"figsize\", ezplot.set_size())\n    subplots_kwargs.update({\"figsize\": figsize})\n    num_chains = 16 if num_chains is None else num_chains\n\n    # tmp = val[0]\n    arr = np.array(val)\n\n    subfigs = None\n    steps = np.arange(arr.shape[0])\n    if warmup is not None and warmup &gt; 0:\n        drop = int(warmup * arr.shape[0])\n        arr = arr[drop:]\n        steps = steps[drop:]\n\n    if len(arr.shape) == 2:\n        import seaborn as sns\n\n        _ = subplots_kwargs.pop(\"constrained_layout\", True)\n        figsize = (3 * figsize[0], 1.5 * figsize[1])\n\n        fig = plt.figure(figsize=figsize, constrained_layout=True)\n        subfigs = fig.subfigures(1, 2)\n\n        gs_kw = {\"width_ratios\": [1.33, 0.33]}\n        (ax, ax1) = subfigs[1].subplots(\n            1, 2, sharey=True, gridspec_kw=gs_kw\n        )\n        ax.grid(alpha=0.2)\n        ax1.grid(False)\n        color = plot_kwargs.get(\"color\", None)\n        label = r\"$\\langle$\" + f\" {key} \" + r\"$\\rangle$\"\n        ax.plot(\n            steps, arr.mean(-1), lw=1.5 * LW, label=label, **plot_kwargs\n        )\n        sns.kdeplot(y=arr.flatten(), ax=ax1, color=color, shade=True)\n        ax1.set_xticks([])\n        ax1.set_xticklabels([])\n        # ax1.set_yticks([])\n        # ax1.set_yticklabels([])\n        sns.despine(ax=ax, top=True, right=True)\n        sns.despine(ax=ax1, top=True, right=True, left=True, bottom=True)\n        # ax.legend(loc='best', frameon=False)\n        ax1.set_xlabel(\"\")\n        # ax1.set_ylabel('')\n        # ax.set_yticks(ax.get_yticks())\n        # ax.set_yticklabels(ax.get_yticklabels())\n        # ax.set_ylabel(key)\n        # _ = subfigs[1].subplots_adjust(wspace=-0.75)\n        axes = (ax, ax1)\n    else:\n        if len(arr.shape) == 1:\n            fig, ax = plt.subplots(**subplots_kwargs)\n            assert isinstance(ax, plt.Axes)\n            ax.plot(steps, arr, **plot_kwargs)\n            axes = ax\n        elif len(arr.shape) == 3:\n            fig, ax = plt.subplots(**subplots_kwargs)\n            assert isinstance(ax, plt.Axes)\n            cmap = plt.get_cmap(\"viridis\")\n            nlf = arr.shape[1]\n            for idx in range(nlf):\n                # y = arr[:, idx, :].mean(-1)\n                # pkwargs = {\n                #     'color': cmap(idx / nlf),\n                #     'label': f'{idx}',\n                # }\n                # ax.plot(steps, y, **pkwargs)\n                label = plot_kwargs.pop(\"label\", None)\n                if label is not None:\n                    label = f\"{label}-{idx}\"\n                y = arr[:, idx, :]\n                color = cmap(idx / y.shape[1])\n                plot_kwargs[\"color\"] = cmap(idx / y.shape[1])\n                if len(y.shape) == 2:\n                    # TOO: Plot chains\n                    if num_chains &gt; 0:\n                        for idx in range(min((num_chains, y.shape[1]))):\n                            _ = ax.plot(\n                                steps,\n                                y[:, idx],  # color,\n                                lw=LW / 2.0,\n                                alpha=0.8,\n                                **plot_kwargs,\n                            )\n\n                    _ = ax.plot(\n                        steps,\n                        y.mean(-1),  # color=color,\n                        label=label,\n                        **plot_kwargs,\n                    )\n                else:\n                    _ = ax.plot(\n                        steps,\n                        y,  # color=color,\n                        label=label,\n                        **plot_kwargs,\n                    )\n            axes = ax\n        else:\n            raise ValueError(\"Unexpected shape encountered\")\n\n        ax.set_ylabel(key)\n\n    if num_chains &gt; 0 and len(arr.shape) &gt; 1:\n        # lw = LW / 2.\n        for idx in range(min(num_chains, arr.shape[1])):\n            # ax = subfigs[0].subplots(1, 1)\n            # plot values of invidual chains, arr[:, idx]\n            # where arr[:, idx].shape = [ndraws, 1]\n            ax.plot(\n                steps, arr[:, idx], alpha=0.5, lw=LW / 2.0, **plot_kwargs\n            )\n\n    ax.set_xlabel(\"draw\")\n    if title is not None:\n        fig.suptitle(title)\n\n    if outdir is not None:\n        # plt.savefig(Path(outdir).joinpath(f'{key}.svg'),\n        #             dpi=400, bbox_inches='tight')\n        outfile = Path(outdir).joinpath(f\"{key}.svg\")\n        if outfile.is_file():\n            tstamp = ezpz.get_timestamp()\n            pngdir = Path(outdir).joinpath(\"pngs\")\n            pngdir.mkdir(exist_ok=True, parents=True)\n            pngfile = pngdir.joinpath(f\"{key}-{tstamp}.png\")\n            svgfile = Path(outdir).joinpath(f\"{key}-{tstamp}.svg\")\n            plt.savefig(pngfile, dpi=400, bbox_inches=\"tight\")\n            plt.savefig(svgfile, dpi=400, bbox_inches=\"tight\")\n\n    return fig, subfigs, axes\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.RichHandler","title":"<code>RichHandler</code>","text":"<p>               Bases: <code>RichHandler</code></p> <p>Enriched handler that does not wrap.</p> Source code in <code>src/ezpz/log/handler.py</code> <pre><code>class RichHandler(OriginalRichHandler):\n    \"\"\"Enriched handler that does not wrap.\"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        if 'console' not in kwargs:\n            console = get_console(\n                redirect=False, width=9999, markup=use_colored_logs()\n            )\n            kwargs['console'] = console\n            self.__console = console\n        super().__init__(*args, **kwargs)\n        # RichHandler constructor does not allow custom renderer\n        # https://github.com/willmcgugan/rich/issues/438\n        self._log_render = FluidLogRender(\n            show_time=kwargs.get('show_time', True),\n            show_level=kwargs.get('show_level', True),\n            show_path=kwargs.get('show_path', True),\n        )  # type: ignore\n\n    def render(\n        self,\n        *,\n        record: LogRecord,\n        traceback: Optional[Any],\n        message_renderable: 'ConsoleRenderable',\n    ) -&gt; 'ConsoleRenderable':\n        \"\"\"Render log for display.\n\n        Args:\n            record (LogRecord): logging Record.\n            traceback (Optional[Traceback]): Traceback instance or None for no Traceback.\n            message_renderable (ConsoleRenderable): Renderable (typically Text) containing log message contents.\n\n        Returns:\n            ConsoleRenderable: Renderable to display log.\n        \"\"\"\n        fp = Path(record.pathname)\n        parent = fp.parent.as_posix().split('/')[-1]\n        module = getattr(record, 'module', None)\n        name = getattr(record, 'name', None)\n\n        parr = [parent]\n        if module is not None:\n            parr.append(module)\n        if name is not None and f'{parent}.{module}' != name:\n            parr.append(name)\n        pstr = '/'.join([parr[0], '.'.join(parr[1:])])\n\n        level = self.get_level_text(record)\n        time_format = None if self.formatter is None else self.formatter.datefmt\n        # default_time_fmt = '%Y-%m-%d %H:%M:%S.%f'\n        default_time_fmt = '%Y-%m-%d %H:%M:%S'  # .%f'\n        time_format = time_format if time_format else default_time_fmt\n        log_time = datetime.fromtimestamp(record.created)\n\n        log_renderable = self._log_render(\n            self.__console,\n            [message_renderable]\n            if not traceback\n            else [message_renderable, traceback],\n            log_time=log_time,\n            time_format=time_format,\n            level=level,\n            path=pstr,\n            line_no=record.lineno,\n            link_path=record.pathname if self.enable_link_path else None,\n        )\n        return log_renderable\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.RichHandler.render","title":"<code>render(*, record, traceback, message_renderable)</code>","text":"<p>Render log for display.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>LogRecord</code> <p>logging Record.</p> required <code>traceback</code> <code>Optional[Traceback]</code> <p>Traceback instance or None for no Traceback.</p> required <code>message_renderable</code> <code>ConsoleRenderable</code> <p>Renderable (typically Text) containing log message contents.</p> required <p>Returns:</p> Name Type Description <code>ConsoleRenderable</code> <code>ConsoleRenderable</code> <p>Renderable to display log.</p> Source code in <code>src/ezpz/log/handler.py</code> <pre><code>def render(\n    self,\n    *,\n    record: LogRecord,\n    traceback: Optional[Any],\n    message_renderable: 'ConsoleRenderable',\n) -&gt; 'ConsoleRenderable':\n    \"\"\"Render log for display.\n\n    Args:\n        record (LogRecord): logging Record.\n        traceback (Optional[Traceback]): Traceback instance or None for no Traceback.\n        message_renderable (ConsoleRenderable): Renderable (typically Text) containing log message contents.\n\n    Returns:\n        ConsoleRenderable: Renderable to display log.\n    \"\"\"\n    fp = Path(record.pathname)\n    parent = fp.parent.as_posix().split('/')[-1]\n    module = getattr(record, 'module', None)\n    name = getattr(record, 'name', None)\n\n    parr = [parent]\n    if module is not None:\n        parr.append(module)\n    if name is not None and f'{parent}.{module}' != name:\n        parr.append(name)\n    pstr = '/'.join([parr[0], '.'.join(parr[1:])])\n\n    level = self.get_level_text(record)\n    time_format = None if self.formatter is None else self.formatter.datefmt\n    # default_time_fmt = '%Y-%m-%d %H:%M:%S.%f'\n    default_time_fmt = '%Y-%m-%d %H:%M:%S'  # .%f'\n    time_format = time_format if time_format else default_time_fmt\n    log_time = datetime.fromtimestamp(record.created)\n\n    log_renderable = self._log_render(\n        self.__console,\n        [message_renderable]\n        if not traceback\n        else [message_renderable, traceback],\n        log_time=log_time,\n        time_format=time_format,\n        level=level,\n        path=pstr,\n        line_no=record.lineno,\n        link_path=record.pathname if self.enable_link_path else None,\n    )\n    return log_renderable\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.breakpoint","title":"<code>breakpoint(rank=0)</code>","text":"<p>Set a breakpoint, but only on a single rank.  All other ranks will wait for you to be done with the breakpoint before continuing.</p> <p>Parameters:</p> Name Type Description Default <code>rank</code> <code>int</code> <p>Which rank to break on.  Default: <code>0</code></p> <code>0</code> Source code in <code>src/ezpz/utils.py</code> <pre><code>def breakpoint(rank: int = 0):\n    \"\"\"\n    Set a breakpoint, but only on a single rank.  All other ranks will wait for you to be\n    done with the breakpoint before continuing.\n\n    Args:\n        rank (int): Which rank to break on.  Default: ``0``\n    \"\"\"\n    if get_rank() == rank:\n        pdb = DistributedPdb()\n        pdb.message(\n            \"\\n!!! ATTENTION !!!\\n\\n\"\n            f\"Type 'up' to get to the frame that called dist.breakpoint(rank={rank})\\n\"\n        )\n        pdb.set_trace()\n    tdist.barrier()\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.check","title":"<code>check(framework='pytorch', backend='deepspeed', port='5432')</code>","text":"<p>Check if the framework is installed and working</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def check(\n    framework: str = \"pytorch\",\n    backend: str = \"deepspeed\",\n    port: int | str = \"5432\",\n):\n    \"\"\"Check if the framework is installed and working\"\"\"\n    from ezpz.configs import FRAMEWORKS\n\n    if framework in FRAMEWORKS[\"pytorch\"]:\n        _ = setup_torch(\n            backend=backend,\n            port=str(port),\n        )\n    elif framework in FRAMEWORKS[\"tensorflow\"]:\n        _ = setup_tensorflow()\n    else:\n        raise ValueError(f\"Unable to parse framework: {framework}\")\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.destroy_tensor_parallel","title":"<code>destroy_tensor_parallel()</code>","text":"<p>Set the groups to none.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def destroy_tensor_parallel() -&gt; None:\n    \"\"\"Set the groups to none.\"\"\"\n    global _TENSOR_PARALLEL_GROUP\n    _TENSOR_PARALLEL_GROUP = None\n    global _TENSOR_PARALLEL_RANKS\n    _TENSOR_PARALLEL_RANKS = None\n\n    global _DATA_PARALLEL_GROUP\n    _DATA_PARALLEL_GROUP = None\n    global _DATA_PARALLEL_RANKS\n    _DATA_PARALLEL_RANKS = None\n\n    global _PIPELINE_PARALLEL_GROUP\n    _PIPELINE_PARALLEL_GROUP = None\n    global _PIPELINE_PARALLEL_RANKS\n    _PIPELINE_PARALLEL_RANKS = None\n\n    global _CONTEXT_PARALLEL_GROUP\n    _CONTEXT_PARALLEL_GROUP = None\n    global _CONTEXT_PARALLEL_GROUP_RANKS\n    _CONTEXT_PARALLEL_GROUP_RANKS = None\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.ensure_divisibility","title":"<code>ensure_divisibility(numerator, denominator)</code>","text":"<p>Ensure that numerator is divisible by the denominator.</p> Source code in <code>src/ezpz/tp/utils.py</code> <pre><code>def ensure_divisibility(numerator: int, denominator: int) -&gt; None:\n    \"\"\"Ensure that numerator is divisible by the denominator.\"\"\"\n    assert numerator % denominator == 0, '{} is not divisible by {}'.format(\n        numerator, denominator\n    )\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_context_parallel_group","title":"<code>get_context_parallel_group()</code>","text":"<p>Get the context parallel group the caller rank belongs to.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_context_parallel_group() -&gt; tdist.ProcessGroup:\n    \"\"\"Get the context parallel group the caller rank belongs to.\"\"\"\n    assert _CONTEXT_PARALLEL_GROUP is not None, (\n        'context parallel group is not initialized'\n    )\n    return _CONTEXT_PARALLEL_GROUP\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_context_parallel_rank","title":"<code>get_context_parallel_rank()</code>","text":"<p>Return my rank for the context parallel group.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_context_parallel_rank() -&gt; int:\n    \"\"\"Return my rank for the context parallel group.\"\"\"\n    return tdist.get_rank(group=get_context_parallel_group())\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_context_parallel_ranks","title":"<code>get_context_parallel_ranks()</code>","text":"<p>Return context parallel ranks for the context parallel group.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_context_parallel_ranks() -&gt; List[int]:\n    \"\"\"Return context parallel ranks for the context parallel group.\"\"\"\n    assert _CONTEXT_PARALLEL_GROUP_RANKS is not None, (\n        'context parallel group is not initialized'\n    )\n    return _CONTEXT_PARALLEL_GROUP_RANKS\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_context_parallel_world_size","title":"<code>get_context_parallel_world_size()</code>","text":"<p>Return world size for the context parallel group.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_context_parallel_world_size() -&gt; int:\n    \"\"\"Return world size for the context parallel group.\"\"\"\n    return tdist.get_world_size(group=get_context_parallel_group())\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_cpus_per_node","title":"<code>get_cpus_per_node()</code>","text":"<p>Get the number of CPUs per node</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_cpus_per_node() -&gt; int:\n    \"\"\"Get the number of CPUs per node\"\"\"\n    from sh import getconf as sh_getconf  # type:ignore noqa\n\n    return int(sh_getconf(\"_NPROCESSORS_ONLN\").rstrip(\"\\n\"))\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_data_parallel_group","title":"<code>get_data_parallel_group()</code>","text":"<p>Get the data parallel group the caller rank belongs to.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_data_parallel_group() -&gt; tdist.ProcessGroup:\n    \"\"\"Get the data parallel group the caller rank belongs to.\"\"\"\n    assert _DATA_PARALLEL_GROUP is not None, (\n        'data parallel group is not initialized'\n    )\n    return _DATA_PARALLEL_GROUP\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_data_parallel_rank","title":"<code>get_data_parallel_rank()</code>","text":"<p>Return my rank for the data parallel group.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_data_parallel_rank() -&gt; int:\n    \"\"\"Return my rank for the data parallel group.\"\"\"\n    return tdist.get_rank(group=get_data_parallel_group())\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_data_parallel_world_size","title":"<code>get_data_parallel_world_size()</code>","text":"<p>Return world size for the data parallel group.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_data_parallel_world_size() -&gt; int:\n    \"\"\"Return world size for the data parallel group.\"\"\"\n    return tdist.get_world_size(group=get_data_parallel_group())\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_gpus_per_node","title":"<code>get_gpus_per_node()</code>","text":"<p>Get the number of GPUs per node</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_gpus_per_node() -&gt; int:\n    \"\"\"Get the number of GPUs per node\"\"\"\n    # return torch.cuda.device_count() if torch.cuda.is_available() else (\n    #     (\n    #         ipex.xpu.device_count() if ipex is not None else (\n    #             get_cpus_per_node()\n    #         )\n    #     )\n    # )\n    # if _assert:\n    #     raise RuntimeError(\n    #         'No {X, G}pus found; but _assert specified. Returning !!'\n    #     )\n    # logger.warning('No {x,g}-pus found, returning' + f'{cpus_per_node}')\n    ngpu_per_host = os.environ.get(\"NGPU_PER_HOST\", None)\n    if ngpu_per_host is not None:\n        return int(ngpu_per_host)\n    if torch.cuda.is_available():\n        return torch.cuda.device_count()\n    if torch.xpu.is_available():\n        return torch.xpu.device_count()\n    if ipex is not None:\n        return ipex.xpu.device_count()  # type:ignore\n    return get_cpus_per_node()\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_local_rank","title":"<code>get_local_rank()</code>","text":"<p>Return <code>get_rank() % get_gpus_per_node()</code></p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_local_rank() -&gt; int:\n    \"\"\"Return `get_rank() % get_gpus_per_node()`\"\"\"\n    return int(get_rank() % get_gpus_per_node())\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_node_index","title":"<code>get_node_index()</code>","text":"<p>Get the index of the current node in the hostfile</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_node_index() -&gt; int:\n    \"\"\"Get the index of the current node in the hostfile\"\"\"\n    return get_rank() % get_num_nodes()\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_num_nodes","title":"<code>get_num_nodes(hostfile=None)</code>","text":"<p>Get the number of nodes from the hostfile</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_num_nodes(hostfile: Optional[PathLike] = None) -&gt; int:\n    \"\"\"Get the number of nodes from the hostfile\"\"\"\n    num_nodes = os.environ.get(\"SLURM_NNODES\", None)\n    if num_nodes is not None:\n        return int(num_nodes)\n    hfp = get_hostfile_with_fallback(hostfile)\n    hosts = [h.split(\".\")[0] for h in get_nodes_from_hostfile(hfp)]\n    return len(hosts)\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_pipeline_parallel_group","title":"<code>get_pipeline_parallel_group()</code>","text":"<p>Get the pipeline parallel group the caller rank belongs to.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_pipeline_parallel_group() -&gt; tdist.ProcessGroup:\n    \"\"\"Get the pipeline parallel group the caller rank belongs to.\"\"\"\n    assert _PIPELINE_PARALLEL_GROUP is not None, (\n        'pipeline parallel group is not initialized'\n    )\n    return _PIPELINE_PARALLEL_GROUP\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_pipeline_parallel_ranks","title":"<code>get_pipeline_parallel_ranks()</code>","text":"<p>Get the pipeline parallel group the caller rank belongs to.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_pipeline_parallel_ranks() -&gt; List[int]:\n    \"\"\"Get the pipeline parallel group the caller rank belongs to.\"\"\"\n    assert _PIPELINE_PARALLEL_RANKS is not None, (\n        'pipeline parallel group is not initialized'\n    )\n    return _PIPELINE_PARALLEL_RANKS\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_rank","title":"<code>get_rank()</code>","text":"<p>Get current MPI rank</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def get_rank() -&gt; int:\n    \"\"\"Get current MPI rank\"\"\"\n    return int(MPI.COMM_WORLD.Get_rank())\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_tensor_parallel_group","title":"<code>get_tensor_parallel_group()</code>","text":"<p>Get the tensor parallel group the caller rank belongs to.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_tensor_parallel_group() -&gt; tdist.ProcessGroup:\n    \"\"\"Get the tensor parallel group the caller rank belongs to.\"\"\"\n    assert _TENSOR_PARALLEL_GROUP is not None, (\n        'tensor parallel group is not initialized'\n    )\n    return _TENSOR_PARALLEL_GROUP\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_tensor_parallel_rank","title":"<code>get_tensor_parallel_rank()</code>","text":"<p>Return my rank for the tensor parallel group.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_tensor_parallel_rank() -&gt; int:\n    \"\"\"Return my rank for the tensor parallel group.\"\"\"\n    return tdist.get_rank(group=get_tensor_parallel_group())\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_tensor_parallel_src_rank","title":"<code>get_tensor_parallel_src_rank()</code>","text":"<p>Calculate the global rank corresponding to local rank 0 in the TP group.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_tensor_parallel_src_rank() -&gt; int:\n    \"\"\"\n    Calculate the global rank corresponding to local rank 0 in the TP group.\n    \"\"\"\n    global_rank = tdist.get_rank()\n    local_world_size = get_tensor_parallel_world_size()\n    return (global_rank // local_world_size) * local_world_size\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_tensor_parallel_world_size","title":"<code>get_tensor_parallel_world_size()</code>","text":"<p>Return world size for the tensor parallel group.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def get_tensor_parallel_world_size() -&gt; int:\n    \"\"\"Return world size for the tensor parallel group.\"\"\"\n    return tdist.get_world_size(group=get_tensor_parallel_group())\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.get_timestamp","title":"<code>get_timestamp(fstr=None)</code>","text":"<p>Get formatted timestamp.</p> Source code in <code>src/ezpz/utils.py</code> <pre><code>def get_timestamp(fstr: Optional[str] = None) -&gt; str:\n    \"\"\"Get formatted timestamp.\"\"\"\n    import datetime\n\n    now = datetime.datetime.now()\n    return (\n        now.strftime(\"%Y-%m-%d-%H%M%S\") if fstr is None else now.strftime(fstr)\n    )\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.initialize_tensor_parallel","title":"<code>initialize_tensor_parallel(tensor_parallel_size=1, pipeline_parallel_size=1, context_parallel_size=1, tensor_parallel_backend=None, pipeline_parallel_backend=None, context_parallel_backend=None, data_parallel_backend=None, timeout=None)</code>","text":"<p>Initialize tensor data parallel groups.</p> <p>Parameters:</p> Name Type Description Default <code>tensor_parallel_size</code> <code>int</code> <p>number of GPUs used to parallelize model.</p> <code>1</code> <p>Let's say we have a total of 8 GPUs denoted by g0 ... g7 and we use 2 GPUs to parallelize the model. The present function will create 4 tensor parallel groups and 2 data parallel groups as:     4 tensor parallel groups:         [g0, g1], [g2, g3], [g4, g5], [g6, g7]     2 data parallel groups:         [g0, g2, g4, g6], [g1, g3, g5, g7] Note that for efficiency, the caller should make sure adjacent ranks are on the same DGX box. For example if we are using 2 DGX-1 boxes with a total of 16 GPUs, rank 0 to 7 belong to the first box and ranks 8 to 15 belong to the second box.</p> <p>process groups initialized in the order of TP, CP, PP, DP.</p> <p>Let's say we have a total of 16 GPUs denoted by g0 ... g15 and we use 2 GPUs to parallelize the tensor tensor, 2 GPUs to parallelize context(seq len), and 2 GPUs to parallelize the tensor pipeline. The present function will create 8 tensor model-parallel groups, 8 context-parallel group, 8 pipeline model-parallel groups and 8 data-parallel groups as: when alternate_pp_config = False,     8 data_parallel groups:         [g0, g4], [g1, g5], [g2, g6], [g3, g7], [g8, g12], [g9, g13], [g10, g14], [g11, g15]     8 tensor model-parallel groups:         [g0, g1], [g2, g3], [g4, g5], [g6, g7], [g8, g9], [g10, g11], [g12, g13], [g14, g15]     8 context-parallel groups:         [g0, g2], [g1, g3], [g4, g6], [g5, g7], [g8, g10], [g9, g11], [g12, g14], [g13, g15]     8 pipeline model-parallel groups:         [g0, g8], [g1, g9], [g2, g10], [g3, g11], [g4, g12], [g5, g13], [g6, g16], [g7, g15]</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def initialize_tensor_parallel(\n    tensor_parallel_size: int = 1,\n    pipeline_parallel_size: int = 1,\n    context_parallel_size: int = 1,\n    tensor_parallel_backend: Optional[str] = None,\n    pipeline_parallel_backend: Optional[str] = None,\n    context_parallel_backend: Optional[str] = None,\n    data_parallel_backend: Optional[str] = None,\n    timeout: Optional[timedelta] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize tensor data parallel groups.\n\n    Arguments:\n        tensor_parallel_size: number of GPUs used to parallelize model.\n\n    Let's say we have a total of 8 GPUs denoted by g0 ... g7 and we\n    use 2 GPUs to parallelize the model. The present function will\n    create 4 tensor parallel groups and 2 data parallel groups as:\n        4 tensor parallel groups:\n            [g0, g1], [g2, g3], [g4, g5], [g6, g7]\n        2 data parallel groups:\n            [g0, g2, g4, g6], [g1, g3, g5, g7]\n    Note that for efficiency, the caller should make sure adjacent ranks\n    are on the same DGX box. For example if we are using 2 DGX-1 boxes\n    with a total of 16 GPUs, rank 0 to 7 belong to the first box and\n    ranks 8 to 15 belong to the second box.\n\n    process groups initialized in the order of TP, CP, PP, DP.\n\n    Let's say we have a total of 16 GPUs denoted by g0 ... g15 and we\n    use 2 GPUs to parallelize the tensor tensor, 2 GPUs to parallelize context(seq len), and 2 GPUs to parallelize\n    the tensor pipeline. The present function will\n    create 8 tensor model-parallel groups, 8 context-parallel group, 8 pipeline model-parallel groups\n    and 8 data-parallel groups as:\n    when alternate_pp_config = False,\n        8 data_parallel groups:\n            [g0, g4], [g1, g5], [g2, g6], [g3, g7], [g8, g12], [g9, g13], [g10, g14], [g11, g15]\n        8 tensor model-parallel groups:\n            [g0, g1], [g2, g3], [g4, g5], [g6, g7], [g8, g9], [g10, g11], [g12, g13], [g14, g15]\n        8 context-parallel groups:\n            [g0, g2], [g1, g3], [g4, g6], [g5, g7], [g8, g10], [g9, g11], [g12, g14], [g13, g15]\n        8 pipeline model-parallel groups:\n            [g0, g8], [g1, g9], [g2, g10], [g3, g11], [g4, g12], [g5, g13], [g6, g16], [g7, g15]\n    \"\"\"\n    # Get world size and rank. Ensure some consistencies.\n    assert tdist.is_initialized()\n    world_size = tdist.get_world_size()\n    tensor_parallel_size = int(min(tensor_parallel_size, world_size))\n    ensure_divisibility(world_size, tensor_parallel_size)\n    ensure_divisibility(world_size, context_parallel_size)\n    ensure_divisibility(\n        world_size,\n        tensor_parallel_size * pipeline_parallel_size * context_parallel_size,\n    )\n    rank = tdist.get_rank()\n\n    dpsize = int(\n        world_size\n        / (\n            tensor_parallel_size\n            * pipeline_parallel_size\n            * context_parallel_size\n        )\n    )\n\n    if tdist.get_rank() == 0:\n        pstr = ', '.join(\n            [\n                f'TP: {tensor_parallel_size}',\n                f'PP: {pipeline_parallel_size}',\n                f'CP: {context_parallel_size}',\n                f'DP: {dpsize}',\n            ]\n        )\n        logger.info(pstr)\n        # pstr = f'TP: {tensor_parallel_size}, PP: {pipeline_parallel_size}, CP: {context_parallel_size}, DP: {dpsize}'\n        # logger.info(\n        #     '&gt; initializing tensor parallel with size {}'.format(\n        #         tensor_parallel_size\n        #     )\n        # )\n        # logger.info(\n        #     '&gt; initializing context parallel with size {}'.format(\n        #         context_parallel_size\n        #     )\n        # )\n        # logger.info(\n        #     '&gt; initializing pipeline with size {}'.format(\n        #         pipeline_parallel_size\n        #     )\n        # )\n\n    groups = torch.LongTensor(range(world_size)).reshape(\n        dpsize,\n        pipeline_parallel_size,\n        context_parallel_size,\n        tensor_parallel_size,\n    )\n\n    found = torch.where(groups == rank)\n    assert all(len(x) == 1 for x in found)\n    found = [x[0] for x in found]\n\n    # Build the data parallel groups.\n    global _DATA_PARALLEL_GROUP\n    global _DATA_PARALLEL_RANKS\n    assert _DATA_PARALLEL_GROUP is None, (\n        'data parallel group is already initialized'\n    )\n    assert _DATA_PARALLEL_RANKS is None, (\n        'data parallel ranks are already initialized'\n    )\n    for i in range(pipeline_parallel_size):\n        for j in range(context_parallel_size):\n            for k in range(tensor_parallel_size):\n                ranks = groups[:, i, j, k].tolist()\n                group = tdist.new_group(\n                    groups[:, i, j, k].tolist(),\n                    backend=data_parallel_backend,\n                    timeout=timeout,\n                )\n                if i == found[1] and j == found[2] and k == found[3]:\n                    _DATA_PARALLEL_GROUP = group\n                    _DATA_PARALLEL_RANKS = ranks\n\n    # Build the tensor parallel groups.\n    global _TENSOR_PARALLEL_GROUP\n    global _TENSOR_PARALLEL_RANKS\n    assert _TENSOR_PARALLEL_GROUP is None, (\n        'tensor parallel group is already initialized'\n    )\n    assert _TENSOR_PARALLEL_RANKS is None, (\n        'tensor parallel ranks are already initialized'\n    )\n    for i in range(dpsize):\n        for j in range(pipeline_parallel_size):\n            for k in range(context_parallel_size):\n                ranks = groups[i, j, k, :].tolist()\n                group = tdist.new_group(\n                    groups[i, j, k, :].tolist(),\n                    backend=tensor_parallel_backend,\n                    timeout=timeout,\n                )\n                if i == found[0] and j == found[1] and k == found[2]:\n                    _TENSOR_PARALLEL_GROUP = group\n                    _TENSOR_PARALLEL_RANKS = ranks\n\n    # Build the pipeline parallel groups.\n    global _PIPELINE_PARALLEL_GROUP\n    global _PIPELINE_PARALLEL_RANKS\n    assert _PIPELINE_PARALLEL_GROUP is None, (\n        'Pipeline parallel group is already initialized'\n    )\n    for i in range(dpsize):\n        for j in range(context_parallel_size):\n            for k in range(tensor_parallel_size):\n                ranks = groups[i, :, j, k].tolist()\n                group = tdist.new_group(\n                    ranks, backend=pipeline_parallel_backend, timeout=timeout\n                )\n                if i == found[0] and j == found[2] and k == found[3]:\n                    _PIPELINE_PARALLEL_GROUP = group\n                    _PIPELINE_PARALLEL_RANKS = ranks\n\n    # Build the context parallel groups.\n    global _CONTEXT_PARALLEL_GROUP\n    global _CONTEXT_PARALLEL_GROUP_RANKS\n\n    assert _CONTEXT_PARALLEL_GROUP is None, (\n        'Context parallelism is already initialized.'\n    )\n    for i in range(dpsize):\n        for j in range(pipeline_parallel_size):\n            for k in range(tensor_parallel_size):\n                ranks = groups[i, j, :, k].tolist()\n                group = tdist.new_group(\n                    ranks, backend=context_parallel_backend, timeout=timeout\n                )\n                if i == found[0] and j == found[1] and k == found[3]:\n                    _CONTEXT_PARALLEL_GROUP = group\n                    _CONTEXT_PARALLEL_GROUP_RANKS = ranks\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.make_layout","title":"<code>make_layout(ratio=4, visible=True)</code>","text":"<p>Define the layout.</p> Source code in <code>src/ezpz/log/style.py</code> <pre><code>def make_layout(ratio: int = 4, visible: bool = True) -&gt; Layout:\n    \"\"\"Define the layout.\"\"\"\n    layout = Layout(name='root', visible=visible)\n    layout.split_row(\n        Layout(name='main', ratio=ratio, visible=visible),\n        Layout(name='footer', visible=visible),\n    )\n    return layout\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.print_config","title":"<code>print_config(config, resolve=True)</code>","text":"<p>Prints content of DictConfig using Rich library and its tree structure.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>DictConfig</code> <p>Configuration composed by Hydra.</p> required <code>print_order</code> <code>Sequence[str]</code> <p>Determines in what order config components are printed.</p> required <code>resolve</code> <code>bool</code> <p>Whether to resolve reference fields of DictConfig.</p> <code>True</code> Source code in <code>src/ezpz/log/style.py</code> <pre><code>def print_config(\n    config: DictConfig | dict | Any,\n    resolve: bool = True,\n) -&gt; None:\n    \"\"\"Prints content of DictConfig using Rich library and its tree structure.\n\n    Args:\n        config (DictConfig): Configuration composed by Hydra.\n        print_order (Sequence[str], optional): Determines in what order config\n            components are printed.\n        resolve (bool, optional): Whether to resolve reference fields of\n            DictConfig.\n    \"\"\"\n    import pandas as pd\n\n    tree = rich.tree.Tree('CONFIG')  # , style=style, guide_style=style)\n    quee = []\n    for f in config:\n        if f not in quee:\n            quee.append(f)\n    dconfig = {}\n    for f in quee:\n        branch = tree.add(f)  # , style=style, guide_style=style)\n        config_group = config[f]\n        if isinstance(config_group, DictConfig):\n            branch_content = OmegaConf.to_yaml(config_group, resolve=resolve)\n            cfg = OmegaConf.to_container(config_group, resolve=resolve)\n        else:\n            branch_content = str(config_group)\n            cfg = str(config_group)\n        dconfig[f] = cfg\n        branch.add(rich.syntax.Syntax(branch_content, 'yaml'))\n    outfile = Path(os.getcwd()).joinpath('config_tree.log')\n    with outfile.open('wt') as f:\n        console = rich.console.Console(file=f)\n        console.print(tree)\n    with open('config.json', 'w') as f:\n        f.write(json.dumps(dconfig))\n    cfgfile = Path('config.yaml')\n    OmegaConf.save(config, cfgfile, resolve=True)\n    cfgdict = OmegaConf.to_object(config)\n    logdir = Path(os.getcwd()).resolve().as_posix()\n    if not config.get('debug_mode', False):\n        dbfpath = Path(os.getcwd()).joinpath('logdirs.csv')\n    else:\n        dbfpath = Path(os.getcwd()).joinpath('logdirs-debug.csv')\n    if dbfpath.is_file():\n        mode = 'a'\n        header = False\n    else:\n        mode = 'w'\n        header = True\n    df = pd.DataFrame({logdir: cfgdict})\n    df.T.to_csv(dbfpath.resolve().as_posix(), mode=mode, header=header)\n    os.environ['LOGDIR'] = logdir\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.print_config_tree","title":"<code>print_config_tree(cfg, resolve=True, save_to_file=True, verbose=True, style='tree', print_order=None, highlight=True, outfile=None)</code>","text":"<p>Prints the contents of a DictConfig as a tree structure using the Rich library.</p> <ul> <li>cfg: A DictConfig composed by Hydra.</li> <li>print_order: Determines in what order config components are printed.</li> <li>resolve: Whether to resolve reference fields of DictConfig.</li> <li>save_to_file: Whether to export config to the hydra output folder.</li> </ul> Source code in <code>src/ezpz/configs.py</code> <pre><code>def print_config_tree(\n    cfg: DictConfig,\n    resolve: bool = True,\n    save_to_file: bool = True,\n    verbose: bool = True,\n    style: str = \"tree\",\n    print_order: Optional[Sequence[str]] = None,\n    highlight: bool = True,\n    outfile: Optional[Union[str, os.PathLike, Path]] = None,\n) -&gt; Tree:\n    \"\"\"Prints the contents of a DictConfig as a tree structure using the Rich\n    library.\n\n    - cfg: A DictConfig composed by Hydra.\n    - print_order: Determines in what order config components are printed.\n    - resolve: Whether to resolve reference fields of DictConfig.\n    - save_to_file: Whether to export config to the hydra output folder.\n    \"\"\"\n    from rich.console import Console\n    from ezpz.log.config import STYLES\n    from rich.theme import Theme\n\n    name = cfg.get(\"_target_\", \"cfg\")\n    console = Console(record=True, theme=Theme(STYLES))\n    tree = Tree(label=name, highlight=highlight)\n    queue = []\n    # add fields from `print_order` to queue\n    if print_order is not None:\n        for field in print_order:\n            (\n                queue.append(field)\n                if field in cfg\n                else log.warning(\n                    f\"Field '{field}' not found in config. \"\n                    f\"Skipping '{field}' config printing...\"\n                )\n            )\n    # add all the other fields to queue (not specified in `print_order`)\n    for field in cfg:\n        if field not in queue:\n            queue.append(field)\n    # generate config tree from queue\n    for field in queue:\n        branch = tree.add(field, highlight=highlight)  # , guide_style=style)\n        config_group = cfg[field]\n        if isinstance(config_group, DictConfig):\n            branch_content = str(\n                OmegaConf.to_yaml(config_group, resolve=resolve)\n            )\n            branch.add(Text(branch_content, style=\"red\"))\n        else:\n            branch_content = str(config_group)\n            branch.add(Text(branch_content, style=\"blue\"))\n    if verbose or save_to_file:\n        console.print(tree)\n        if save_to_file:\n            outfpath = (\n                Path(os.getcwd()).joinpath(\"config_tree.log\")\n                if outfile is None\n                else Path(outfile)\n            )\n            console.save_text(outfpath.as_posix())\n    return tree\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.printarr","title":"<code>printarr(*arrs, float_width=6)</code>","text":"<p>Print a pretty table giving name, shape, dtype, type, and content information for input tensors or scalars.</p> <p>Call like: printarr(my_arr, some_other_arr, maybe_a_scalar). Accepts a variable number of arguments.</p> Inputs can be <ul> <li>Numpy tensor arrays</li> <li>Pytorch tensor arrays</li> <li>Jax tensor arrays</li> <li>Python ints / floats</li> <li>None</li> </ul> <p>It may also work with other array-like types, but they have not been tested</p> <p>Use the <code>float_width</code> option specify the precision to which floating point types are printed.</p> <p>Author: Nicholas Sharp (nmwsharp.com) Canonical source:     https://gist.github.com/nmwsharp/54d04af87872a4988809f128e1a1d233 License: This snippet may be used under an MIT license, and it is also released into the public domain. Please retain this docstring as a reference.</p> Source code in <code>src/ezpz/log/style.py</code> <pre><code>def printarr(*arrs, float_width=6):\n    \"\"\"\n    Print a pretty table giving name, shape, dtype, type, and content\n    information for input tensors or scalars.\n\n    Call like: printarr(my_arr, some_other_arr, maybe_a_scalar). Accepts a\n    variable number of arguments.\n\n    Inputs can be:\n        - Numpy tensor arrays\n        - Pytorch tensor arrays\n        - Jax tensor arrays\n        - Python ints / floats\n        - None\n\n    It may also work with other array-like types, but they have not been tested\n\n    Use the `float_width` option specify the precision to which floating point\n    types are printed.\n\n    Author: Nicholas Sharp (nmwsharp.com)\n    Canonical source:\n        https://gist.github.com/nmwsharp/54d04af87872a4988809f128e1a1d233\n    License: This snippet may be used under an MIT license, and it is also\n    released into the public domain. Please retain this docstring as a\n    reference.\n    \"\"\"\n    import inspect\n\n    frame_ = inspect.currentframe()\n    assert frame_ is not None\n    frame = frame_.f_back\n    # if frame_ is not None:\n    #     frame = frame_.f_back\n    # else:\n    #     frame = inspect.getouterframes()\n    default_name = '[temporary]'\n\n    # helpers to gather data about each array\n\n    def name_from_outer_scope(a):\n        if a is None:\n            return '[None]'\n        name = default_name\n        if frame_ is not None:\n            for k, v in frame_.f_locals.items():\n                if v is a:\n                    name = k\n                    break\n        return name\n\n    def dtype_str(a):\n        if a is None:\n            return 'None'\n        if isinstance(a, int):\n            return 'int'\n        if isinstance(a, float):\n            return 'float'\n        return str(a.dtype)\n\n    def shape_str(a):\n        if a is None:\n            return 'N/A'\n        if isinstance(a, int):\n            return 'scalar'\n        if isinstance(a, float):\n            return 'scalar'\n        return str(list(a.shape))\n\n    def type_str(a):\n        # TODO this is is weird... what's the better way?\n        return str(type(a))[8:-2]\n\n    def device_str(a):\n        if hasattr(a, 'device'):\n            device_str = str(a.device)\n            if len(device_str) &lt; 10:\n                # heuristic: jax returns some goofy long string we don't want,\n                # ignore it\n                return device_str\n        return ''\n\n    def format_float(x):\n        return f'{x:{float_width}g}'\n\n    def minmaxmean_str(a):\n        if a is None:\n            return ('N/A', 'N/A', 'N/A')\n        if isinstance(a, int) or isinstance(a, float):\n            return (format_float(a), format_float(a), format_float(a))\n\n        # compute min/max/mean. if anything goes wrong, just print 'N/A'\n        min_str = 'N/A'\n        try:\n            min_str = format_float(a.min())\n        except Exception:\n            pass\n        max_str = 'N/A'\n        try:\n            max_str = format_float(a.max())\n        except Exception:\n            pass\n        mean_str = 'N/A'\n        try:\n            mean_str = format_float(a.mean())\n        except Exception:\n            pass\n\n        return (min_str, max_str, mean_str)\n\n    try:\n        props = [\n            'name',\n            'dtype',\n            'shape',\n            'type',\n            'device',\n            'min',\n            'max',\n            'mean',\n        ]\n\n        # precompute all of the properties for each input\n        str_props = []\n        for a in arrs:\n            minmaxmean = minmaxmean_str(a)\n            str_props.append(\n                {\n                    'name': name_from_outer_scope(a),\n                    'dtype': dtype_str(a),\n                    'shape': shape_str(a),\n                    'type': type_str(a),\n                    'device': device_str(a),\n                    'min': minmaxmean[0],\n                    'max': minmaxmean[1],\n                    'mean': minmaxmean[2],\n                }\n            )\n\n        # for each property, compute its length\n        maxlen = {}\n        for p in props:\n            maxlen[p] = 0\n        for sp in str_props:\n            for p in props:\n                maxlen[p] = max(maxlen[p], len(sp[p]))\n\n        # if any property got all empty strings,\n        # don't bother printing it, remove if from the list\n        props = [p for p in props if maxlen[p] &gt; 0]\n\n        # print a header\n        header_str = ''\n        for p in props:\n            prefix = '' if p == 'name' else ' | '\n            fmt_key = '&gt;' if p == 'name' else '&lt;'\n            header_str += f'{prefix}{p:{fmt_key}{maxlen[p]}}'\n        print(header_str)\n        print('-' * len(header_str))\n        # now print the acual arrays\n        for strp in str_props:\n            for p in props:\n                prefix = '' if p == 'name' else ' | '\n                fmt_key = '&gt;' if p == 'name' else '&lt;'\n                print(f'{prefix}{strp[p]:{fmt_key}{maxlen[p]}}', end='')\n            print('')\n\n    finally:\n        del frame\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.query_environment","title":"<code>query_environment()</code>","text":"<p>Query environment variables for info about distributed setup</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def query_environment() -&gt; dict[str, int]:\n    \"\"\"Query environment variables for info about distributed setup\"\"\"\n    ws = os.environ.get(\"WORLD_SIZE\", None)\n    r = os.environ.get(\"RANK\", None)\n    lr = os.environ.get(\"LOCAL_RANK\", None)\n    if ws is not None and r is not None and lr is not None:\n        return {\n            \"world_size\": int(ws),\n            \"rank\": int(r),\n            \"local_rank\": int(lr),\n            # 'machine': machine,\n        }\n    return {\n        \"world_size\": int(get_world_size()),\n        \"rank\": int(get_rank()),\n        \"local_rank\": int(get_local_rank()),\n    }\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.setup_torch","title":"<code>setup_torch(backend=None, port=None, seed=None, timeout=None, verbose=False, tensor_parallel_size=1, pipeline_parallel_size=1, context_parallel_size=1, tensor_parallel_backend=None, pipeline_parallel_backend=None, context_parallel_backend=None, data_parallel_backend=None)</code>","text":"<p>Setup torch.</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def setup_torch(\n    backend: Optional[str] = None,\n    port: Optional[str | int] = None,\n    seed: Optional[int] = None,\n    timeout: Optional[str | int] = None,\n    verbose: Optional[bool] = False,\n    tensor_parallel_size: int = 1,\n    pipeline_parallel_size: int = 1,\n    context_parallel_size: int = 1,\n    tensor_parallel_backend: Optional[str] = None,\n    pipeline_parallel_backend: Optional[str] = None,\n    context_parallel_backend: Optional[str] = None,\n    data_parallel_backend: Optional[str] = None,\n) -&gt; int:\n    \"\"\"Setup torch.\"\"\"\n    device = get_torch_device()\n    # if ACCELERATOR_TYPE == 'NvidiaGPU' and device == 'cuda':\n    #     os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n    #     torch.backends.cudnn.deterministic = True     # type:ignore\n    #     torch.backends.cudnn.benchmark = True         # type:ignore\n    #     torch.backends.cudnn.allow_tf32 = True        # type:ignore\n    #     torch.backends.cuda.matmul.allow_tf32 = True  # type:ignore\n    # torch.use_deterministic_algorithms(True)\n    ws_from_env = os.environ.get(\"WORLD_SIZE\", None)\n    backend = \"DDP\" if backend is None else backend\n    backend = backend.lower()\n    if ws_from_env is not None and ws_from_env == \"1\":\n        logger.info(\n            f\"Running on a single {device}, not initializing torch.distributed!\"\n        )\n        rank = 0\n        world_size = 1\n        local_rank = 0\n        local_size = 1\n        num_nodes = 1\n    else:\n        dsetup = setup_torch_distributed(\n            backend=backend,\n            port=port,\n            timeout=timeout,\n            tensor_parallel_size=int(tensor_parallel_size),\n            pipeline_parallel_size=int(pipeline_parallel_size),\n            context_parallel_size=int(context_parallel_size),\n            tensor_parallel_backend=tensor_parallel_backend,\n            pipeline_parallel_backend=pipeline_parallel_backend,\n            context_parallel_backend=context_parallel_backend,\n            data_parallel_backend=data_parallel_backend,\n        )\n        rank = dsetup[\"rank\"]\n        world_size = dsetup[\"world_size\"]\n        local_rank = dsetup[\"local_rank\"]\n        local_size = get_gpus_per_node()\n        num_nodes = get_num_nodes()\n    os.environ[\"RANK\"] = str(rank)\n    os.environ[\"LOCAL_RANK\"] = str(local_rank)\n    os.environ[\"NUM_NODES\"] = str(num_nodes)\n    os.environ[\"LOCAL_SIZE\"] = str(local_size)\n    os.environ[\"WORLD_SIZE\"] = str(world_size)\n    # nthreads = os.environ.get('OMP_NUM_THREADS', None)\n    if ACCELERATOR_TYPE == \"IntelGPU\" and device == \"xpu\":\n        # logger.warning(f'Using {get_torch_device()}:{get_local_rank()}')\n        # os.environ['CCL_LOCAL_RANK'] = str(local_rank)\n        # os.environ['CCL_LOCAL_SIZE'] = str(local_size)\n        torch.xpu.set_device(local_rank)  # type:ignore\n    if seed is not None:\n        seed_everything(seed * (rank + 1) * (local_rank + 1))\n    if rank == 0:\n        if backend in {\"ds\", \"deepspeed\", \"dspeed\"}:\n            from ezpz.configs import git_ds_info\n\n            git_ds_info()\n        _ = get_dist_info(verbose=verbose)\n        if verbose:\n            _ = print_dist_setup()\n    if oneccl_bpt is not None:\n        logger.debug(f\"Using oneccl_bindings from: {oneccl_bpt.__file__}\")\n    if ipex is not None:\n        logger.debug(f\"Using ipex from: {ipex.__file__}\")\n    # if world_size &gt; 1:\n    #     tdist.barrier()\n\n    if rank == 0:\n        logger.info(\n            f\"Using {device=} with {backend=} \"\n            f\"+ '{get_torch_backend()}' \"\n            \"for distributed training.\"\n        )\n    lrank = len(str(world_size - 1))\n    # nz = lrank - len(str(rank))\n    hn = socket.gethostname()\n    psizes = [f\"['{hn}']\" + f\"[{rank:&gt;{lrank}}/{world_size - 1:&lt;{lrank}}] \"]\n    if (\n        tensor_parallel_size &gt; 1\n        or context_parallel_size &gt; 1\n        or pipeline_parallel_size &gt; 1\n    ):\n        import ezpz.tp\n\n        tprank = ezpz.tp.get_tensor_parallel_rank()\n        # tpranks = ezpz.tp.get_tensor_parallel_ranks()\n        tpsize = ezpz.tp.get_tensor_parallel_world_size()\n\n        dprank = ezpz.tp.get_data_parallel_rank()\n        # dpranks = ezpz.tp.get_data_parallel_ranks()\n        dpsize = ezpz.tp.get_data_parallel_world_size()\n\n        pprank = ezpz.tp.get_pipeline_parallel_rank()\n        # ppranks = ezpz.tp.get_pipeline_parallel_ranks()\n        ppsize = ezpz.tp.get_pipeline_parallel_world_size()\n\n        # cpranks = ezpz.tp.get_context_parallel_ranks()\n        cprank = ezpz.tp.get_context_parallel_rank()\n        cpsize = ezpz.tp.get_context_parallel_world_size()\n\n        if cpsize &gt; 1 or ppsize &gt; 1 or tpsize &gt; 1:\n            if cpsize &gt; 1:\n                lcp = len(str(cpsize - 1))\n                psizes.append(f\"[cp:{cprank:&gt;{lcp}}/{cpsize - 1:&lt;{lcp}}]\")\n                tdist.barrier(group=ezpz.tp.get_context_parallel_group())\n            if ppsize &gt; 1:\n                lpp = len(str(ppsize - 1))\n                psizes.append(f\"[pp:{pprank:&gt;{lpp}}/{ppsize - 1:&lt;{lpp}}]\")\n                tdist.barrier(group=ezpz.tp.get_pipeline_parallel_group())\n            if tpsize &gt; 1:\n                ltp = len(str(tpsize - 1))\n                psizes.append(f\"[tp:{tprank:&gt;{ltp}}/{tpsize - 1:&lt;{ltp}}]\")\n                tdist.barrier(group=ezpz.tp.get_tensor_parallel_group())\n            if dpsize &gt; 1:\n                ldp = len(str(dpsize - 1))\n                psizes.append(f\"[dp:{dprank:&gt;{ldp}}/{dpsize - 1:&lt;{ldp}}]\")\n                tdist.barrier(group=ezpz.tp.get_data_parallel_group())\n    # tdist.all_gather(psizes)\n    logger.info(\"\".join(psizes))\n    tdist.barrier()\n    # MPI.COMM_WORLD.Barrier()\n    return rank\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.setup_torch_distributed","title":"<code>setup_torch_distributed(backend=None, tensor_parallel_size=1, pipeline_parallel_size=1, context_parallel_size=1, tensor_parallel_backend=None, pipeline_parallel_backend=None, context_parallel_backend=None, data_parallel_backend=None, port=None, timeout=None)</code>","text":"<p>Returns {'world_size': int, 'rank': int, 'local_rank': int}</p> Source code in <code>src/ezpz/dist.py</code> <pre><code>def setup_torch_distributed(\n    backend: Optional[str] = None,\n    tensor_parallel_size: int = 1,\n    pipeline_parallel_size: int = 1,\n    context_parallel_size: int = 1,\n    tensor_parallel_backend: Optional[str] = None,\n    pipeline_parallel_backend: Optional[str] = None,\n    context_parallel_backend: Optional[str] = None,\n    data_parallel_backend: Optional[str] = None,\n    port: Optional[str | int] = None,\n    timeout: Optional[str | int] = None,\n) -&gt; dict[str, int]:\n    \"\"\"Returns {'world_size': int, 'rank': int, 'local_rank': int}\"\"\"\n    backend = \"DDP\" if backend is None else backend\n    assert backend.lower() in {\n        \"ddp\",\n        \"ds\",\n        \"deepspeed\",\n        \"horovod\",\n        \"hvd\",\n    }\n    timeout = (\n        3600\n        if timeout is None\n        else int(timeout)\n        if isinstance(timeout, str)\n        else timeout\n    )\n    port = (\n        \"1234\" if port is None else str(port) if isinstance(port, int) else port\n    )\n    rank = get_rank()\n    world_size = get_world_size()\n    local_rank = get_local_rank()\n    be = backend.lower()\n    # assert be in BACKENDS['pytorch']\n    if be == \"ddp\":\n        dsetup = setup_torch_DDP(port, timeout)\n        world_size = dsetup[\"world_size\"]\n        rank = dsetup[\"rank\"]\n        local_rank = dsetup[\"local_rank\"]\n        if torch.cuda.is_available():\n            torch.cuda.set_device(local_rank)\n    elif be in {\"deepspeed\", \"ds\"}:\n        init_deepspeed(timeout=timeout)\n        world_size = get_world_size()\n        rank = get_rank()\n        local_rank = get_local_rank()\n    elif be in {\"horovod\", \"hvd\"}:\n        import horovod.torch as hvd  # type:ignore noqa\n\n        _ = None if hvd.is_initialized() else hvd.init()\n        # hvd.init() if not hvd.is_initialized() else None\n        rank = hvd.rank()\n        world_size = hvd.size()\n        local_rank = hvd.local_rank()\n        if torch.cuda.is_available():\n            torch.cuda.set_device(hvd.local_rank())\n    else:\n        raise ValueError(f\"Unable to parse backend: {be=}\")\n\n    if (\n        tensor_parallel_size &gt; 1\n        or context_parallel_size &gt; 1\n        or pipeline_parallel_size &gt; 1\n    ):\n        ezpz.tp.initialize_tensor_parallel(\n            tensor_parallel_size=tensor_parallel_size,\n            pipeline_parallel_size=pipeline_parallel_size,\n            context_parallel_size=context_parallel_size,\n            tensor_parallel_backend=tensor_parallel_backend,\n            pipeline_parallel_backend=pipeline_parallel_backend,\n            context_parallel_backend=context_parallel_backend,\n            data_parallel_backend=data_parallel_backend,\n            timeout=timedelta(seconds=timeout),\n        )\n\n    os.environ[\"world_size\"] = str(world_size)\n    os.environ[\"RANK\"] = str(rank)\n    os.environ[\"LOCAL_RANK\"] = str(local_rank)\n\n    return {\"world_size\": world_size, \"rank\": rank, \"local_rank\": local_rank}\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.should_do_markup","title":"<code>should_do_markup(stream=sys.stdout)</code>","text":"<p>Decide about use of ANSI colors.</p> Source code in <code>src/ezpz/log/console.py</code> <pre><code>def should_do_markup(stream: TextIO = sys.stdout) -&gt; bool:\n    \"\"\"Decide about use of ANSI colors.\"\"\"\n    py_colors = None\n\n    # https://xkcd.com/927/\n    for env_var in [\"PY_COLORS\", \"CLICOLOR\", \"FORCE_COLOR\", \"ANSIBLE_FORCE_COLOR\"]:\n        value = os.environ.get(env_var, None)\n        if value is not None:\n            py_colors = to_bool(value)\n            break\n\n    # If deliverately disabled colors\n    if os.environ.get(\"NO_COLOR\", None):\n        return False\n\n    # User configuration requested colors\n    if py_colors is not None:\n        return to_bool(py_colors)\n\n    term = os.environ.get(\"TERM\", \"\")\n    if \"xterm\" in term:\n        return True\n\n    if term.lower() == \"dumb\":\n        return False\n\n    # Use tty detection logic as last resort because there are numerous\n    # factors that can make isatty return a misleading value, including:\n    # - stdin.isatty() is the only one returning true, even on a real terminal\n    # - stderr returting false if user user uses a error stream coloring solution\n    return stream.isatty()\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.tensor_parallel_is_initialized","title":"<code>tensor_parallel_is_initialized()</code>","text":"<p>Check if tensor and data parallel groups are initialized.</p> Source code in <code>src/ezpz/tp/__init__.py</code> <pre><code>def tensor_parallel_is_initialized() -&gt; bool:\n    \"\"\"Check if tensor and data parallel groups are initialized.\"\"\"\n    if (\n        _TENSOR_PARALLEL_GROUP is None\n        or _DATA_PARALLEL_GROUP is None\n        or _PIPELINE_PARALLEL_GROUP is None\n        or _CONTEXT_PARALLEL_GROUP is None\n    ):\n        return False\n    return True\n</code></pre>"},{"location":"Code-Reference/ezpz-reference/#ezpz.to_bool","title":"<code>to_bool(value)</code>","text":"<p>Return a bool for the arg.</p> Source code in <code>src/ezpz/log/console.py</code> <pre><code>def to_bool(value: Any) -&gt; bool:\n    \"\"\"Return a bool for the arg.\"\"\"\n    if value is None or isinstance(value, bool):\n        return bool(value)\n    if isinstance(value, str):\n        value = value.lower()\n    if value in (\"yes\", \"on\", \"1\", \"true\", 1):\n        return True\n    return False\n</code></pre>"},{"location":"Code-Reference/test-dist-reference/","title":"<code>ezpz.test_dist</code>","text":"<p>This module is part of the <code>ezpz</code> package</p> <p>test_dist.py</p> <ul> <li>to launch:</li> </ul> <p>$ source ezpz/src/ezpz/bin/savejobenv   $ BACKEND=DDP launch python3 ezpz_ddp.py</p>"}]}